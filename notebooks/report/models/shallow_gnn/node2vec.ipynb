{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fg4sTOLBNbFJ","executionInfo":{"status":"ok","timestamp":1707464155439,"user_tz":-210,"elapsed":20945,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"55844775-d4f1-4453-d06d-008fb4defe0a"},"id":"Fg4sTOLBNbFJ","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Academic/Topics/AI/Machine\\ Learning\\ Dr.\\ Montazeri/Project/ml_mda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkz5A_SiNcle","executionInfo":{"status":"ok","timestamp":1707464156797,"user_tz":-210,"elapsed":1361,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"c1948036-c0c4-4d25-f608-dc520a127c31"},"id":"gkz5A_SiNcle","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Academic/Topics/AI/Machine Learning Dr. Montazeri/Project/ml_mda\n"]}]},{"cell_type":"code","source":["!pip install torch_geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODp_C8LiNecw","executionInfo":{"status":"ok","timestamp":1707464164872,"user_tz":-210,"elapsed":8077,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"fe3c7be9-947f-4ae4-ce8b-a95b9348a02f"},"id":"ODp_C8LiNecw","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch_geometric\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m0.9/1.0 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n","Installing collected packages: torch_geometric\n","Successfully installed torch_geometric-2.4.0\n"]}]},{"cell_type":"code","source":["!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IaKc5GwjNgRJ","executionInfo":{"status":"ok","timestamp":1707464179636,"user_tz":-210,"elapsed":14769,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"92a21734-ac25-4a4a-e681-97016d345b8e"},"id":"IaKc5GwjNgRJ","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\n","Collecting pyg_lib\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/pyg_lib-0.4.0%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_scatter\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (10.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_sparse\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_cluster\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_cluster-1.6.3%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_spline_conv\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (932 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m932.1/932.1 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n","Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n","Successfully installed pyg_lib-0.4.0+pt21cu121 torch_cluster-1.6.3+pt21cu121 torch_scatter-2.1.2+pt21cu121 torch_sparse-0.6.18+pt21cu121 torch_spline_conv-1.2.2+pt21cu121\n"]}]},{"cell_type":"markdown","source":["# Requirements"],"metadata":{"id":"Syp1fG3XMOu8"},"id":"Syp1fG3XMOu8"},{"cell_type":"code","source":["import torch\n","\n","from base import OptimizerConfig, cross_validation\n","from base import SimplePytorchData, SimplePytorchDataTrainTestSplit\n","from base import SimpleTrainer, SimpleTester\n","from src.config import Node2VecConfig, Node2VecOptimizerConfig, SimpleClassifierConfig\n","from src.features import get_node2vec_pair_embedd_for_training_data, get_associations\n","from src.models import SimpleMDAClassifier, SimpleMDAClassifierFactory\n","from src.utils import train_test_sampler, prj_logger"],"metadata":{"id":"aQN35hGYL9zT","executionInfo":{"status":"ok","timestamp":1707464201788,"user_tz":-210,"elapsed":22174,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"aQN35hGYL9zT","execution_count":5,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"fAZ0nEWSMSOU","executionInfo":{"status":"ok","timestamp":1707464202427,"user_tz":-210,"elapsed":663,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"fAZ0nEWSMSOU","execution_count":6,"outputs":[]},{"cell_type":"code","source":["import logging\n","import sys\n","\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n","    handlers=[\n","        logging.StreamHandler(stream=sys.stdout)\n","    ],\n","    force=True\n",")"],"metadata":{"id":"ZhHjiOAeJPHm","executionInfo":{"status":"ok","timestamp":1707464202427,"user_tz":-210,"elapsed":4,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"ZhHjiOAeJPHm","execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Pretraining with Node2Vec"],"metadata":{"id":"w-tFOU11MKi9"},"id":"w-tFOU11MKi9"},{"cell_type":"markdown","source":["## Configs"],"metadata":{"id":"S7SfvxE63t_v"},"id":"S7SfvxE63t_v"},{"cell_type":"code","source":["# Node2Vec Config\n","node2vec_config = Node2VecConfig()\n","node2vec_config.embedding_dim = 32\n","node2vec_config.walk_length = 50\n","node2vec_config.context_size = 10\n","node2vec_config.walks_per_node = 10\n","node2vec_config.num_negative_samples = 1\n","node2vec_config.p = 1.0\n","node2vec_config.q = 1.0\n","node2vec_config.num_nodes = None\n","node2vec_config.sparse = True\n","\n","# Node2Vec Optimizer Config\n","node2vec_optimizer_config = Node2VecOptimizerConfig()\n","node2vec_optimizer_config.exp_name = 'Node2VecOptimizer Default'\n","node2vec_optimizer_config.shuffle = True\n","node2vec_optimizer_config.num_workers = 2\n","node2vec_optimizer_config.lr = 0.01\n","node2vec_optimizer_config.device = device\n","node2vec_optimizer_config.report_size = 1000\n","node2vec_optimizer_config.optimizer = torch.optim.SparseAdam"],"metadata":{"id":"3G6ocDSzMbtF","executionInfo":{"status":"ok","timestamp":1707464202427,"user_tz":-210,"elapsed":3,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"3G6ocDSzMbtF","execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Embeddings"],"metadata":{"id":"sH2G8xOr3xng"},"id":"sH2G8xOr3xng"},{"cell_type":"code","source":["md_embed = get_node2vec_pair_embedd_for_training_data(node2vec_config, node2vec_optimizer_config)"],"metadata":{"id":"FGlGbumL3icd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707464527592,"user_tz":-210,"elapsed":325168,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"42a0f13b-d086-4c93-c9eb-6016115974ff"},"id":"FGlGbumL3icd","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 07:36:42,620 [INFO] Calling get_node2vec_pair_embedd on cuda device ...\n","2024-02-09 07:36:42,621 [INFO] Calling get_homogeneous_graph\n","2024-02-09 07:36:46,538 [INFO] homogeneous data : Data(x=[66911, 1], edge_index=[2, 633662])\n","2024-02-09 07:36:46,545 [INFO] Calling get_node2vec_embedd on cuda device ...\n","2024-02-09 07:36:46,546 [INFO] Creating Node2Vec model ...\n","2024-02-09 07:36:46,549 [INFO] Calling get_homogeneous_graph\n","2024-02-09 07:36:47,250 [INFO] homogeneous data : Data(x=[66911, 1], edge_index=[2, 633662])\n","2024-02-09 07:36:47,252 [INFO] Initialing MDNode2Vec with model_config {'model_name': None, 'embedding_dim': 32, 'walk_length': 50}\n","2024-02-09 07:36:47,570 [INFO] Training Node2Vec ...\n","2024-02-09 07:36:47,572 [INFO] Running Node2vecTrainer with Node2VecOptimizer Default\n","2024-02-09 07:36:47,576 [INFO] Creating <class 'torch.optim.sparse_adam.SparseAdam'> with lr : 0.01\n","2024-02-09 07:36:47,578 [INFO] moving model to cuda\n","2024-02-09 07:36:47,584 [INFO] start batch optimizing\n","2024-02-09 07:36:57,492 [INFO] loss: 3.4961    [ 1000]\n","2024-02-09 07:37:01,834 [INFO] loss: 2.3066    [ 2000]\n","2024-02-09 07:37:06,345 [INFO] loss: 1.6438    [ 3000]\n","2024-02-09 07:37:11,313 [INFO] loss: 1.3106    [ 4000]\n","2024-02-09 07:37:15,584 [INFO] loss: 1.1286    [ 5000]\n","2024-02-09 07:37:20,415 [INFO] loss: 1.0306    [ 6000]\n","2024-02-09 07:37:25,091 [INFO] loss: 0.9741    [ 7000]\n","2024-02-09 07:37:29,362 [INFO] loss: 0.9377    [ 8000]\n","2024-02-09 07:37:34,588 [INFO] loss: 0.9159    [ 9000]\n","2024-02-09 07:37:38,952 [INFO] loss: 0.8989    [10000]\n","2024-02-09 07:37:43,418 [INFO] loss: 0.8893    [11000]\n","2024-02-09 07:37:48,591 [INFO] loss: 0.8814    [12000]\n","2024-02-09 07:37:53,032 [INFO] loss: 0.8735    [13000]\n","2024-02-09 07:37:57,382 [INFO] loss: 0.8699    [14000]\n","2024-02-09 07:38:02,690 [INFO] loss: 0.8664    [15000]\n","2024-02-09 07:38:07,039 [INFO] loss: 0.8614    [16000]\n","2024-02-09 07:38:11,765 [INFO] loss: 0.8588    [17000]\n","2024-02-09 07:38:16,611 [INFO] loss: 0.8591    [18000]\n","2024-02-09 07:38:20,933 [INFO] loss: 0.8548    [19000]\n","2024-02-09 07:38:26,075 [INFO] loss: 0.8531    [20000]\n","2024-02-09 07:38:30,524 [INFO] loss: 0.8521    [21000]\n","2024-02-09 07:38:35,187 [INFO] loss: 0.8517    [22000]\n","2024-02-09 07:38:40,398 [INFO] loss: 0.8482    [23000]\n","2024-02-09 07:38:44,709 [INFO] loss: 0.8491    [24000]\n","2024-02-09 07:38:48,974 [INFO] loss: 0.8471    [25000]\n","2024-02-09 07:38:54,249 [INFO] loss: 0.8448    [26000]\n","2024-02-09 07:38:58,693 [INFO] loss: 0.8447    [27000]\n","2024-02-09 07:39:03,352 [INFO] loss: 0.8460    [28000]\n","2024-02-09 07:39:08,282 [INFO] loss: 0.8467    [29000]\n","2024-02-09 07:39:12,606 [INFO] loss: 0.8449    [30000]\n","2024-02-09 07:39:17,322 [INFO] loss: 0.8425    [31000]\n","2024-02-09 07:39:22,092 [INFO] loss: 0.8426    [32000]\n","2024-02-09 07:39:26,686 [INFO] loss: 0.8416    [33000]\n","2024-02-09 07:39:32,141 [INFO] loss: 0.8422    [34000]\n","2024-02-09 07:39:36,668 [INFO] loss: 0.8410    [35000]\n","2024-02-09 07:39:41,105 [INFO] loss: 0.8415    [36000]\n","2024-02-09 07:39:46,393 [INFO] loss: 0.8402    [37000]\n","2024-02-09 07:39:50,817 [INFO] loss: 0.8388    [38000]\n","2024-02-09 07:39:55,476 [INFO] loss: 0.8399    [39000]\n","2024-02-09 07:40:00,496 [INFO] loss: 0.8393    [40000]\n","2024-02-09 07:40:04,889 [INFO] loss: 0.8367    [41000]\n","2024-02-09 07:40:09,850 [INFO] loss: 0.8368    [42000]\n","2024-02-09 07:40:14,515 [INFO] loss: 0.8391    [43000]\n","2024-02-09 07:40:18,931 [INFO] loss: 0.8392    [44000]\n","2024-02-09 07:40:24,221 [INFO] loss: 0.8371    [45000]\n","2024-02-09 07:40:28,668 [INFO] loss: 0.8384    [46000]\n","2024-02-09 07:40:33,104 [INFO] loss: 0.8357    [47000]\n","2024-02-09 07:40:38,357 [INFO] loss: 0.8351    [48000]\n","2024-02-09 07:40:42,644 [INFO] loss: 0.8354    [49000]\n","2024-02-09 07:40:47,106 [INFO] loss: 0.8338    [50000]\n","2024-02-09 07:40:52,274 [INFO] loss: 0.8360    [51000]\n","2024-02-09 07:40:56,863 [INFO] loss: 0.8363    [52000]\n","2024-02-09 07:41:01,883 [INFO] loss: 0.8356    [53000]\n","2024-02-09 07:41:06,726 [INFO] loss: 0.8339    [54000]\n","2024-02-09 07:41:11,350 [INFO] loss: 0.8374    [55000]\n","2024-02-09 07:41:16,594 [INFO] loss: 0.8367    [56000]\n","2024-02-09 07:41:20,922 [INFO] loss: 0.8350    [57000]\n","2024-02-09 07:41:25,312 [INFO] loss: 0.8340    [58000]\n","2024-02-09 07:41:30,414 [INFO] loss: 0.8352    [59000]\n","2024-02-09 07:41:34,717 [INFO] loss: 0.8349    [60000]\n","2024-02-09 07:41:39,134 [INFO] loss: 0.8349    [61000]\n","2024-02-09 07:41:44,346 [INFO] loss: 0.8335    [62000]\n","2024-02-09 07:41:48,689 [INFO] loss: 0.8331    [63000]\n","2024-02-09 07:41:53,481 [INFO] loss: 0.8334    [64000]\n","2024-02-09 07:41:58,294 [INFO] loss: 0.8335    [65000]\n","2024-02-09 07:42:02,494 [INFO] loss: 0.8327    [66000]\n","2024-02-09 07:42:07,105 [INFO] Result on Train Data : {'AUC': 0, 'ACC': 0, 'F1 Score': 0, 'AUPR': 0, 'Loss': 0.9367399621032275}\n","2024-02-09 07:42:07,112 [INFO] loss of Node2Vec model : 0.9367399621032275\n","2024-02-09 07:42:07,143 [INFO] node embedding shape : torch.Size([66911, 32])\n","2024-02-09 07:42:07,150 [INFO] disease embedding shape : torch.Size([898, 32])\n","2024-02-09 07:42:07,154 [INFO] microbe embedding shape : torch.Size([898, 32])\n","2024-02-09 07:42:07,159 [INFO] microbe disease combination embedding shape : torch.Size([898, 64])\n"]}]},{"cell_type":"markdown","source":["# Classification"],"metadata":{"id":"T_hIMihJMts8"},"id":"T_hIMihJMts8"},{"cell_type":"markdown","source":["## Data"],"metadata":{"id":"ocxVXIz1MqLJ"},"id":"ocxVXIz1MqLJ"},{"cell_type":"code","source":["associations = get_associations()\n","y = torch.tensor(associations['increased'].tolist(), dtype=torch.float32).reshape(-1, 1).to(device)"],"metadata":{"id":"S2oiSKaEx1nl","executionInfo":{"status":"ok","timestamp":1707464527593,"user_tz":-210,"elapsed":30,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"S2oiSKaEx1nl","execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Train Test Split\n","train_indices, test_indices = train_test_sampler(y.shape[0], 0.7)\n","\n","data = SimplePytorchData(md_embed, y)\n","train_data = SimplePytorchData(md_embed[train_indices], y[train_indices])\n","test_data = SimplePytorchData(md_embed[test_indices], y[test_indices])"],"metadata":{"id":"DNdQlgzMMtHN","executionInfo":{"status":"ok","timestamp":1707464527593,"user_tz":-210,"elapsed":10,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b349382b-750d-4461-99f1-db01158650c5"},"id":"DNdQlgzMMtHN","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 07:42:07,197 [INFO] Initializing SimplePytorchData with X shape : torch.Size([898, 64]) and y shape : torch.Size([898, 1])\n","2024-02-09 07:42:07,201 [INFO] Initializing SimplePytorchData with X shape : torch.Size([628, 64]) and y shape : torch.Size([628, 1])\n","2024-02-09 07:42:07,204 [INFO] Initializing SimplePytorchData with X shape : torch.Size([270, 64]) and y shape : torch.Size([270, 1])\n"]}]},{"cell_type":"markdown","source":["## Classifier"],"metadata":{"id":"s0NauTO_SZLq"},"id":"s0NauTO_SZLq"},{"cell_type":"code","source":["simple_classifier_config = SimpleClassifierConfig()\n","simple_classifier_config.model_name = \"simple classifier\"\n","simple_classifier_config.input_dim = 64\n","simple_classifier_config.hidden_dim = 16\n","simple_classifier_config.output_dim = 1\n","simple_classifier_config.num_layers = 3\n","simple_classifier_config.dropout = 0.1"],"metadata":{"id":"BFTQsCl8M9bv","executionInfo":{"status":"ok","timestamp":1707464527593,"user_tz":-210,"elapsed":7,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"BFTQsCl8M9bv","execution_count":12,"outputs":[]},{"cell_type":"code","source":["mda_classifier = SimpleMDAClassifier(simple_classifier_config)"],"metadata":{"id":"1ciyBQ4QM_0U","executionInfo":{"status":"ok","timestamp":1707464527593,"user_tz":-210,"elapsed":7,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cc66a432-d621-40e1-f230-6d7895f6bdd6"},"id":"1ciyBQ4QM_0U","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 07:42:07,224 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 07:42:07,230 [INFO] Initial SimpleMLP with 64 input dimension, 16 hidden dimension, 1 \n","            output dimension, 3 layers and with 0.1 dropout\n"]}]},{"cell_type":"markdown","source":["## Optimizer"],"metadata":{"id":"jqfpkib2sjIv"},"id":"jqfpkib2sjIv"},{"cell_type":"code","source":["classifier_optimizer_config = OptimizerConfig()\n","classifier_optimizer_config.optimizer = torch.optim.Adam\n","classifier_optimizer_config.criterion = torch.nn.BCEWithLogitsLoss()\n","classifier_optimizer_config.lr = 0.01\n","classifier_optimizer_config.batch_size = 32\n","classifier_optimizer_config.n_epoch = 50\n","classifier_optimizer_config.exp_name = \"adam optimizer\"\n","classifier_optimizer_config.save = False\n","classifier_optimizer_config.save_path = None\n","classifier_optimizer_config.device = device\n","classifier_optimizer_config.report_size = 10  # batch to report ratio\n","classifier_optimizer_config.threshold = 0.5"],"metadata":{"id":"3D6yhiPpNEc8","executionInfo":{"status":"ok","timestamp":1707464527593,"user_tz":-210,"elapsed":6,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"3D6yhiPpNEc8","execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Train Test Approach Evaluation"],"metadata":{"id":"4iI5bMmJNQV3"},"id":"4iI5bMmJNQV3"},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"h24KnmDZNAgD"},"id":"h24KnmDZNAgD"},{"cell_type":"code","source":["train_result = SimpleTrainer().train(model=mda_classifier,\n","                                     data=train_data,\n","                                     config=classifier_optimizer_config)"],"metadata":{"id":"OqKrF7HmNFx1","executionInfo":{"status":"ok","timestamp":1707464530444,"user_tz":-210,"elapsed":2857,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"eb7f21c0-d0ed-47dc-cc4f-9512dbca86f4"},"id":"OqKrF7HmNFx1","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 07:42:07,251 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 07:42:07,252 [INFO] moving data and model to cuda\n","2024-02-09 07:42:07,786 [INFO] loss: 0.0212    [1,    10]\n","2024-02-09 07:42:07,820 [INFO] loss: 0.0189    [1,    20]\n","2024-02-09 07:42:07,853 [INFO] loss: 0.0170    [2,    10]\n","2024-02-09 07:42:07,889 [INFO] loss: 0.0168    [2,    20]\n","2024-02-09 07:42:07,932 [INFO] loss: 0.0140    [3,    10]\n","2024-02-09 07:42:07,964 [INFO] loss: 0.0150    [3,    20]\n","2024-02-09 07:42:07,999 [INFO] loss: 0.0145    [4,    10]\n","2024-02-09 07:42:08,034 [INFO] loss: 0.0127    [4,    20]\n","2024-02-09 07:42:08,070 [INFO] loss: 0.0125    [5,    10]\n","2024-02-09 07:42:08,093 [INFO] loss: 0.0126    [5,    20]\n","2024-02-09 07:42:08,116 [INFO] loss: 0.0118    [6,    10]\n","2024-02-09 07:42:08,139 [INFO] loss: 0.0125    [6,    20]\n","2024-02-09 07:42:08,161 [INFO] loss: 0.0116    [7,    10]\n","2024-02-09 07:42:08,184 [INFO] loss: 0.0120    [7,    20]\n","2024-02-09 07:42:08,209 [INFO] loss: 0.0118    [8,    10]\n","2024-02-09 07:42:08,233 [INFO] loss: 0.0121    [8,    20]\n","2024-02-09 07:42:08,257 [INFO] loss: 0.0113    [9,    10]\n","2024-02-09 07:42:08,283 [INFO] loss: 0.0117    [9,    20]\n","2024-02-09 07:42:08,306 [INFO] loss: 0.0107    [10,    10]\n","2024-02-09 07:42:08,328 [INFO] loss: 0.0116    [10,    20]\n","2024-02-09 07:42:08,350 [INFO] loss: 0.0108    [11,    10]\n","2024-02-09 07:42:08,372 [INFO] loss: 0.0116    [11,    20]\n","2024-02-09 07:42:08,395 [INFO] loss: 0.0114    [12,    10]\n","2024-02-09 07:42:08,417 [INFO] loss: 0.0102    [12,    20]\n","2024-02-09 07:42:08,440 [INFO] loss: 0.0095    [13,    10]\n","2024-02-09 07:42:08,463 [INFO] loss: 0.0113    [13,    20]\n","2024-02-09 07:42:08,485 [INFO] loss: 0.0100    [14,    10]\n","2024-02-09 07:42:08,508 [INFO] loss: 0.0106    [14,    20]\n","2024-02-09 07:42:08,542 [INFO] loss: 0.0101    [15,    10]\n","2024-02-09 07:42:08,565 [INFO] loss: 0.0095    [15,    20]\n","2024-02-09 07:42:08,588 [INFO] loss: 0.0102    [16,    10]\n","2024-02-09 07:42:08,610 [INFO] loss: 0.0104    [16,    20]\n","2024-02-09 07:42:08,633 [INFO] loss: 0.0100    [17,    10]\n","2024-02-09 07:42:08,657 [INFO] loss: 0.0088    [17,    20]\n","2024-02-09 07:42:08,680 [INFO] loss: 0.0083    [18,    10]\n","2024-02-09 07:42:08,703 [INFO] loss: 0.0092    [18,    20]\n","2024-02-09 07:42:08,727 [INFO] loss: 0.0085    [19,    10]\n","2024-02-09 07:42:08,753 [INFO] loss: 0.0095    [19,    20]\n","2024-02-09 07:42:08,776 [INFO] loss: 0.0090    [20,    10]\n","2024-02-09 07:42:08,799 [INFO] loss: 0.0081    [20,    20]\n","2024-02-09 07:42:08,822 [INFO] loss: 0.0083    [21,    10]\n","2024-02-09 07:42:08,844 [INFO] loss: 0.0076    [21,    20]\n","2024-02-09 07:42:08,866 [INFO] loss: 0.0077    [22,    10]\n","2024-02-09 07:42:08,888 [INFO] loss: 0.0079    [22,    20]\n","2024-02-09 07:42:08,910 [INFO] loss: 0.0093    [23,    10]\n","2024-02-09 07:42:08,933 [INFO] loss: 0.0068    [23,    20]\n","2024-02-09 07:42:08,962 [INFO] loss: 0.0078    [24,    10]\n","2024-02-09 07:42:08,985 [INFO] loss: 0.0098    [24,    20]\n","2024-02-09 07:42:09,008 [INFO] loss: 0.0088    [25,    10]\n","2024-02-09 07:42:09,030 [INFO] loss: 0.0078    [25,    20]\n","2024-02-09 07:42:09,053 [INFO] loss: 0.0079    [26,    10]\n","2024-02-09 07:42:09,075 [INFO] loss: 0.0082    [26,    20]\n","2024-02-09 07:42:09,097 [INFO] loss: 0.0074    [27,    10]\n","2024-02-09 07:42:09,120 [INFO] loss: 0.0096    [27,    20]\n","2024-02-09 07:42:09,142 [INFO] loss: 0.0097    [28,    10]\n","2024-02-09 07:42:09,165 [INFO] loss: 0.0081    [28,    20]\n","2024-02-09 07:42:09,187 [INFO] loss: 0.0071    [29,    10]\n","2024-02-09 07:42:09,210 [INFO] loss: 0.0083    [29,    20]\n","2024-02-09 07:42:09,234 [INFO] loss: 0.0077    [30,    10]\n","2024-02-09 07:42:09,259 [INFO] loss: 0.0078    [30,    20]\n","2024-02-09 07:42:09,282 [INFO] loss: 0.0081    [31,    10]\n","2024-02-09 07:42:09,304 [INFO] loss: 0.0066    [31,    20]\n","2024-02-09 07:42:09,326 [INFO] loss: 0.0053    [32,    10]\n","2024-02-09 07:42:09,347 [INFO] loss: 0.0084    [32,    20]\n","2024-02-09 07:42:09,370 [INFO] loss: 0.0078    [33,    10]\n","2024-02-09 07:42:09,393 [INFO] loss: 0.0061    [33,    20]\n","2024-02-09 07:42:09,425 [INFO] loss: 0.0072    [34,    10]\n","2024-02-09 07:42:09,448 [INFO] loss: 0.0073    [34,    20]\n","2024-02-09 07:42:09,470 [INFO] loss: 0.0070    [35,    10]\n","2024-02-09 07:42:09,492 [INFO] loss: 0.0083    [35,    20]\n","2024-02-09 07:42:09,514 [INFO] loss: 0.0077    [36,    10]\n","2024-02-09 07:42:09,536 [INFO] loss: 0.0076    [36,    20]\n","2024-02-09 07:42:09,558 [INFO] loss: 0.0081    [37,    10]\n","2024-02-09 07:42:09,580 [INFO] loss: 0.0062    [37,    20]\n","2024-02-09 07:42:09,603 [INFO] loss: 0.0073    [38,    10]\n","2024-02-09 07:42:09,626 [INFO] loss: 0.0075    [38,    20]\n","2024-02-09 07:42:09,649 [INFO] loss: 0.0051    [39,    10]\n","2024-02-09 07:42:09,671 [INFO] loss: 0.0071    [39,    20]\n","2024-02-09 07:42:09,692 [INFO] loss: 0.0058    [40,    10]\n","2024-02-09 07:42:09,714 [INFO] loss: 0.0096    [40,    20]\n","2024-02-09 07:42:09,736 [INFO] loss: 0.0073    [41,    10]\n","2024-02-09 07:42:09,757 [INFO] loss: 0.0070    [41,    20]\n","2024-02-09 07:42:09,780 [INFO] loss: 0.0067    [42,    10]\n","2024-02-09 07:42:09,802 [INFO] loss: 0.0074    [42,    20]\n","2024-02-09 07:42:09,827 [INFO] loss: 0.0074    [43,    10]\n","2024-02-09 07:42:09,849 [INFO] loss: 0.0066    [43,    20]\n","2024-02-09 07:42:09,870 [INFO] loss: 0.0079    [44,    10]\n","2024-02-09 07:42:09,892 [INFO] loss: 0.0067    [44,    20]\n","2024-02-09 07:42:09,914 [INFO] loss: 0.0082    [45,    10]\n","2024-02-09 07:42:09,935 [INFO] loss: 0.0072    [45,    20]\n","2024-02-09 07:42:09,957 [INFO] loss: 0.0075    [46,    10]\n","2024-02-09 07:42:09,986 [INFO] loss: 0.0089    [46,    20]\n","2024-02-09 07:42:10,011 [INFO] loss: 0.0097    [47,    10]\n","2024-02-09 07:42:10,033 [INFO] loss: 0.0068    [47,    20]\n","2024-02-09 07:42:10,055 [INFO] loss: 0.0064    [48,    10]\n","2024-02-09 07:42:10,076 [INFO] loss: 0.0068    [48,    20]\n","2024-02-09 07:42:10,098 [INFO] loss: 0.0074    [49,    10]\n","2024-02-09 07:42:10,119 [INFO] loss: 0.0057    [49,    20]\n","2024-02-09 07:42:10,141 [INFO] loss: 0.0072    [50,    10]\n","2024-02-09 07:42:10,162 [INFO] loss: 0.0067    [50,    20]\n","2024-02-09 07:42:10,207 [INFO] Result on Train Data : {'AUC': 0.9800851970181044, 'ACC': 0.9028662420382165, 'F1 Score': 0.9022712719684272, 'AUPR': 0, 'Loss': 0.2004528496414423}\n"]}]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"0eQGNWm_NMVG"},"id":"0eQGNWm_NMVG"},{"cell_type":"code","source":["test_result = SimpleTester().test(model=mda_classifier,\n","                                  data=test_data,\n","                                  config=classifier_optimizer_config)"],"metadata":{"id":"U05mXL_fNHpG","executionInfo":{"status":"ok","timestamp":1707464530445,"user_tz":-210,"elapsed":11,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"12f7f63b-18d4-4e9f-c3fa-0df8bce9b82a"},"id":"U05mXL_fNHpG","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 07:42:10,217 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 07:42:10,220 [INFO] moving data and model to cuda\n","2024-02-09 07:42:10,271 [INFO] Result on Test Data : {'AUC': 0.9349794238683128, 'ACC': 0.8555555555555555, 'F1 Score': 0.854836708529205, 'AUPR': 0, 'Loss': 0.49580668409665424}\n"]}]},{"cell_type":"code","source":["test_result.get_result()"],"metadata":{"id":"oqgiZQqRWWGF","executionInfo":{"status":"ok","timestamp":1707464530445,"user_tz":-210,"elapsed":7,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc68edaa-9c18-4864-e356-c7d8b3189a15"},"id":"oqgiZQqRWWGF","execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'AUC': 0.9349794238683128,\n"," 'ACC': 0.8555555555555555,\n"," 'F1 Score': 0.854836708529205,\n"," 'AUPR': 0,\n"," 'Loss': 0.49580668409665424}"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["## Cross Validation Evaluation"],"metadata":{"id":"ti8vEX_cNNwy"},"id":"ti8vEX_cNNwy"},{"cell_type":"code","execution_count":18,"id":"initial_id","metadata":{"id":"initial_id","executionInfo":{"status":"ok","timestamp":1707464544704,"user_tz":-210,"elapsed":14265,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"03543e89-8dd7-4116-c4f4-d7ac83e167b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 07:42:10,291 [INFO] Initializing SimpleMDAClassifierFactory with model : simple classifier\n","2024-02-09 07:42:10,294 [INFO] Initializing SimplePytorchDataTrainTestSplit\n","2024-02-09 07:42:10,297 [INFO] Start 5-fold Cross Validation with config : adam optimizer\n","2024-02-09 07:42:10,300 [INFO] ---- Fold 1 ----\n","2024-02-09 07:42:10,303 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-09 07:42:10,305 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-09 07:42:10,306 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 07:42:10,307 [INFO] Initial SimpleMLP with 64 input dimension, 16 hidden dimension, 1 \n","            output dimension, 3 layers and with 0.1 dropout\n","2024-02-09 07:42:10,309 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 07:42:10,315 [INFO] moving data and model to cuda\n","2024-02-09 07:42:10,349 [INFO] loss: 0.0217    [1,    10]\n","2024-02-09 07:42:10,372 [INFO] loss: 0.0204    [1,    20]\n","2024-02-09 07:42:10,406 [INFO] loss: 0.0189    [2,    10]\n","2024-02-09 07:42:10,429 [INFO] loss: 0.0173    [2,    20]\n","2024-02-09 07:42:10,459 [INFO] loss: 0.0162    [3,    10]\n","2024-02-09 07:42:10,481 [INFO] loss: 0.0153    [3,    20]\n","2024-02-09 07:42:10,511 [INFO] loss: 0.0146    [4,    10]\n","2024-02-09 07:42:10,535 [INFO] loss: 0.0141    [4,    20]\n","2024-02-09 07:42:10,564 [INFO] loss: 0.0143    [5,    10]\n","2024-02-09 07:42:10,590 [INFO] loss: 0.0136    [5,    20]\n","2024-02-09 07:42:10,618 [INFO] loss: 0.0126    [6,    10]\n","2024-02-09 07:42:10,640 [INFO] loss: 0.0133    [6,    20]\n","2024-02-09 07:42:10,668 [INFO] loss: 0.0118    [7,    10]\n","2024-02-09 07:42:10,689 [INFO] loss: 0.0126    [7,    20]\n","2024-02-09 07:42:10,717 [INFO] loss: 0.0119    [8,    10]\n","2024-02-09 07:42:10,739 [INFO] loss: 0.0110    [8,    20]\n","2024-02-09 07:42:10,766 [INFO] loss: 0.0117    [9,    10]\n","2024-02-09 07:42:10,787 [INFO] loss: 0.0102    [9,    20]\n","2024-02-09 07:42:10,814 [INFO] loss: 0.0117    [10,    10]\n","2024-02-09 07:42:10,835 [INFO] loss: 0.0112    [10,    20]\n","2024-02-09 07:42:10,862 [INFO] loss: 0.0103    [11,    10]\n","2024-02-09 07:42:10,883 [INFO] loss: 0.0120    [11,    20]\n","2024-02-09 07:42:10,910 [INFO] loss: 0.0096    [12,    10]\n","2024-02-09 07:42:10,936 [INFO] loss: 0.0104    [12,    20]\n","2024-02-09 07:42:10,963 [INFO] loss: 0.0088    [13,    10]\n","2024-02-09 07:42:10,987 [INFO] loss: 0.0121    [13,    20]\n","2024-02-09 07:42:11,020 [INFO] loss: 0.0090    [14,    10]\n","2024-02-09 07:42:11,042 [INFO] loss: 0.0116    [14,    20]\n","2024-02-09 07:42:11,069 [INFO] loss: 0.0090    [15,    10]\n","2024-02-09 07:42:11,090 [INFO] loss: 0.0106    [15,    20]\n","2024-02-09 07:42:11,117 [INFO] loss: 0.0082    [16,    10]\n","2024-02-09 07:42:11,142 [INFO] loss: 0.0095    [16,    20]\n","2024-02-09 07:42:11,170 [INFO] loss: 0.0084    [17,    10]\n","2024-02-09 07:42:11,191 [INFO] loss: 0.0104    [17,    20]\n","2024-02-09 07:42:11,219 [INFO] loss: 0.0092    [18,    10]\n","2024-02-09 07:42:11,241 [INFO] loss: 0.0090    [18,    20]\n","2024-02-09 07:42:11,269 [INFO] loss: 0.0087    [19,    10]\n","2024-02-09 07:42:11,291 [INFO] loss: 0.0096    [19,    20]\n","2024-02-09 07:42:11,317 [INFO] loss: 0.0099    [20,    10]\n","2024-02-09 07:42:11,338 [INFO] loss: 0.0090    [20,    20]\n","2024-02-09 07:42:11,365 [INFO] loss: 0.0087    [21,    10]\n","2024-02-09 07:42:11,387 [INFO] loss: 0.0083    [21,    20]\n","2024-02-09 07:42:11,415 [INFO] loss: 0.0084    [22,    10]\n","2024-02-09 07:42:11,438 [INFO] loss: 0.0098    [22,    20]\n","2024-02-09 07:42:11,470 [INFO] loss: 0.0078    [23,    10]\n","2024-02-09 07:42:11,491 [INFO] loss: 0.0093    [23,    20]\n","2024-02-09 07:42:11,517 [INFO] loss: 0.0072    [24,    10]\n","2024-02-09 07:42:11,542 [INFO] loss: 0.0081    [24,    20]\n","2024-02-09 07:42:11,569 [INFO] loss: 0.0063    [25,    10]\n","2024-02-09 07:42:11,592 [INFO] loss: 0.0082    [25,    20]\n","2024-02-09 07:42:11,619 [INFO] loss: 0.0077    [26,    10]\n","2024-02-09 07:42:11,644 [INFO] loss: 0.0098    [26,    20]\n","2024-02-09 07:42:11,672 [INFO] loss: 0.0092    [27,    10]\n","2024-02-09 07:42:11,693 [INFO] loss: 0.0089    [27,    20]\n","2024-02-09 07:42:11,720 [INFO] loss: 0.0075    [28,    10]\n","2024-02-09 07:42:11,742 [INFO] loss: 0.0073    [28,    20]\n","2024-02-09 07:42:11,769 [INFO] loss: 0.0072    [29,    10]\n","2024-02-09 07:42:11,792 [INFO] loss: 0.0101    [29,    20]\n","2024-02-09 07:42:11,820 [INFO] loss: 0.0087    [30,    10]\n","2024-02-09 07:42:11,842 [INFO] loss: 0.0086    [30,    20]\n","2024-02-09 07:42:11,868 [INFO] loss: 0.0082    [31,    10]\n","2024-02-09 07:42:11,889 [INFO] loss: 0.0073    [31,    20]\n","2024-02-09 07:42:11,916 [INFO] loss: 0.0072    [32,    10]\n","2024-02-09 07:42:11,937 [INFO] loss: 0.0090    [32,    20]\n","2024-02-09 07:42:11,964 [INFO] loss: 0.0068    [33,    10]\n","2024-02-09 07:42:11,985 [INFO] loss: 0.0088    [33,    20]\n","2024-02-09 07:42:12,016 [INFO] loss: 0.0081    [34,    10]\n","2024-02-09 07:42:12,044 [INFO] loss: 0.0061    [34,    20]\n","2024-02-09 07:42:12,071 [INFO] loss: 0.0076    [35,    10]\n","2024-02-09 07:42:12,096 [INFO] loss: 0.0069    [35,    20]\n","2024-02-09 07:42:12,123 [INFO] loss: 0.0078    [36,    10]\n","2024-02-09 07:42:12,147 [INFO] loss: 0.0065    [36,    20]\n","2024-02-09 07:42:12,175 [INFO] loss: 0.0078    [37,    10]\n","2024-02-09 07:42:12,198 [INFO] loss: 0.0076    [37,    20]\n","2024-02-09 07:42:12,226 [INFO] loss: 0.0095    [38,    10]\n","2024-02-09 07:42:12,250 [INFO] loss: 0.0064    [38,    20]\n","2024-02-09 07:42:12,277 [INFO] loss: 0.0074    [39,    10]\n","2024-02-09 07:42:12,299 [INFO] loss: 0.0079    [39,    20]\n","2024-02-09 07:42:12,327 [INFO] loss: 0.0075    [40,    10]\n","2024-02-09 07:42:12,348 [INFO] loss: 0.0065    [40,    20]\n","2024-02-09 07:42:12,375 [INFO] loss: 0.0052    [41,    10]\n","2024-02-09 07:42:12,397 [INFO] loss: 0.0072    [41,    20]\n","2024-02-09 07:42:12,424 [INFO] loss: 0.0064    [42,    10]\n","2024-02-09 07:42:12,446 [INFO] loss: 0.0066    [42,    20]\n","2024-02-09 07:42:12,472 [INFO] loss: 0.0084    [43,    10]\n","2024-02-09 07:42:12,494 [INFO] loss: 0.0066    [43,    20]\n","2024-02-09 07:42:12,521 [INFO] loss: 0.0055    [44,    10]\n","2024-02-09 07:42:12,543 [INFO] loss: 0.0068    [44,    20]\n","2024-02-09 07:42:12,573 [INFO] loss: 0.0063    [45,    10]\n","2024-02-09 07:42:12,595 [INFO] loss: 0.0061    [45,    20]\n","2024-02-09 07:42:12,623 [INFO] loss: 0.0064    [46,    10]\n","2024-02-09 07:42:12,645 [INFO] loss: 0.0081    [46,    20]\n","2024-02-09 07:42:12,674 [INFO] loss: 0.0068    [47,    10]\n","2024-02-09 07:42:12,696 [INFO] loss: 0.0070    [47,    20]\n","2024-02-09 07:42:12,724 [INFO] loss: 0.0053    [48,    10]\n","2024-02-09 07:42:12,749 [INFO] loss: 0.0066    [48,    20]\n","2024-02-09 07:42:12,778 [INFO] loss: 0.0076    [49,    10]\n","2024-02-09 07:42:12,803 [INFO] loss: 0.0062    [49,    20]\n","2024-02-09 07:42:12,831 [INFO] loss: 0.0044    [50,    10]\n","2024-02-09 07:42:12,853 [INFO] loss: 0.0079    [50,    20]\n","2024-02-09 07:42:12,904 [INFO] Result on Train Data : {'AUC': 0.9840475748289844, 'ACC': 0.9276773296244785, 'F1 Score': 0.9274177266303251, 'AUPR': 0, 'Loss': 0.159493381238502}\n","2024-02-09 07:42:12,905 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 07:42:12,910 [INFO] moving data and model to cuda\n","2024-02-09 07:42:12,932 [INFO] Result on Test Data : {'AUC': 0.8702800700175045, 'ACC': 0.7877094972067039, 'F1 Score': 0.7877028714107366, 'AUPR': 0, 'Loss': 0.9140482793251673}\n","2024-02-09 07:42:12,933 [INFO] Result of fold 1 : {'AUC': 0.8702800700175045, 'ACC': 0.7877094972067039, 'F1 Score': 0.7877028714107366, 'AUPR': 0, 'Loss': 0.9140482793251673}\n","2024-02-09 07:42:12,934 [INFO] ---- Fold 2 ----\n","2024-02-09 07:42:12,937 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-09 07:42:12,940 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-09 07:42:12,941 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 07:42:12,942 [INFO] Initial SimpleMLP with 64 input dimension, 16 hidden dimension, 1 \n","            output dimension, 3 layers and with 0.1 dropout\n","2024-02-09 07:42:12,945 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 07:42:12,946 [INFO] moving data and model to cuda\n","2024-02-09 07:42:12,975 [INFO] loss: 0.0215    [1,    10]\n","2024-02-09 07:42:12,999 [INFO] loss: 0.0205    [1,    20]\n","2024-02-09 07:42:13,027 [INFO] loss: 0.0194    [2,    10]\n","2024-02-09 07:42:13,055 [INFO] loss: 0.0167    [2,    20]\n","2024-02-09 07:42:13,086 [INFO] loss: 0.0164    [3,    10]\n","2024-02-09 07:42:13,113 [INFO] loss: 0.0156    [3,    20]\n","2024-02-09 07:42:13,141 [INFO] loss: 0.0144    [4,    10]\n","2024-02-09 07:42:13,163 [INFO] loss: 0.0136    [4,    20]\n","2024-02-09 07:42:13,190 [INFO] loss: 0.0140    [5,    10]\n","2024-02-09 07:42:13,212 [INFO] loss: 0.0133    [5,    20]\n","2024-02-09 07:42:13,241 [INFO] loss: 0.0128    [6,    10]\n","2024-02-09 07:42:13,263 [INFO] loss: 0.0136    [6,    20]\n","2024-02-09 07:42:13,292 [INFO] loss: 0.0118    [7,    10]\n","2024-02-09 07:42:13,313 [INFO] loss: 0.0137    [7,    20]\n","2024-02-09 07:42:13,340 [INFO] loss: 0.0116    [8,    10]\n","2024-02-09 07:42:13,366 [INFO] loss: 0.0131    [8,    20]\n","2024-02-09 07:42:13,394 [INFO] loss: 0.0127    [9,    10]\n","2024-02-09 07:42:13,416 [INFO] loss: 0.0125    [9,    20]\n","2024-02-09 07:42:13,443 [INFO] loss: 0.0101    [10,    10]\n","2024-02-09 07:42:13,463 [INFO] loss: 0.0118    [10,    20]\n","2024-02-09 07:42:13,490 [INFO] loss: 0.0110    [11,    10]\n","2024-02-09 07:42:13,512 [INFO] loss: 0.0111    [11,    20]\n","2024-02-09 07:42:13,540 [INFO] loss: 0.0113    [12,    10]\n","2024-02-09 07:42:13,562 [INFO] loss: 0.0118    [12,    20]\n","2024-02-09 07:42:13,590 [INFO] loss: 0.0108    [13,    10]\n","2024-02-09 07:42:13,614 [INFO] loss: 0.0115    [13,    20]\n","2024-02-09 07:42:13,641 [INFO] loss: 0.0112    [14,    10]\n","2024-02-09 07:42:13,664 [INFO] loss: 0.0103    [14,    20]\n","2024-02-09 07:42:13,691 [INFO] loss: 0.0105    [15,    10]\n","2024-02-09 07:42:13,712 [INFO] loss: 0.0106    [15,    20]\n","2024-02-09 07:42:13,740 [INFO] loss: 0.0099    [16,    10]\n","2024-02-09 07:42:13,763 [INFO] loss: 0.0100    [16,    20]\n","2024-02-09 07:42:13,790 [INFO] loss: 0.0109    [17,    10]\n","2024-02-09 07:42:13,812 [INFO] loss: 0.0096    [17,    20]\n","2024-02-09 07:42:13,839 [INFO] loss: 0.0085    [18,    10]\n","2024-02-09 07:42:13,861 [INFO] loss: 0.0097    [18,    20]\n","2024-02-09 07:42:13,896 [INFO] loss: 0.0102    [19,    10]\n","2024-02-09 07:42:13,921 [INFO] loss: 0.0088    [19,    20]\n","2024-02-09 07:42:13,950 [INFO] loss: 0.0108    [20,    10]\n","2024-02-09 07:42:13,974 [INFO] loss: 0.0087    [20,    20]\n","2024-02-09 07:42:14,004 [INFO] loss: 0.0081    [21,    10]\n","2024-02-09 07:42:14,026 [INFO] loss: 0.0105    [21,    20]\n","2024-02-09 07:42:14,055 [INFO] loss: 0.0099    [22,    10]\n","2024-02-09 07:42:14,081 [INFO] loss: 0.0106    [22,    20]\n","2024-02-09 07:42:14,114 [INFO] loss: 0.0105    [23,    10]\n","2024-02-09 07:42:14,136 [INFO] loss: 0.0102    [23,    20]\n","2024-02-09 07:42:14,164 [INFO] loss: 0.0085    [24,    10]\n","2024-02-09 07:42:14,186 [INFO] loss: 0.0098    [24,    20]\n","2024-02-09 07:42:14,214 [INFO] loss: 0.0091    [25,    10]\n","2024-02-09 07:42:14,237 [INFO] loss: 0.0095    [25,    20]\n","2024-02-09 07:42:14,265 [INFO] loss: 0.0077    [26,    10]\n","2024-02-09 07:42:14,287 [INFO] loss: 0.0100    [26,    20]\n","2024-02-09 07:42:14,315 [INFO] loss: 0.0088    [27,    10]\n","2024-02-09 07:42:14,337 [INFO] loss: 0.0091    [27,    20]\n","2024-02-09 07:42:14,364 [INFO] loss: 0.0097    [28,    10]\n","2024-02-09 07:42:14,386 [INFO] loss: 0.0078    [28,    20]\n","2024-02-09 07:42:14,415 [INFO] loss: 0.0098    [29,    10]\n","2024-02-09 07:42:14,438 [INFO] loss: 0.0084    [29,    20]\n","2024-02-09 07:42:14,466 [INFO] loss: 0.0092    [30,    10]\n","2024-02-09 07:42:14,488 [INFO] loss: 0.0078    [30,    20]\n","2024-02-09 07:42:14,517 [INFO] loss: 0.0085    [31,    10]\n","2024-02-09 07:42:14,539 [INFO] loss: 0.0088    [31,    20]\n","2024-02-09 07:42:14,569 [INFO] loss: 0.0100    [32,    10]\n","2024-02-09 07:42:14,592 [INFO] loss: 0.0090    [32,    20]\n","2024-02-09 07:42:14,621 [INFO] loss: 0.0085    [33,    10]\n","2024-02-09 07:42:14,643 [INFO] loss: 0.0088    [33,    20]\n","2024-02-09 07:42:14,673 [INFO] loss: 0.0063    [34,    10]\n","2024-02-09 07:42:14,695 [INFO] loss: 0.0091    [34,    20]\n","2024-02-09 07:42:14,724 [INFO] loss: 0.0079    [35,    10]\n","2024-02-09 07:42:14,750 [INFO] loss: 0.0079    [35,    20]\n","2024-02-09 07:42:14,778 [INFO] loss: 0.0076    [36,    10]\n","2024-02-09 07:42:14,800 [INFO] loss: 0.0067    [36,    20]\n","2024-02-09 07:42:14,828 [INFO] loss: 0.0072    [37,    10]\n","2024-02-09 07:42:14,851 [INFO] loss: 0.0071    [37,    20]\n","2024-02-09 07:42:14,881 [INFO] loss: 0.0081    [38,    10]\n","2024-02-09 07:42:14,905 [INFO] loss: 0.0091    [38,    20]\n","2024-02-09 07:42:14,933 [INFO] loss: 0.0076    [39,    10]\n","2024-02-09 07:42:14,957 [INFO] loss: 0.0090    [39,    20]\n","2024-02-09 07:42:14,985 [INFO] loss: 0.0078    [40,    10]\n","2024-02-09 07:42:15,008 [INFO] loss: 0.0093    [40,    20]\n","2024-02-09 07:42:15,035 [INFO] loss: 0.0096    [41,    10]\n","2024-02-09 07:42:15,057 [INFO] loss: 0.0085    [41,    20]\n","2024-02-09 07:42:15,085 [INFO] loss: 0.0089    [42,    10]\n","2024-02-09 07:42:15,110 [INFO] loss: 0.0098    [42,    20]\n","2024-02-09 07:42:15,147 [INFO] loss: 0.0083    [43,    10]\n","2024-02-09 07:42:15,169 [INFO] loss: 0.0096    [43,    20]\n","2024-02-09 07:42:15,198 [INFO] loss: 0.0084    [44,    10]\n","2024-02-09 07:42:15,220 [INFO] loss: 0.0082    [44,    20]\n","2024-02-09 07:42:15,251 [INFO] loss: 0.0081    [45,    10]\n","2024-02-09 07:42:15,273 [INFO] loss: 0.0099    [45,    20]\n","2024-02-09 07:42:15,301 [INFO] loss: 0.0091    [46,    10]\n","2024-02-09 07:42:15,324 [INFO] loss: 0.0083    [46,    20]\n","2024-02-09 07:42:15,354 [INFO] loss: 0.0084    [47,    10]\n","2024-02-09 07:42:15,376 [INFO] loss: 0.0077    [47,    20]\n","2024-02-09 07:42:15,405 [INFO] loss: 0.0083    [48,    10]\n","2024-02-09 07:42:15,427 [INFO] loss: 0.0080    [48,    20]\n","2024-02-09 07:42:15,455 [INFO] loss: 0.0072    [49,    10]\n","2024-02-09 07:42:15,479 [INFO] loss: 0.0083    [49,    20]\n","2024-02-09 07:42:15,507 [INFO] loss: 0.0059    [50,    10]\n","2024-02-09 07:42:15,530 [INFO] loss: 0.0094    [50,    20]\n","2024-02-09 07:42:15,582 [INFO] Result on Train Data : {'AUC': 0.9731552458381726, 'ACC': 0.8720445062586927, 'F1 Score': 0.8708551347130027, 'AUPR': 0, 'Loss': 0.212973320937675}\n","2024-02-09 07:42:15,584 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 07:42:15,586 [INFO] moving data and model to cuda\n","2024-02-09 07:42:15,609 [INFO] Result on Test Data : {'AUC': 0.8215909090909091, 'ACC': 0.7430167597765364, 'F1 Score': 0.7256796375266525, 'AUPR': 0, 'Loss': 0.6112666428089142}\n","2024-02-09 07:42:15,610 [INFO] Result of fold 2 : {'AUC': 0.8215909090909091, 'ACC': 0.7430167597765364, 'F1 Score': 0.7256796375266525, 'AUPR': 0, 'Loss': 0.6112666428089142}\n","2024-02-09 07:42:15,613 [INFO] ---- Fold 3 ----\n","2024-02-09 07:42:15,615 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-09 07:42:15,619 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-09 07:42:15,621 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 07:42:15,622 [INFO] Initial SimpleMLP with 64 input dimension, 16 hidden dimension, 1 \n","            output dimension, 3 layers and with 0.1 dropout\n","2024-02-09 07:42:15,624 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 07:42:15,625 [INFO] moving data and model to cuda\n","2024-02-09 07:42:15,650 [INFO] loss: 0.0215    [1,    10]\n","2024-02-09 07:42:15,675 [INFO] loss: 0.0204    [1,    20]\n","2024-02-09 07:42:15,702 [INFO] loss: 0.0187    [2,    10]\n","2024-02-09 07:42:15,726 [INFO] loss: 0.0181    [2,    20]\n","2024-02-09 07:42:15,755 [INFO] loss: 0.0154    [3,    10]\n","2024-02-09 07:42:15,778 [INFO] loss: 0.0157    [3,    20]\n","2024-02-09 07:42:15,807 [INFO] loss: 0.0149    [4,    10]\n","2024-02-09 07:42:15,830 [INFO] loss: 0.0151    [4,    20]\n","2024-02-09 07:42:15,857 [INFO] loss: 0.0133    [5,    10]\n","2024-02-09 07:42:15,878 [INFO] loss: 0.0142    [5,    20]\n","2024-02-09 07:42:15,905 [INFO] loss: 0.0123    [6,    10]\n","2024-02-09 07:42:15,926 [INFO] loss: 0.0134    [6,    20]\n","2024-02-09 07:42:15,956 [INFO] loss: 0.0135    [7,    10]\n","2024-02-09 07:42:15,977 [INFO] loss: 0.0121    [7,    20]\n","2024-02-09 07:42:16,005 [INFO] loss: 0.0132    [8,    10]\n","2024-02-09 07:42:16,026 [INFO] loss: 0.0118    [8,    20]\n","2024-02-09 07:42:16,054 [INFO] loss: 0.0118    [9,    10]\n","2024-02-09 07:42:16,082 [INFO] loss: 0.0125    [9,    20]\n","2024-02-09 07:42:16,109 [INFO] loss: 0.0126    [10,    10]\n","2024-02-09 07:42:16,132 [INFO] loss: 0.0126    [10,    20]\n","2024-02-09 07:42:16,168 [INFO] loss: 0.0102    [11,    10]\n","2024-02-09 07:42:16,190 [INFO] loss: 0.0126    [11,    20]\n","2024-02-09 07:42:16,217 [INFO] loss: 0.0116    [12,    10]\n","2024-02-09 07:42:16,239 [INFO] loss: 0.0128    [12,    20]\n","2024-02-09 07:42:16,267 [INFO] loss: 0.0118    [13,    10]\n","2024-02-09 07:42:16,289 [INFO] loss: 0.0109    [13,    20]\n","2024-02-09 07:42:16,316 [INFO] loss: 0.0110    [14,    10]\n","2024-02-09 07:42:16,338 [INFO] loss: 0.0117    [14,    20]\n","2024-02-09 07:42:16,365 [INFO] loss: 0.0121    [15,    10]\n","2024-02-09 07:42:16,387 [INFO] loss: 0.0111    [15,    20]\n","2024-02-09 07:42:16,415 [INFO] loss: 0.0108    [16,    10]\n","2024-02-09 07:42:16,438 [INFO] loss: 0.0109    [16,    20]\n","2024-02-09 07:42:16,465 [INFO] loss: 0.0120    [17,    10]\n","2024-02-09 07:42:16,486 [INFO] loss: 0.0105    [17,    20]\n","2024-02-09 07:42:16,514 [INFO] loss: 0.0100    [18,    10]\n","2024-02-09 07:42:16,535 [INFO] loss: 0.0102    [18,    20]\n","2024-02-09 07:42:16,564 [INFO] loss: 0.0097    [19,    10]\n","2024-02-09 07:42:16,586 [INFO] loss: 0.0103    [19,    20]\n","2024-02-09 07:42:16,614 [INFO] loss: 0.0090    [20,    10]\n","2024-02-09 07:42:16,636 [INFO] loss: 0.0103    [20,    20]\n","2024-02-09 07:42:16,664 [INFO] loss: 0.0107    [21,    10]\n","2024-02-09 07:42:16,689 [INFO] loss: 0.0085    [21,    20]\n","2024-02-09 07:42:16,716 [INFO] loss: 0.0088    [22,    10]\n","2024-02-09 07:42:16,739 [INFO] loss: 0.0095    [22,    20]\n","2024-02-09 07:42:16,766 [INFO] loss: 0.0079    [23,    10]\n","2024-02-09 07:42:16,787 [INFO] loss: 0.0099    [23,    20]\n","2024-02-09 07:42:16,815 [INFO] loss: 0.0098    [24,    10]\n","2024-02-09 07:42:16,837 [INFO] loss: 0.0094    [24,    20]\n","2024-02-09 07:42:16,864 [INFO] loss: 0.0079    [25,    10]\n","2024-02-09 07:42:16,886 [INFO] loss: 0.0092    [25,    20]\n","2024-02-09 07:42:16,914 [INFO] loss: 0.0078    [26,    10]\n","2024-02-09 07:42:16,936 [INFO] loss: 0.0088    [26,    20]\n","2024-02-09 07:42:16,964 [INFO] loss: 0.0088    [27,    10]\n","2024-02-09 07:42:16,993 [INFO] loss: 0.0099    [27,    20]\n","2024-02-09 07:42:17,022 [INFO] loss: 0.0083    [28,    10]\n","2024-02-09 07:42:17,045 [INFO] loss: 0.0081    [28,    20]\n","2024-02-09 07:42:17,074 [INFO] loss: 0.0076    [29,    10]\n","2024-02-09 07:42:17,096 [INFO] loss: 0.0087    [29,    20]\n","2024-02-09 07:42:17,125 [INFO] loss: 0.0074    [30,    10]\n","2024-02-09 07:42:17,148 [INFO] loss: 0.0083    [30,    20]\n","2024-02-09 07:42:17,182 [INFO] loss: 0.0083    [31,    10]\n","2024-02-09 07:42:17,208 [INFO] loss: 0.0073    [31,    20]\n","2024-02-09 07:42:17,236 [INFO] loss: 0.0074    [32,    10]\n","2024-02-09 07:42:17,260 [INFO] loss: 0.0100    [32,    20]\n","2024-02-09 07:42:17,291 [INFO] loss: 0.0099    [33,    10]\n","2024-02-09 07:42:17,313 [INFO] loss: 0.0079    [33,    20]\n","2024-02-09 07:42:17,343 [INFO] loss: 0.0091    [34,    10]\n","2024-02-09 07:42:17,364 [INFO] loss: 0.0077    [34,    20]\n","2024-02-09 07:42:17,393 [INFO] loss: 0.0081    [35,    10]\n","2024-02-09 07:42:17,415 [INFO] loss: 0.0079    [35,    20]\n","2024-02-09 07:42:17,442 [INFO] loss: 0.0062    [36,    10]\n","2024-02-09 07:42:17,464 [INFO] loss: 0.0076    [36,    20]\n","2024-02-09 07:42:17,495 [INFO] loss: 0.0078    [37,    10]\n","2024-02-09 07:42:17,520 [INFO] loss: 0.0078    [37,    20]\n","2024-02-09 07:42:17,548 [INFO] loss: 0.0075    [38,    10]\n","2024-02-09 07:42:17,570 [INFO] loss: 0.0075    [38,    20]\n","2024-02-09 07:42:17,600 [INFO] loss: 0.0076    [39,    10]\n","2024-02-09 07:42:17,623 [INFO] loss: 0.0081    [39,    20]\n","2024-02-09 07:42:17,651 [INFO] loss: 0.0077    [40,    10]\n","2024-02-09 07:42:17,674 [INFO] loss: 0.0084    [40,    20]\n","2024-02-09 07:42:17,702 [INFO] loss: 0.0075    [41,    10]\n","2024-02-09 07:42:17,726 [INFO] loss: 0.0082    [41,    20]\n","2024-02-09 07:42:17,754 [INFO] loss: 0.0082    [42,    10]\n","2024-02-09 07:42:17,776 [INFO] loss: 0.0086    [42,    20]\n","2024-02-09 07:42:17,805 [INFO] loss: 0.0089    [43,    10]\n","2024-02-09 07:42:17,827 [INFO] loss: 0.0082    [43,    20]\n","2024-02-09 07:42:17,855 [INFO] loss: 0.0087    [44,    10]\n","2024-02-09 07:42:17,876 [INFO] loss: 0.0093    [44,    20]\n","2024-02-09 07:42:17,906 [INFO] loss: 0.0100    [45,    10]\n","2024-02-09 07:42:17,927 [INFO] loss: 0.0072    [45,    20]\n","2024-02-09 07:42:17,955 [INFO] loss: 0.0083    [46,    10]\n","2024-02-09 07:42:17,978 [INFO] loss: 0.0091    [46,    20]\n","2024-02-09 07:42:18,006 [INFO] loss: 0.0100    [47,    10]\n","2024-02-09 07:42:18,032 [INFO] loss: 0.0082    [47,    20]\n","2024-02-09 07:42:18,059 [INFO] loss: 0.0086    [48,    10]\n","2024-02-09 07:42:18,086 [INFO] loss: 0.0082    [48,    20]\n","2024-02-09 07:42:18,126 [INFO] loss: 0.0089    [49,    10]\n","2024-02-09 07:42:18,157 [INFO] loss: 0.0087    [49,    20]\n","2024-02-09 07:42:18,199 [INFO] loss: 0.0058    [50,    10]\n","2024-02-09 07:42:18,230 [INFO] loss: 0.0080    [50,    20]\n","2024-02-09 07:42:18,312 [INFO] Result on Train Data : {'AUC': 0.9705843663432223, 'ACC': 0.9040333796940194, 'F1 Score': 0.9036037593970354, 'AUPR': 0, 'Loss': 0.22234412865794223}\n","2024-02-09 07:42:18,314 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 07:42:18,315 [INFO] moving data and model to cuda\n","2024-02-09 07:42:18,347 [INFO] Result on Test Data : {'AUC': 0.9061719140429785, 'ACC': 0.8324022346368715, 'F1 Score': 0.832355144855145, 'AUPR': 0, 'Loss': 0.5411765525738398}\n","2024-02-09 07:42:18,349 [INFO] Result of fold 3 : {'AUC': 0.9061719140429785, 'ACC': 0.8324022346368715, 'F1 Score': 0.832355144855145, 'AUPR': 0, 'Loss': 0.5411765525738398}\n","2024-02-09 07:42:18,351 [INFO] ---- Fold 4 ----\n","2024-02-09 07:42:18,354 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-09 07:42:18,357 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-09 07:42:18,360 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 07:42:18,362 [INFO] Initial SimpleMLP with 64 input dimension, 16 hidden dimension, 1 \n","            output dimension, 3 layers and with 0.1 dropout\n","2024-02-09 07:42:18,365 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 07:42:18,366 [INFO] moving data and model to cuda\n","2024-02-09 07:42:18,407 [INFO] loss: 0.0211    [1,    10]\n","2024-02-09 07:42:18,438 [INFO] loss: 0.0203    [1,    20]\n","2024-02-09 07:42:18,474 [INFO] loss: 0.0175    [2,    10]\n","2024-02-09 07:42:18,505 [INFO] loss: 0.0168    [2,    20]\n","2024-02-09 07:42:18,544 [INFO] loss: 0.0147    [3,    10]\n","2024-02-09 07:42:18,573 [INFO] loss: 0.0146    [3,    20]\n","2024-02-09 07:42:18,610 [INFO] loss: 0.0145    [4,    10]\n","2024-02-09 07:42:18,640 [INFO] loss: 0.0134    [4,    20]\n","2024-02-09 07:42:18,675 [INFO] loss: 0.0134    [5,    10]\n","2024-02-09 07:42:18,703 [INFO] loss: 0.0137    [5,    20]\n","2024-02-09 07:42:18,737 [INFO] loss: 0.0109    [6,    10]\n","2024-02-09 07:42:18,767 [INFO] loss: 0.0132    [6,    20]\n","2024-02-09 07:42:18,804 [INFO] loss: 0.0110    [7,    10]\n","2024-02-09 07:42:18,829 [INFO] loss: 0.0124    [7,    20]\n","2024-02-09 07:42:18,861 [INFO] loss: 0.0106    [8,    10]\n","2024-02-09 07:42:18,886 [INFO] loss: 0.0127    [8,    20]\n","2024-02-09 07:42:18,919 [INFO] loss: 0.0132    [9,    10]\n","2024-02-09 07:42:18,945 [INFO] loss: 0.0100    [9,    20]\n","2024-02-09 07:42:18,977 [INFO] loss: 0.0112    [10,    10]\n","2024-02-09 07:42:19,003 [INFO] loss: 0.0110    [10,    20]\n","2024-02-09 07:42:19,035 [INFO] loss: 0.0093    [11,    10]\n","2024-02-09 07:42:19,062 [INFO] loss: 0.0111    [11,    20]\n","2024-02-09 07:42:19,095 [INFO] loss: 0.0105    [12,    10]\n","2024-02-09 07:42:19,121 [INFO] loss: 0.0107    [12,    20]\n","2024-02-09 07:42:19,155 [INFO] loss: 0.0092    [13,    10]\n","2024-02-09 07:42:19,183 [INFO] loss: 0.0102    [13,    20]\n","2024-02-09 07:42:19,223 [INFO] loss: 0.0082    [14,    10]\n","2024-02-09 07:42:19,256 [INFO] loss: 0.0098    [14,    20]\n","2024-02-09 07:42:19,304 [INFO] loss: 0.0088    [15,    10]\n","2024-02-09 07:42:19,330 [INFO] loss: 0.0100    [15,    20]\n","2024-02-09 07:42:19,369 [INFO] loss: 0.0096    [16,    10]\n","2024-02-09 07:42:19,401 [INFO] loss: 0.0092    [16,    20]\n","2024-02-09 07:42:19,437 [INFO] loss: 0.0084    [17,    10]\n","2024-02-09 07:42:19,464 [INFO] loss: 0.0103    [17,    20]\n","2024-02-09 07:42:19,502 [INFO] loss: 0.0084    [18,    10]\n","2024-02-09 07:42:19,529 [INFO] loss: 0.0098    [18,    20]\n","2024-02-09 07:42:19,564 [INFO] loss: 0.0096    [19,    10]\n","2024-02-09 07:42:19,596 [INFO] loss: 0.0084    [19,    20]\n","2024-02-09 07:42:19,634 [INFO] loss: 0.0097    [20,    10]\n","2024-02-09 07:42:19,663 [INFO] loss: 0.0087    [20,    20]\n","2024-02-09 07:42:19,700 [INFO] loss: 0.0085    [21,    10]\n","2024-02-09 07:42:19,729 [INFO] loss: 0.0095    [21,    20]\n","2024-02-09 07:42:19,765 [INFO] loss: 0.0072    [22,    10]\n","2024-02-09 07:42:19,796 [INFO] loss: 0.0090    [22,    20]\n","2024-02-09 07:42:19,833 [INFO] loss: 0.0084    [23,    10]\n","2024-02-09 07:42:19,863 [INFO] loss: 0.0095    [23,    20]\n","2024-02-09 07:42:19,898 [INFO] loss: 0.0088    [24,    10]\n","2024-02-09 07:42:19,927 [INFO] loss: 0.0089    [24,    20]\n","2024-02-09 07:42:19,966 [INFO] loss: 0.0084    [25,    10]\n","2024-02-09 07:42:19,995 [INFO] loss: 0.0082    [25,    20]\n","2024-02-09 07:42:20,032 [INFO] loss: 0.0091    [26,    10]\n","2024-02-09 07:42:20,061 [INFO] loss: 0.0080    [26,    20]\n","2024-02-09 07:42:20,096 [INFO] loss: 0.0087    [27,    10]\n","2024-02-09 07:42:20,124 [INFO] loss: 0.0076    [27,    20]\n","2024-02-09 07:42:20,161 [INFO] loss: 0.0077    [28,    10]\n","2024-02-09 07:42:20,190 [INFO] loss: 0.0074    [28,    20]\n","2024-02-09 07:42:20,226 [INFO] loss: 0.0084    [29,    10]\n","2024-02-09 07:42:20,255 [INFO] loss: 0.0076    [29,    20]\n","2024-02-09 07:42:20,293 [INFO] loss: 0.0083    [30,    10]\n","2024-02-09 07:42:20,331 [INFO] loss: 0.0090    [30,    20]\n","2024-02-09 07:42:20,374 [INFO] loss: 0.0078    [31,    10]\n","2024-02-09 07:42:20,408 [INFO] loss: 0.0073    [31,    20]\n","2024-02-09 07:42:20,445 [INFO] loss: 0.0078    [32,    10]\n","2024-02-09 07:42:20,478 [INFO] loss: 0.0075    [32,    20]\n","2024-02-09 07:42:20,517 [INFO] loss: 0.0079    [33,    10]\n","2024-02-09 07:42:20,547 [INFO] loss: 0.0076    [33,    20]\n","2024-02-09 07:42:20,588 [INFO] loss: 0.0075    [34,    10]\n","2024-02-09 07:42:20,622 [INFO] loss: 0.0074    [34,    20]\n","2024-02-09 07:42:20,658 [INFO] loss: 0.0072    [35,    10]\n","2024-02-09 07:42:20,693 [INFO] loss: 0.0082    [35,    20]\n","2024-02-09 07:42:20,731 [INFO] loss: 0.0079    [36,    10]\n","2024-02-09 07:42:20,762 [INFO] loss: 0.0083    [36,    20]\n","2024-02-09 07:42:20,801 [INFO] loss: 0.0084    [37,    10]\n","2024-02-09 07:42:20,830 [INFO] loss: 0.0067    [37,    20]\n","2024-02-09 07:42:20,868 [INFO] loss: 0.0057    [38,    10]\n","2024-02-09 07:42:20,904 [INFO] loss: 0.0073    [38,    20]\n","2024-02-09 07:42:20,946 [INFO] loss: 0.0084    [39,    10]\n","2024-02-09 07:42:20,979 [INFO] loss: 0.0078    [39,    20]\n","2024-02-09 07:42:21,021 [INFO] loss: 0.0066    [40,    10]\n","2024-02-09 07:42:21,054 [INFO] loss: 0.0083    [40,    20]\n","2024-02-09 07:42:21,093 [INFO] loss: 0.0083    [41,    10]\n","2024-02-09 07:42:21,126 [INFO] loss: 0.0095    [41,    20]\n","2024-02-09 07:42:21,166 [INFO] loss: 0.0078    [42,    10]\n","2024-02-09 07:42:21,200 [INFO] loss: 0.0084    [42,    20]\n","2024-02-09 07:42:21,245 [INFO] loss: 0.0072    [43,    10]\n","2024-02-09 07:42:21,270 [INFO] loss: 0.0085    [43,    20]\n","2024-02-09 07:42:21,300 [INFO] loss: 0.0081    [44,    10]\n","2024-02-09 07:42:21,322 [INFO] loss: 0.0072    [44,    20]\n","2024-02-09 07:42:21,351 [INFO] loss: 0.0083    [45,    10]\n","2024-02-09 07:42:21,373 [INFO] loss: 0.0085    [45,    20]\n","2024-02-09 07:42:21,406 [INFO] loss: 0.0076    [46,    10]\n","2024-02-09 07:42:21,433 [INFO] loss: 0.0068    [46,    20]\n","2024-02-09 07:42:21,461 [INFO] loss: 0.0077    [47,    10]\n","2024-02-09 07:42:21,483 [INFO] loss: 0.0081    [47,    20]\n","2024-02-09 07:42:21,511 [INFO] loss: 0.0075    [48,    10]\n","2024-02-09 07:42:21,533 [INFO] loss: 0.0072    [48,    20]\n","2024-02-09 07:42:21,561 [INFO] loss: 0.0064    [49,    10]\n","2024-02-09 07:42:21,586 [INFO] loss: 0.0075    [49,    20]\n","2024-02-09 07:42:21,616 [INFO] loss: 0.0078    [50,    10]\n","2024-02-09 07:42:21,639 [INFO] loss: 0.0065    [50,    20]\n","2024-02-09 07:42:21,692 [INFO] Result on Train Data : {'AUC': 0.977638813598699, 'ACC': 0.8984700973574409, 'F1 Score': 0.89845752635438, 'AUPR': 0, 'Loss': 0.19079720455667246}\n","2024-02-09 07:42:21,693 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 07:42:21,696 [INFO] moving data and model to cuda\n","2024-02-09 07:42:21,721 [INFO] Result on Test Data : {'AUC': 0.8764556962025315, 'ACC': 0.8324022346368715, 'F1 Score': 0.8290679908326967, 'AUPR': 0, 'Loss': 0.7521248857180277}\n","2024-02-09 07:42:21,722 [INFO] Result of fold 4 : {'AUC': 0.8764556962025315, 'ACC': 0.8324022346368715, 'F1 Score': 0.8290679908326967, 'AUPR': 0, 'Loss': 0.7521248857180277}\n","2024-02-09 07:42:21,727 [INFO] ---- Fold 5 ----\n","2024-02-09 07:42:21,730 [INFO] Initializing SimplePytorchData with X shape : torch.Size([716, 64]) and y shape : torch.Size([716, 1])\n","2024-02-09 07:42:21,732 [INFO] Initializing SimplePytorchData with X shape : torch.Size([182, 64]) and y shape : torch.Size([182, 1])\n","2024-02-09 07:42:21,734 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 07:42:21,735 [INFO] Initial SimpleMLP with 64 input dimension, 16 hidden dimension, 1 \n","            output dimension, 3 layers and with 0.1 dropout\n","2024-02-09 07:42:21,737 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 07:42:21,739 [INFO] moving data and model to cuda\n","2024-02-09 07:42:21,766 [INFO] loss: 0.0215    [1,    10]\n","2024-02-09 07:42:21,792 [INFO] loss: 0.0208    [1,    20]\n","2024-02-09 07:42:21,823 [INFO] loss: 0.0182    [2,    10]\n","2024-02-09 07:42:21,846 [INFO] loss: 0.0164    [2,    20]\n","2024-02-09 07:42:21,874 [INFO] loss: 0.0149    [3,    10]\n","2024-02-09 07:42:21,898 [INFO] loss: 0.0148    [3,    20]\n","2024-02-09 07:42:21,930 [INFO] loss: 0.0135    [4,    10]\n","2024-02-09 07:42:21,953 [INFO] loss: 0.0142    [4,    20]\n","2024-02-09 07:42:21,983 [INFO] loss: 0.0126    [5,    10]\n","2024-02-09 07:42:22,008 [INFO] loss: 0.0128    [5,    20]\n","2024-02-09 07:42:22,037 [INFO] loss: 0.0137    [6,    10]\n","2024-02-09 07:42:22,061 [INFO] loss: 0.0115    [6,    20]\n","2024-02-09 07:42:22,091 [INFO] loss: 0.0118    [7,    10]\n","2024-02-09 07:42:22,117 [INFO] loss: 0.0122    [7,    20]\n","2024-02-09 07:42:22,149 [INFO] loss: 0.0118    [8,    10]\n","2024-02-09 07:42:22,174 [INFO] loss: 0.0107    [8,    20]\n","2024-02-09 07:42:22,203 [INFO] loss: 0.0115    [9,    10]\n","2024-02-09 07:42:22,226 [INFO] loss: 0.0113    [9,    20]\n","2024-02-09 07:42:22,256 [INFO] loss: 0.0105    [10,    10]\n","2024-02-09 07:42:22,280 [INFO] loss: 0.0109    [10,    20]\n","2024-02-09 07:42:22,310 [INFO] loss: 0.0119    [11,    10]\n","2024-02-09 07:42:22,333 [INFO] loss: 0.0096    [11,    20]\n","2024-02-09 07:42:22,362 [INFO] loss: 0.0095    [12,    10]\n","2024-02-09 07:42:22,388 [INFO] loss: 0.0107    [12,    20]\n","2024-02-09 07:42:22,418 [INFO] loss: 0.0106    [13,    10]\n","2024-02-09 07:42:22,449 [INFO] loss: 0.0104    [13,    20]\n","2024-02-09 07:42:22,478 [INFO] loss: 0.0106    [14,    10]\n","2024-02-09 07:42:22,503 [INFO] loss: 0.0116    [14,    20]\n","2024-02-09 07:42:22,532 [INFO] loss: 0.0106    [15,    10]\n","2024-02-09 07:42:22,556 [INFO] loss: 0.0094    [15,    20]\n","2024-02-09 07:42:22,586 [INFO] loss: 0.0093    [16,    10]\n","2024-02-09 07:42:22,610 [INFO] loss: 0.0109    [16,    20]\n","2024-02-09 07:42:22,642 [INFO] loss: 0.0115    [17,    10]\n","2024-02-09 07:42:22,664 [INFO] loss: 0.0099    [17,    20]\n","2024-02-09 07:42:22,692 [INFO] loss: 0.0107    [18,    10]\n","2024-02-09 07:42:22,715 [INFO] loss: 0.0098    [18,    20]\n","2024-02-09 07:42:22,743 [INFO] loss: 0.0086    [19,    10]\n","2024-02-09 07:42:22,765 [INFO] loss: 0.0101    [19,    20]\n","2024-02-09 07:42:22,794 [INFO] loss: 0.0078    [20,    10]\n","2024-02-09 07:42:22,817 [INFO] loss: 0.0099    [20,    20]\n","2024-02-09 07:42:22,846 [INFO] loss: 0.0083    [21,    10]\n","2024-02-09 07:42:22,868 [INFO] loss: 0.0092    [21,    20]\n","2024-02-09 07:42:22,897 [INFO] loss: 0.0077    [22,    10]\n","2024-02-09 07:42:22,919 [INFO] loss: 0.0089    [22,    20]\n","2024-02-09 07:42:22,948 [INFO] loss: 0.0093    [23,    10]\n","2024-02-09 07:42:22,970 [INFO] loss: 0.0087    [23,    20]\n","2024-02-09 07:42:22,998 [INFO] loss: 0.0094    [24,    10]\n","2024-02-09 07:42:23,021 [INFO] loss: 0.0095    [24,    20]\n","2024-02-09 07:42:23,049 [INFO] loss: 0.0095    [25,    10]\n","2024-02-09 07:42:23,072 [INFO] loss: 0.0085    [25,    20]\n","2024-02-09 07:42:23,100 [INFO] loss: 0.0079    [26,    10]\n","2024-02-09 07:42:23,122 [INFO] loss: 0.0089    [26,    20]\n","2024-02-09 07:42:23,155 [INFO] loss: 0.0060    [27,    10]\n","2024-02-09 07:42:23,177 [INFO] loss: 0.0109    [27,    20]\n","2024-02-09 07:42:23,205 [INFO] loss: 0.0083    [28,    10]\n","2024-02-09 07:42:23,230 [INFO] loss: 0.0092    [28,    20]\n","2024-02-09 07:42:23,259 [INFO] loss: 0.0092    [29,    10]\n","2024-02-09 07:42:23,282 [INFO] loss: 0.0081    [29,    20]\n","2024-02-09 07:42:23,312 [INFO] loss: 0.0084    [30,    10]\n","2024-02-09 07:42:23,337 [INFO] loss: 0.0089    [30,    20]\n","2024-02-09 07:42:23,367 [INFO] loss: 0.0073    [31,    10]\n","2024-02-09 07:42:23,390 [INFO] loss: 0.0080    [31,    20]\n","2024-02-09 07:42:23,418 [INFO] loss: 0.0080    [32,    10]\n","2024-02-09 07:42:23,440 [INFO] loss: 0.0068    [32,    20]\n","2024-02-09 07:42:23,476 [INFO] loss: 0.0082    [33,    10]\n","2024-02-09 07:42:23,499 [INFO] loss: 0.0096    [33,    20]\n","2024-02-09 07:42:23,529 [INFO] loss: 0.0091    [34,    10]\n","2024-02-09 07:42:23,551 [INFO] loss: 0.0082    [34,    20]\n","2024-02-09 07:42:23,580 [INFO] loss: 0.0092    [35,    10]\n","2024-02-09 07:42:23,603 [INFO] loss: 0.0089    [35,    20]\n","2024-02-09 07:42:23,634 [INFO] loss: 0.0100    [36,    10]\n","2024-02-09 07:42:23,659 [INFO] loss: 0.0085    [36,    20]\n","2024-02-09 07:42:23,689 [INFO] loss: 0.0068    [37,    10]\n","2024-02-09 07:42:23,714 [INFO] loss: 0.0089    [37,    20]\n","2024-02-09 07:42:23,743 [INFO] loss: 0.0071    [38,    10]\n","2024-02-09 07:42:23,767 [INFO] loss: 0.0087    [38,    20]\n","2024-02-09 07:42:23,798 [INFO] loss: 0.0076    [39,    10]\n","2024-02-09 07:42:23,823 [INFO] loss: 0.0085    [39,    20]\n","2024-02-09 07:42:23,854 [INFO] loss: 0.0066    [40,    10]\n","2024-02-09 07:42:23,879 [INFO] loss: 0.0087    [40,    20]\n","2024-02-09 07:42:23,910 [INFO] loss: 0.0071    [41,    10]\n","2024-02-09 07:42:23,935 [INFO] loss: 0.0083    [41,    20]\n","2024-02-09 07:42:23,965 [INFO] loss: 0.0080    [42,    10]\n","2024-02-09 07:42:23,991 [INFO] loss: 0.0083    [42,    20]\n","2024-02-09 07:42:24,022 [INFO] loss: 0.0078    [43,    10]\n","2024-02-09 07:42:24,046 [INFO] loss: 0.0081    [43,    20]\n","2024-02-09 07:42:24,078 [INFO] loss: 0.0070    [44,    10]\n","2024-02-09 07:42:24,102 [INFO] loss: 0.0066    [44,    20]\n","2024-02-09 07:42:24,132 [INFO] loss: 0.0069    [45,    10]\n","2024-02-09 07:42:24,156 [INFO] loss: 0.0064    [45,    20]\n","2024-02-09 07:42:24,188 [INFO] loss: 0.0076    [46,    10]\n","2024-02-09 07:42:24,213 [INFO] loss: 0.0078    [46,    20]\n","2024-02-09 07:42:24,247 [INFO] loss: 0.0076    [47,    10]\n","2024-02-09 07:42:24,272 [INFO] loss: 0.0066    [47,    20]\n","2024-02-09 07:42:24,307 [INFO] loss: 0.0067    [48,    10]\n","2024-02-09 07:42:24,331 [INFO] loss: 0.0073    [48,    20]\n","2024-02-09 07:42:24,361 [INFO] loss: 0.0085    [49,    10]\n","2024-02-09 07:42:24,388 [INFO] loss: 0.0103    [49,    20]\n","2024-02-09 07:42:24,430 [INFO] loss: 0.0073    [50,    10]\n","2024-02-09 07:42:24,454 [INFO] loss: 0.0082    [50,    20]\n","2024-02-09 07:42:24,518 [INFO] Result on Train Data : {'AUC': 0.9714155301020568, 'ACC': 0.9203910614525139, 'F1 Score': 0.9199850996461166, 'AUPR': 0, 'Loss': 0.18509159123767976}\n","2024-02-09 07:42:24,519 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 07:42:24,521 [INFO] moving data and model to cuda\n","2024-02-09 07:42:24,545 [INFO] Result on Test Data : {'AUC': 0.859316507668156, 'ACC': 0.7582417582417582, 'F1 Score': 0.7568027210884354, 'AUPR': 0, 'Loss': 0.7607837977508703}\n","2024-02-09 07:42:24,546 [INFO] Result of fold 5 : {'AUC': 0.859316507668156, 'ACC': 0.7582417582417582, 'F1 Score': 0.7568027210884354, 'AUPR': 0, 'Loss': 0.7607837977508703}\n","2024-02-09 07:42:24,549 [INFO] 5-fold result: avg_auc: 0.8667630194044159, avg_acc: 0.7907544968997483, avg_f1: 0.7863216731427333, avg_aupr: 0.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<base.evaluation.Result at 0x7e45a201e7a0>"]},"metadata":{},"execution_count":18}],"source":["trainer = SimpleTrainer()\n","tester = SimpleTester()\n","factory = SimpleMDAClassifierFactory(simple_classifier_config)\n","spliter = SimplePytorchDataTrainTestSplit(data)\n","cross_validation(k=5, data_size=data.X.shape[0], train_test_spliter=spliter, model_factory=factory,\n","                    trainer=trainer, tester=tester, config=classifier_optimizer_config)"]},{"cell_type":"code","source":[],"metadata":{"id":"VkLUXnRnuDx_","executionInfo":{"status":"ok","timestamp":1707464544704,"user_tz":-210,"elapsed":4,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"VkLUXnRnuDx_","execution_count":18,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}