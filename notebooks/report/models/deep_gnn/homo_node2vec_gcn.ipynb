{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fg4sTOLBNbFJ","executionInfo":{"status":"ok","timestamp":1707467003697,"user_tz":-210,"elapsed":2939,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"f314543c-630a-4c24-8ff3-a9e666536a81"},"id":"Fg4sTOLBNbFJ","execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Academic/Topics/AI/Machine\\ Learning\\ Dr.\\ Montazeri/Project/ml_mda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkz5A_SiNcle","executionInfo":{"status":"ok","timestamp":1707467003698,"user_tz":-210,"elapsed":5,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"a32f3f91-3a48-494c-f76c-1c9576a7eba7"},"id":"gkz5A_SiNcle","execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Academic/Topics/AI/Machine Learning Dr. Montazeri/Project/ml_mda\n"]}]},{"cell_type":"code","source":["!pip install torch_geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODp_C8LiNecw","executionInfo":{"status":"ok","timestamp":1707467009834,"user_tz":-210,"elapsed":6139,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"a6dd30f7-9967-4860-b4bb-a6f1b75e98a0"},"id":"ODp_C8LiNecw","execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"]}]},{"cell_type":"code","source":["!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IaKc5GwjNgRJ","executionInfo":{"status":"ok","timestamp":1707467015143,"user_tz":-210,"elapsed":5314,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"20726628-eedf-4a2f-f101-503c1292f8e1"},"id":"IaKc5GwjNgRJ","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\n","Requirement already satisfied: pyg_lib in /usr/local/lib/python3.10/dist-packages (0.4.0+pt21cu121)\n","Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt21cu121)\n","Requirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt21cu121)\n","Requirement already satisfied: torch_cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt21cu121)\n","Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt21cu121)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n"]}]},{"cell_type":"markdown","source":["# Requirements"],"metadata":{"id":"Syp1fG3XMOu8"},"id":"Syp1fG3XMOu8"},{"cell_type":"code","source":["import torch\n","\n","from base import OptimizerConfig, cross_validation\n","from base import SimplePytorchData, SimplePytorchDataTrainTestSplit\n","from base import SimpleTrainer, SimpleTester\n","from src.config import Node2VecConfig, Node2VecOptimizerConfig, SimpleClassifierConfig\n","from src.config import GraphAutoEncoderConfig\n","from src.features import get_associations, get_node2vec_gae_pair_embedd_for_training_data\n","from src.models import SimpleMDAClassifier, SimpleMDAClassifierFactory\n","from src.utils import train_test_sampler, prj_logger\n","\n","from torch_geometric.nn import GCNConv"],"metadata":{"id":"aQN35hGYL9zT","executionInfo":{"status":"ok","timestamp":1707467015143,"user_tz":-210,"elapsed":8,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"aQN35hGYL9zT","execution_count":28,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"fAZ0nEWSMSOU","executionInfo":{"status":"ok","timestamp":1707467015144,"user_tz":-210,"elapsed":8,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"fAZ0nEWSMSOU","execution_count":29,"outputs":[]},{"cell_type":"code","source":["import logging\n","import sys\n","\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n","    handlers=[\n","        logging.StreamHandler(stream=sys.stdout)\n","    ],\n","    force=True\n",")"],"metadata":{"id":"ZhHjiOAeJPHm","executionInfo":{"status":"ok","timestamp":1707467015145,"user_tz":-210,"elapsed":8,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"ZhHjiOAeJPHm","execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["# Node2Vec + Graph Auto Encoder Embedding"],"metadata":{"id":"lfmQ_Z57YXJh"},"id":"lfmQ_Z57YXJh"},{"cell_type":"markdown","source":["## Config"],"metadata":{"id":"S7SfvxE63t_v"},"id":"S7SfvxE63t_v"},{"cell_type":"code","source":["# Node2Vec Config\n","node2vec_config = Node2VecConfig()\n","node2vec_config.embedding_dim = 128\n","node2vec_config.walk_length = 50\n","node2vec_config.context_size = 10\n","node2vec_config.walks_per_node = 10\n","node2vec_config.num_negative_samples = 1\n","node2vec_config.p = 1.0\n","node2vec_config.q = 1.0\n","node2vec_config.num_nodes = None\n","node2vec_config.sparse = True\n","\n","# Node2Vec Optimizer Config\n","node2vec_optimizer_config = Node2VecOptimizerConfig()\n","node2vec_optimizer_config.exp_name = 'Node2VecOptimizer For All Nodes'\n","node2vec_optimizer_config.shuffle = True\n","node2vec_optimizer_config.num_workers = 2\n","node2vec_optimizer_config.lr = 0.01\n","node2vec_optimizer_config.device = device\n","node2vec_optimizer_config.report_size = 1000\n","node2vec_optimizer_config.optimizer = torch.optim.SparseAdam"],"metadata":{"id":"3G6ocDSzMbtF","executionInfo":{"status":"ok","timestamp":1707467015145,"user_tz":-210,"elapsed":8,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"3G6ocDSzMbtF","execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Graph Auto Encoder Config\n","gae_model_config = GraphAutoEncoderConfig()\n","gae_model_config.model_name = \"Graph Auto Encoder Model\"\n","gae_model_config.device = device\n","gae_model_config.hidden_dim = 32\n","gae_model_config.output_dim = 32\n","gae_model_config.num_layers = 3\n","gae_model_config.dropout = 0.5\n","gae_model_config.GCN = GCNConv\n","\n","# Graph Auto Encoder Optimizer Config\n","gae_optimizer_config = OptimizerConfig()\n","gae_optimizer_config.optimizer = torch.optim.Adam\n","gae_optimizer_config.criterion = torch.nn.BCEWithLogitsLoss()\n","gae_optimizer_config.lr = 0.01\n","gae_optimizer_config.n_epoch = 80\n","gae_optimizer_config.exp_name = \"Optimizer for Graph Auto Encoder\"\n","gae_optimizer_config.device = device"],"metadata":{"id":"2mLn9LIN6a4i","executionInfo":{"status":"ok","timestamp":1707467015145,"user_tz":-210,"elapsed":8,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"2mLn9LIN6a4i","execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["## Embedding"],"metadata":{"id":"sH2G8xOr3xng"},"id":"sH2G8xOr3xng"},{"cell_type":"code","source":["md_embed = get_node2vec_gae_pair_embedd_for_training_data(node2vec_config, node2vec_optimizer_config, gae_model_config, gae_optimizer_config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p8u3hYWM6o7u","executionInfo":{"status":"ok","timestamp":1707467418168,"user_tz":-210,"elapsed":403031,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"610f2de8-a616-4be6-b6f8-bbbf5ebd0140"},"id":"p8u3hYWM6o7u","execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 08:23:35,040 [INFO] Calling get_node2vec_gae_pair_embedd on cuda device ...\n","2024-02-09 08:23:35,045 [INFO] Calling get_homogeneous_graph\n","2024-02-09 08:23:36,330 [INFO] homogeneous data : Data(x=[66911, 1], edge_index=[2, 633662])\n","2024-02-09 08:23:36,331 [INFO] Calling get_homogeneous_graph\n","2024-02-09 08:23:37,271 [INFO] homogeneous data : Data(x=[66911, 1], edge_index=[2, 633662])\n","2024-02-09 08:23:37,278 [INFO] Calling get_node2vec_embedd on cuda device ...\n","2024-02-09 08:23:37,280 [INFO] Creating Node2Vec model ...\n","2024-02-09 08:23:37,282 [INFO] Calling get_homogeneous_graph\n","2024-02-09 08:23:38,779 [INFO] homogeneous data : Data(x=[66911, 1], edge_index=[2, 633662])\n","2024-02-09 08:23:38,785 [INFO] Initialing MDNode2Vec with model_config {'model_name': None, 'embedding_dim': 128, 'walk_length': 50}\n","2024-02-09 08:23:39,015 [INFO] Training Node2Vec ...\n","2024-02-09 08:23:39,017 [INFO] Running Node2vecTrainer with Node2VecOptimizer For All Nodes\n","2024-02-09 08:23:39,019 [INFO] Creating <class 'torch.optim.sparse_adam.SparseAdam'> with lr : 0.01\n","2024-02-09 08:23:39,020 [INFO] moving model to cuda\n","2024-02-09 08:23:39,045 [INFO] start batch optimizing\n","2024-02-09 08:23:46,748 [INFO] loss: 7.7352    [ 1000]\n","2024-02-09 08:23:51,418 [INFO] loss: 5.6319    [ 2000]\n","2024-02-09 08:23:56,386 [INFO] loss: 4.5580    [ 3000]\n","2024-02-09 08:24:00,816 [INFO] loss: 3.8102    [ 4000]\n","2024-02-09 08:24:05,801 [INFO] loss: 3.2408    [ 5000]\n","2024-02-09 08:24:10,298 [INFO] loss: 2.7994    [ 6000]\n","2024-02-09 08:24:14,698 [INFO] loss: 2.4509    [ 7000]\n","2024-02-09 08:24:19,800 [INFO] loss: 2.1735    [ 8000]\n","2024-02-09 08:24:24,199 [INFO] loss: 1.9513    [ 9000]\n","2024-02-09 08:24:28,527 [INFO] loss: 1.7713    [10000]\n","2024-02-09 08:24:33,581 [INFO] loss: 1.6206    [11000]\n","2024-02-09 08:24:38,319 [INFO] loss: 1.4980    [12000]\n","2024-02-09 08:24:42,975 [INFO] loss: 1.4000    [13000]\n","2024-02-09 08:24:47,891 [INFO] loss: 1.3191    [14000]\n","2024-02-09 08:24:52,418 [INFO] loss: 1.2412    [15000]\n","2024-02-09 08:24:57,511 [INFO] loss: 1.1865    [16000]\n","2024-02-09 08:25:01,943 [INFO] loss: 1.1407    [17000]\n","2024-02-09 08:25:06,250 [INFO] loss: 1.1039    [18000]\n","2024-02-09 08:25:11,384 [INFO] loss: 1.0684    [19000]\n","2024-02-09 08:25:15,819 [INFO] loss: 1.0361    [20000]\n","2024-02-09 08:25:20,271 [INFO] loss: 1.0132    [21000]\n","2024-02-09 08:25:25,399 [INFO] loss: 0.9934    [22000]\n","2024-02-09 08:25:29,735 [INFO] loss: 0.9744    [23000]\n","2024-02-09 08:25:34,329 [INFO] loss: 0.9613    [24000]\n","2024-02-09 08:25:39,208 [INFO] loss: 0.9491    [25000]\n","2024-02-09 08:25:43,530 [INFO] loss: 0.9369    [26000]\n","2024-02-09 08:25:48,551 [INFO] loss: 0.9302    [27000]\n","2024-02-09 08:25:52,990 [INFO] loss: 0.9208    [28000]\n","2024-02-09 08:25:57,278 [INFO] loss: 0.9131    [29000]\n","2024-02-09 08:26:02,340 [INFO] loss: 0.9067    [30000]\n","2024-02-09 08:26:06,668 [INFO] loss: 0.9003    [31000]\n","2024-02-09 08:26:11,113 [INFO] loss: 0.8938    [32000]\n","2024-02-09 08:26:16,397 [INFO] loss: 0.8908    [33000]\n","2024-02-09 08:26:20,937 [INFO] loss: 0.8869    [34000]\n","2024-02-09 08:26:25,577 [INFO] loss: 0.8815    [35000]\n","2024-02-09 08:26:30,563 [INFO] loss: 0.8809    [36000]\n","2024-02-09 08:26:35,083 [INFO] loss: 0.8753    [37000]\n","2024-02-09 08:26:40,195 [INFO] loss: 0.8736    [38000]\n","2024-02-09 08:26:44,933 [INFO] loss: 0.8713    [39000]\n","2024-02-09 08:26:49,569 [INFO] loss: 0.8686    [40000]\n","2024-02-09 08:26:54,732 [INFO] loss: 0.8667    [41000]\n","2024-02-09 08:26:59,181 [INFO] loss: 0.8622    [42000]\n","2024-02-09 08:27:03,651 [INFO] loss: 0.8635    [43000]\n","2024-02-09 08:27:08,769 [INFO] loss: 0.8640    [44000]\n","2024-02-09 08:27:13,093 [INFO] loss: 0.8596    [45000]\n","2024-02-09 08:27:17,862 [INFO] loss: 0.8589    [46000]\n","2024-02-09 08:27:22,587 [INFO] loss: 0.8592    [47000]\n","2024-02-09 08:27:27,093 [INFO] loss: 0.8564    [48000]\n","2024-02-09 08:27:32,259 [INFO] loss: 0.8563    [49000]\n","2024-02-09 08:27:36,710 [INFO] loss: 0.8543    [50000]\n","2024-02-09 08:27:41,138 [INFO] loss: 0.8523    [51000]\n","2024-02-09 08:27:46,295 [INFO] loss: 0.8519    [52000]\n","2024-02-09 08:27:50,735 [INFO] loss: 0.8521    [53000]\n","2024-02-09 08:27:55,230 [INFO] loss: 0.8505    [54000]\n","2024-02-09 08:28:00,318 [INFO] loss: 0.8489    [55000]\n","2024-02-09 08:28:04,712 [INFO] loss: 0.8489    [56000]\n","2024-02-09 08:28:09,542 [INFO] loss: 0.8475    [57000]\n","2024-02-09 08:28:14,162 [INFO] loss: 0.8472    [58000]\n","2024-02-09 08:28:18,491 [INFO] loss: 0.8472    [59000]\n","2024-02-09 08:28:23,499 [INFO] loss: 0.8491    [60000]\n","2024-02-09 08:28:27,813 [INFO] loss: 0.8457    [61000]\n","2024-02-09 08:28:32,079 [INFO] loss: 0.8469    [62000]\n","2024-02-09 08:28:37,114 [INFO] loss: 0.8453    [63000]\n","2024-02-09 08:28:41,442 [INFO] loss: 0.8439    [64000]\n","2024-02-09 08:28:45,697 [INFO] loss: 0.8447    [65000]\n","2024-02-09 08:28:50,802 [INFO] loss: 0.8433    [66000]\n","2024-02-09 08:28:54,748 [INFO] Result on Train Data : {'AUC': 0, 'ACC': 0, 'F1 Score': 0, 'AUPR': 0, 'Loss': 1.3449857347980156}\n","2024-02-09 08:28:54,750 [INFO] loss of Node2Vec model : 1.3449857347980156\n","2024-02-09 08:28:54,770 [INFO] node embedding shape : torch.Size([66911, 128])\n","2024-02-09 08:28:54,772 [INFO] set graph auto encoder input_dim to homo.x.shape[1] : 128\n","2024-02-09 08:28:54,775 [INFO] set graph auto encoder with_embedd to False\n","2024-02-09 08:28:54,777 [INFO] Calling get_node2vec_gae_embedd on cuda device ...\n","2024-02-09 08:28:54,778 [INFO] Creating GraphAutoEncoderModel ...\n","2024-02-09 08:28:54,779 [INFO] Initializing GraphAutoEncoderModel with config : {'model_name': 'Graph Auto Encoder Model', 'input_dim': 128, 'hidden_dim': 32, 'output_dim': 32, 'num_layers': 3, 'dropout': 0.5, 'with_embedd': False, 'GCN': <class 'torch_geometric.nn.conv.gcn_conv.GCNConv'>}\n","2024-02-09 08:28:54,781 [INFO] Initializing GCNAutoEncoder ...\n","2024-02-09 08:28:54,782 [INFO] Initial GCNEncoder with 128 input_dimension,\n","            32 hidden dimension, 32 output dimension,\n","            3 layers and with 0.5 dropout\n","2024-02-09 08:28:54,801 [INFO] Initial LinkDecoder\n","2024-02-09 08:28:54,802 [INFO] Training GraphAutoEncoderModel ...\n","2024-02-09 08:28:54,804 [INFO] Running GraphAutoEncoderTrainer with Optimizer for Graph Auto Encoder\n","2024-02-09 08:28:54,805 [INFO] Creating <class 'torch.optim.adam.Adam'> with lr : 0.01\n","2024-02-09 08:28:54,807 [INFO] moving model to cuda\n","2024-02-09 08:28:54,811 [INFO] moving data x and edge_index to cuda\n","2024-02-09 08:28:55,769 [INFO] loss: 0.6931    [epoch:     1]\n","2024-02-09 08:28:56,710 [INFO] loss: 0.6794    [epoch:     2]\n","2024-02-09 08:28:57,646 [INFO] loss: 0.6519    [epoch:     3]\n","2024-02-09 08:28:58,593 [INFO] loss: 0.6141    [epoch:     4]\n","2024-02-09 08:28:59,631 [INFO] loss: 0.5718    [epoch:     5]\n","2024-02-09 08:29:01,157 [INFO] loss: 0.5373    [epoch:     6]\n","2024-02-09 08:29:02,514 [INFO] loss: 0.5353    [epoch:     7]\n","2024-02-09 08:29:03,462 [INFO] loss: 0.5427    [epoch:     8]\n","2024-02-09 08:29:04,421 [INFO] loss: 0.5592    [epoch:     9]\n","2024-02-09 08:29:05,377 [INFO] loss: 0.5457    [epoch:    10]\n","2024-02-09 08:29:06,339 [INFO] loss: 0.5256    [epoch:    11]\n","2024-02-09 08:29:07,270 [INFO] loss: 0.5081    [epoch:    12]\n","2024-02-09 08:29:08,256 [INFO] loss: 0.5004    [epoch:    13]\n","2024-02-09 08:29:09,277 [INFO] loss: 0.4949    [epoch:    14]\n","2024-02-09 08:29:10,267 [INFO] loss: 0.5013    [epoch:    15]\n","2024-02-09 08:29:11,204 [INFO] loss: 0.4921    [epoch:    16]\n","2024-02-09 08:29:12,149 [INFO] loss: 0.4814    [epoch:    17]\n","2024-02-09 08:29:13,649 [INFO] loss: 0.4741    [epoch:    18]\n","2024-02-09 08:29:15,168 [INFO] loss: 0.4702    [epoch:    19]\n","2024-02-09 08:29:16,101 [INFO] loss: 0.4629    [epoch:    20]\n","2024-02-09 08:29:17,096 [INFO] loss: 0.4573    [epoch:    21]\n","2024-02-09 08:29:18,065 [INFO] loss: 0.4634    [epoch:    22]\n","2024-02-09 08:29:19,029 [INFO] loss: 0.4534    [epoch:    23]\n","2024-02-09 08:29:19,979 [INFO] loss: 0.4624    [epoch:    24]\n","2024-02-09 08:29:20,919 [INFO] loss: 0.4452    [epoch:    25]\n","2024-02-09 08:29:21,857 [INFO] loss: 0.4487    [epoch:    26]\n","2024-02-09 08:29:22,776 [INFO] loss: 0.4433    [epoch:    27]\n","2024-02-09 08:29:23,699 [INFO] loss: 0.4395    [epoch:    28]\n","2024-02-09 08:29:24,643 [INFO] loss: 0.4450    [epoch:    29]\n","2024-02-09 08:29:25,952 [INFO] loss: 0.4408    [epoch:    30]\n","2024-02-09 08:29:27,432 [INFO] loss: 0.4341    [epoch:    31]\n","2024-02-09 08:29:28,540 [INFO] loss: 0.4322    [epoch:    32]\n","2024-02-09 08:29:29,509 [INFO] loss: 0.4370    [epoch:    33]\n","2024-02-09 08:29:30,465 [INFO] loss: 0.4282    [epoch:    34]\n","2024-02-09 08:29:31,416 [INFO] loss: 0.4195    [epoch:    35]\n","2024-02-09 08:29:32,388 [INFO] loss: 0.4260    [epoch:    36]\n","2024-02-09 08:29:33,330 [INFO] loss: 0.4204    [epoch:    37]\n","2024-02-09 08:29:34,273 [INFO] loss: 0.4293    [epoch:    38]\n","2024-02-09 08:29:35,210 [INFO] loss: 0.4140    [epoch:    39]\n","2024-02-09 08:29:36,155 [INFO] loss: 0.4232    [epoch:    40]\n","2024-02-09 08:29:37,064 [INFO] loss: 0.4155    [epoch:    41]\n","2024-02-09 08:29:38,053 [INFO] loss: 0.4094    [epoch:    42]\n","2024-02-09 08:29:39,599 [INFO] loss: 0.4203    [epoch:    43]\n","2024-02-09 08:29:41,042 [INFO] loss: 0.4214    [epoch:    44]\n","2024-02-09 08:29:41,988 [INFO] loss: 0.4143    [epoch:    45]\n","2024-02-09 08:29:42,909 [INFO] loss: 0.4199    [epoch:    46]\n","2024-02-09 08:29:43,836 [INFO] loss: 0.4103    [epoch:    47]\n","2024-02-09 08:29:44,761 [INFO] loss: 0.4158    [epoch:    48]\n","2024-02-09 08:29:45,681 [INFO] loss: 0.4200    [epoch:    49]\n","2024-02-09 08:29:46,595 [INFO] loss: 0.4108    [epoch:    50]\n","2024-02-09 08:29:47,557 [INFO] loss: 0.4118    [epoch:    51]\n","2024-02-09 08:29:48,529 [INFO] loss: 0.4152    [epoch:    52]\n","2024-02-09 08:29:49,496 [INFO] loss: 0.4150    [epoch:    53]\n","2024-02-09 08:29:50,434 [INFO] loss: 0.4094    [epoch:    54]\n","2024-02-09 08:29:51,779 [INFO] loss: 0.4129    [epoch:    55]\n","2024-02-09 08:29:53,304 [INFO] loss: 0.4031    [epoch:    56]\n","2024-02-09 08:29:54,358 [INFO] loss: 0.4127    [epoch:    57]\n","2024-02-09 08:29:55,286 [INFO] loss: 0.4156    [epoch:    58]\n","2024-02-09 08:29:56,217 [INFO] loss: 0.4134    [epoch:    59]\n","2024-02-09 08:29:57,173 [INFO] loss: 0.4108    [epoch:    60]\n","2024-02-09 08:29:58,122 [INFO] loss: 0.4035    [epoch:    61]\n","2024-02-09 08:29:59,033 [INFO] loss: 0.4113    [epoch:    62]\n","2024-02-09 08:30:00,007 [INFO] loss: 0.4098    [epoch:    63]\n","2024-02-09 08:30:00,958 [INFO] loss: 0.4088    [epoch:    64]\n","2024-02-09 08:30:01,902 [INFO] loss: 0.4082    [epoch:    65]\n","2024-02-09 08:30:02,854 [INFO] loss: 0.4074    [epoch:    66]\n","2024-02-09 08:30:03,840 [INFO] loss: 0.4067    [epoch:    67]\n","2024-02-09 08:30:05,365 [INFO] loss: 0.4028    [epoch:    68]\n","2024-02-09 08:30:06,792 [INFO] loss: 0.3997    [epoch:    69]\n","2024-02-09 08:30:07,717 [INFO] loss: 0.4142    [epoch:    70]\n","2024-02-09 08:30:08,636 [INFO] loss: 0.4092    [epoch:    71]\n","2024-02-09 08:30:09,614 [INFO] loss: 0.4036    [epoch:    72]\n","2024-02-09 08:30:10,554 [INFO] loss: 0.4057    [epoch:    73]\n","2024-02-09 08:30:11,484 [INFO] loss: 0.4081    [epoch:    74]\n","2024-02-09 08:30:12,413 [INFO] loss: 0.4093    [epoch:    75]\n","2024-02-09 08:30:13,354 [INFO] loss: 0.4073    [epoch:    76]\n","2024-02-09 08:30:14,306 [INFO] loss: 0.4087    [epoch:    77]\n","2024-02-09 08:30:15,259 [INFO] loss: 0.4039    [epoch:    78]\n","2024-02-09 08:30:16,215 [INFO] loss: 0.4033    [epoch:    79]\n","2024-02-09 08:30:17,546 [INFO] loss: 0.4082    [epoch:    80]\n","2024-02-09 08:30:17,552 [INFO] loss of GraphAutoEncoderModel model : 0.40823647379875183\n","2024-02-09 08:30:17,566 [INFO] node embedding shape : torch.Size([66911, 32])\n","2024-02-09 08:30:17,571 [INFO] disease embedding shape : torch.Size([898, 32])\n","2024-02-09 08:30:17,574 [INFO] microbe embedding shape : torch.Size([898, 32])\n","2024-02-09 08:30:17,577 [INFO] microbe disease combination embedding shape : torch.Size([898, 64])\n"]}]},{"cell_type":"markdown","source":["# Classification"],"metadata":{"id":"T_hIMihJMts8"},"id":"T_hIMihJMts8"},{"cell_type":"markdown","source":["## Data"],"metadata":{"id":"ocxVXIz1MqLJ"},"id":"ocxVXIz1MqLJ"},{"cell_type":"code","source":["associations = get_associations()\n","y = torch.tensor(associations['increased'].tolist(), dtype=torch.float32).reshape(-1, 1).to(device)"],"metadata":{"id":"jEfB8KA7gPx2","executionInfo":{"status":"ok","timestamp":1707467418168,"user_tz":-210,"elapsed":14,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":34,"outputs":[],"id":"jEfB8KA7gPx2"},{"cell_type":"code","source":["# Train Test Split\n","train_indices, test_indices = train_test_sampler(y.shape[0], 0.7)\n","\n","data = SimplePytorchData(md_embed, y)\n","train_data = SimplePytorchData(md_embed[train_indices], y[train_indices])\n","test_data = SimplePytorchData(md_embed[test_indices], y[test_indices])"],"metadata":{"id":"DNdQlgzMMtHN","executionInfo":{"status":"ok","timestamp":1707467418168,"user_tz":-210,"elapsed":13,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f12b3ce-d8fb-479e-bd9c-01b350eb9449"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 08:30:17,607 [INFO] Initializing SimplePytorchData with X shape : torch.Size([898, 64]) and y shape : torch.Size([898, 1])\n","2024-02-09 08:30:17,613 [INFO] Initializing SimplePytorchData with X shape : torch.Size([628, 64]) and y shape : torch.Size([628, 1])\n","2024-02-09 08:30:17,615 [INFO] Initializing SimplePytorchData with X shape : torch.Size([270, 64]) and y shape : torch.Size([270, 1])\n"]}],"id":"DNdQlgzMMtHN"},{"cell_type":"markdown","source":["## Classifier"],"metadata":{"id":"UN1hkf2s9RO7"},"id":"UN1hkf2s9RO7"},{"cell_type":"code","source":["simple_classifier_config = SimpleClassifierConfig()\n","simple_classifier_config.model_name = \"simple classifier\"\n","simple_classifier_config.input_dim = md_embed.shape[1]\n","simple_classifier_config.hidden_dim = 32\n","simple_classifier_config.output_dim = 1\n","simple_classifier_config.num_layers = 3\n","simple_classifier_config.dropout = 0.1"],"metadata":{"id":"BFTQsCl8M9bv","executionInfo":{"status":"ok","timestamp":1707467418168,"user_tz":-210,"elapsed":9,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"BFTQsCl8M9bv","execution_count":36,"outputs":[]},{"cell_type":"code","source":["mda_classifier = SimpleMDAClassifier(simple_classifier_config)"],"metadata":{"id":"1ciyBQ4QM_0U","executionInfo":{"status":"ok","timestamp":1707467418168,"user_tz":-210,"elapsed":8,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8c94b0c8-f324-4ed5-bc71-a120b4c089f6"},"id":"1ciyBQ4QM_0U","execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 08:30:17,634 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 08:30:17,635 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 3 layers and with 0.1 dropout\n"]}]},{"cell_type":"markdown","source":["## Train Test Approach"],"metadata":{"id":"4iI5bMmJNQV3"},"id":"4iI5bMmJNQV3"},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"h24KnmDZNAgD"},"id":"h24KnmDZNAgD"},{"cell_type":"code","source":["classifier_optimizer_config = OptimizerConfig()\n","classifier_optimizer_config.optimizer = torch.optim.Adam\n","classifier_optimizer_config.criterion = torch.nn.BCEWithLogitsLoss()\n","classifier_optimizer_config.lr = 0.01\n","classifier_optimizer_config.batch_size = 32\n","classifier_optimizer_config.n_epoch = 50\n","classifier_optimizer_config.exp_name = \"adam optimizer\"\n","classifier_optimizer_config.save = False\n","classifier_optimizer_config.save_path = None\n","classifier_optimizer_config.device = device\n","classifier_optimizer_config.report_size = 10  # batch to report ratio\n","classifier_optimizer_config.threshold = 0.5"],"metadata":{"id":"3D6yhiPpNEc8","executionInfo":{"status":"ok","timestamp":1707467418168,"user_tz":-210,"elapsed":7,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"3D6yhiPpNEc8","execution_count":38,"outputs":[]},{"cell_type":"code","source":["train_result = SimpleTrainer().train(model=mda_classifier,\n","                                     data=train_data,\n","                                     config=classifier_optimizer_config)"],"metadata":{"id":"OqKrF7HmNFx1","executionInfo":{"status":"ok","timestamp":1707467420903,"user_tz":-210,"elapsed":2742,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fae6ac8e-8087-413e-c6fd-5639bf5e33dc"},"id":"OqKrF7HmNFx1","execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 08:30:17,658 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 08:30:17,659 [INFO] moving data and model to cuda\n","2024-02-09 08:30:17,697 [INFO] loss: 0.0212    [1,    10]\n","2024-02-09 08:30:17,728 [INFO] loss: 0.0210    [1,    20]\n","2024-02-09 08:30:17,756 [INFO] loss: 0.0202    [2,    10]\n","2024-02-09 08:30:17,786 [INFO] loss: 0.0214    [2,    20]\n","2024-02-09 08:30:17,811 [INFO] loss: 0.0203    [3,    10]\n","2024-02-09 08:30:17,837 [INFO] loss: 0.0191    [3,    20]\n","2024-02-09 08:30:17,865 [INFO] loss: 0.0192    [4,    10]\n","2024-02-09 08:30:17,893 [INFO] loss: 0.0196    [4,    20]\n","2024-02-09 08:30:17,919 [INFO] loss: 0.0185    [5,    10]\n","2024-02-09 08:30:17,945 [INFO] loss: 0.0192    [5,    20]\n","2024-02-09 08:30:17,981 [INFO] loss: 0.0182    [6,    10]\n","2024-02-09 08:30:18,018 [INFO] loss: 0.0192    [6,    20]\n","2024-02-09 08:30:18,046 [INFO] loss: 0.0186    [7,    10]\n","2024-02-09 08:30:18,073 [INFO] loss: 0.0184    [7,    20]\n","2024-02-09 08:30:18,100 [INFO] loss: 0.0176    [8,    10]\n","2024-02-09 08:30:18,127 [INFO] loss: 0.0183    [8,    20]\n","2024-02-09 08:30:18,156 [INFO] loss: 0.0184    [9,    10]\n","2024-02-09 08:30:18,183 [INFO] loss: 0.0172    [9,    20]\n","2024-02-09 08:30:18,214 [INFO] loss: 0.0167    [10,    10]\n","2024-02-09 08:30:18,242 [INFO] loss: 0.0180    [10,    20]\n","2024-02-09 08:30:18,272 [INFO] loss: 0.0184    [11,    10]\n","2024-02-09 08:30:18,299 [INFO] loss: 0.0173    [11,    20]\n","2024-02-09 08:30:18,325 [INFO] loss: 0.0165    [12,    10]\n","2024-02-09 08:30:18,351 [INFO] loss: 0.0183    [12,    20]\n","2024-02-09 08:30:18,378 [INFO] loss: 0.0167    [13,    10]\n","2024-02-09 08:30:18,403 [INFO] loss: 0.0180    [13,    20]\n","2024-02-09 08:30:18,428 [INFO] loss: 0.0174    [14,    10]\n","2024-02-09 08:30:18,456 [INFO] loss: 0.0164    [14,    20]\n","2024-02-09 08:30:18,481 [INFO] loss: 0.0179    [15,    10]\n","2024-02-09 08:30:18,506 [INFO] loss: 0.0173    [15,    20]\n","2024-02-09 08:30:18,534 [INFO] loss: 0.0175    [16,    10]\n","2024-02-09 08:30:18,558 [INFO] loss: 0.0158    [16,    20]\n","2024-02-09 08:30:18,582 [INFO] loss: 0.0176    [17,    10]\n","2024-02-09 08:30:18,606 [INFO] loss: 0.0171    [17,    20]\n","2024-02-09 08:30:18,631 [INFO] loss: 0.0163    [18,    10]\n","2024-02-09 08:30:18,655 [INFO] loss: 0.0167    [18,    20]\n","2024-02-09 08:30:18,678 [INFO] loss: 0.0169    [19,    10]\n","2024-02-09 08:30:18,703 [INFO] loss: 0.0165    [19,    20]\n","2024-02-09 08:30:18,733 [INFO] loss: 0.0166    [20,    10]\n","2024-02-09 08:30:18,764 [INFO] loss: 0.0160    [20,    20]\n","2024-02-09 08:30:18,795 [INFO] loss: 0.0167    [21,    10]\n","2024-02-09 08:30:18,828 [INFO] loss: 0.0168    [21,    20]\n","2024-02-09 08:30:18,856 [INFO] loss: 0.0155    [22,    10]\n","2024-02-09 08:30:18,889 [INFO] loss: 0.0165    [22,    20]\n","2024-02-09 08:30:18,920 [INFO] loss: 0.0160    [23,    10]\n","2024-02-09 08:30:18,950 [INFO] loss: 0.0162    [23,    20]\n","2024-02-09 08:30:18,985 [INFO] loss: 0.0161    [24,    10]\n","2024-02-09 08:30:19,023 [INFO] loss: 0.0158    [24,    20]\n","2024-02-09 08:30:19,081 [INFO] loss: 0.0159    [25,    10]\n","2024-02-09 08:30:19,120 [INFO] loss: 0.0174    [25,    20]\n","2024-02-09 08:30:19,158 [INFO] loss: 0.0155    [26,    10]\n","2024-02-09 08:30:19,201 [INFO] loss: 0.0170    [26,    20]\n","2024-02-09 08:30:19,236 [INFO] loss: 0.0149    [27,    10]\n","2024-02-09 08:30:19,273 [INFO] loss: 0.0179    [27,    20]\n","2024-02-09 08:30:19,303 [INFO] loss: 0.0158    [28,    10]\n","2024-02-09 08:30:19,334 [INFO] loss: 0.0166    [28,    20]\n","2024-02-09 08:30:19,374 [INFO] loss: 0.0163    [29,    10]\n","2024-02-09 08:30:19,413 [INFO] loss: 0.0158    [29,    20]\n","2024-02-09 08:30:19,460 [INFO] loss: 0.0149    [30,    10]\n","2024-02-09 08:30:19,498 [INFO] loss: 0.0187    [30,    20]\n","2024-02-09 08:30:19,542 [INFO] loss: 0.0164    [31,    10]\n","2024-02-09 08:30:19,576 [INFO] loss: 0.0156    [31,    20]\n","2024-02-09 08:30:19,610 [INFO] loss: 0.0173    [32,    10]\n","2024-02-09 08:30:19,653 [INFO] loss: 0.0179    [32,    20]\n","2024-02-09 08:30:19,687 [INFO] loss: 0.0166    [33,    10]\n","2024-02-09 08:30:19,717 [INFO] loss: 0.0175    [33,    20]\n","2024-02-09 08:30:19,746 [INFO] loss: 0.0172    [34,    10]\n","2024-02-09 08:30:19,776 [INFO] loss: 0.0152    [34,    20]\n","2024-02-09 08:30:19,804 [INFO] loss: 0.0158    [35,    10]\n","2024-02-09 08:30:19,827 [INFO] loss: 0.0153    [35,    20]\n","2024-02-09 08:30:19,849 [INFO] loss: 0.0153    [36,    10]\n","2024-02-09 08:30:19,871 [INFO] loss: 0.0153    [36,    20]\n","2024-02-09 08:30:19,894 [INFO] loss: 0.0152    [37,    10]\n","2024-02-09 08:30:19,916 [INFO] loss: 0.0157    [37,    20]\n","2024-02-09 08:30:19,938 [INFO] loss: 0.0150    [38,    10]\n","2024-02-09 08:30:19,962 [INFO] loss: 0.0155    [38,    20]\n","2024-02-09 08:30:19,984 [INFO] loss: 0.0146    [39,    10]\n","2024-02-09 08:30:20,005 [INFO] loss: 0.0178    [39,    20]\n","2024-02-09 08:30:20,027 [INFO] loss: 0.0159    [40,    10]\n","2024-02-09 08:30:20,048 [INFO] loss: 0.0165    [40,    20]\n","2024-02-09 08:30:20,069 [INFO] loss: 0.0156    [41,    10]\n","2024-02-09 08:30:20,098 [INFO] loss: 0.0146    [41,    20]\n","2024-02-09 08:30:20,120 [INFO] loss: 0.0141    [42,    10]\n","2024-02-09 08:30:20,141 [INFO] loss: 0.0151    [42,    20]\n","2024-02-09 08:30:20,161 [INFO] loss: 0.0149    [43,    10]\n","2024-02-09 08:30:20,181 [INFO] loss: 0.0153    [43,    20]\n","2024-02-09 08:30:20,201 [INFO] loss: 0.0140    [44,    10]\n","2024-02-09 08:30:20,221 [INFO] loss: 0.0154    [44,    20]\n","2024-02-09 08:30:20,243 [INFO] loss: 0.0163    [45,    10]\n","2024-02-09 08:30:20,264 [INFO] loss: 0.0144    [45,    20]\n","2024-02-09 08:30:20,287 [INFO] loss: 0.0143    [46,    10]\n","2024-02-09 08:30:20,309 [INFO] loss: 0.0151    [46,    20]\n","2024-02-09 08:30:20,333 [INFO] loss: 0.0139    [47,    10]\n","2024-02-09 08:30:20,353 [INFO] loss: 0.0165    [47,    20]\n","2024-02-09 08:30:20,374 [INFO] loss: 0.0151    [48,    10]\n","2024-02-09 08:30:20,394 [INFO] loss: 0.0154    [48,    20]\n","2024-02-09 08:30:20,414 [INFO] loss: 0.0173    [49,    10]\n","2024-02-09 08:30:20,434 [INFO] loss: 0.0140    [49,    20]\n","2024-02-09 08:30:20,455 [INFO] loss: 0.0153    [50,    10]\n","2024-02-09 08:30:20,475 [INFO] loss: 0.0150    [50,    20]\n","2024-02-09 08:30:20,510 [INFO] Result on Train Data : {'AUC': 0.8694046882449005, 'ACC': 0.8009554140127388, 'F1 Score': 0.7998342576655828, 'AUPR': 0, 'Loss': 0.4752172529697418}\n"]}]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"0eQGNWm_NMVG"},"id":"0eQGNWm_NMVG"},{"cell_type":"code","source":["test_result = SimpleTester().test(model=mda_classifier,\n","                                  data=test_data,\n","                                  config=classifier_optimizer_config)"],"metadata":{"id":"U05mXL_fNHpG","executionInfo":{"status":"ok","timestamp":1707467420903,"user_tz":-210,"elapsed":11,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1118a56e-0fe9-4736-c5c9-d6cf5e38500c"},"id":"U05mXL_fNHpG","execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 08:30:20,520 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 08:30:20,526 [INFO] moving data and model to cuda\n","2024-02-09 08:30:20,547 [INFO] Result on Test Data : {'AUC': 0.8532368537339814, 'ACC': 0.7666666666666667, 'F1 Score': 0.7665097253297827, 'AUPR': 0, 'Loss': 0.503961142566469}\n"]}]},{"cell_type":"code","source":["test_result.get_result()"],"metadata":{"id":"oqgiZQqRWWGF","executionInfo":{"status":"ok","timestamp":1707467420903,"user_tz":-210,"elapsed":10,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"31e0750c-1e46-462c-b0f6-559004e22108"},"id":"oqgiZQqRWWGF","execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'AUC': 0.8532368537339814,\n"," 'ACC': 0.7666666666666667,\n"," 'F1 Score': 0.7665097253297827,\n"," 'AUPR': 0,\n"," 'Loss': 0.503961142566469}"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["## Cross Validation"],"metadata":{"id":"ti8vEX_cNNwy"},"id":"ti8vEX_cNNwy"},{"cell_type":"code","execution_count":42,"id":"initial_id","metadata":{"id":"initial_id","executionInfo":{"status":"ok","timestamp":1707467437231,"user_tz":-210,"elapsed":16336,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"842fc969-e4ed-4ee0-bf4c-b80958576fd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 08:30:20,567 [INFO] Initializing SimpleMDAClassifierFactory with model : simple classifier\n","2024-02-09 08:30:20,570 [INFO] Initializing SimplePytorchDataTrainTestSplit\n","2024-02-09 08:30:20,571 [INFO] Start 5-fold Cross Validation with config : adam optimizer\n","2024-02-09 08:30:20,573 [INFO] ---- Fold 1 ----\n","2024-02-09 08:30:20,575 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-09 08:30:20,576 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-09 08:30:20,577 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 08:30:20,578 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 3 layers and with 0.1 dropout\n","2024-02-09 08:30:20,580 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 08:30:20,581 [INFO] moving data and model to cuda\n","2024-02-09 08:30:20,613 [INFO] loss: 0.0211    [1,    10]\n","2024-02-09 08:30:20,633 [INFO] loss: 0.0212    [1,    20]\n","2024-02-09 08:30:20,661 [INFO] loss: 0.0202    [2,    10]\n","2024-02-09 08:30:20,681 [INFO] loss: 0.0187    [2,    20]\n","2024-02-09 08:30:20,721 [INFO] loss: 0.0188    [3,    10]\n","2024-02-09 08:30:20,752 [INFO] loss: 0.0205    [3,    20]\n","2024-02-09 08:30:20,791 [INFO] loss: 0.0191    [4,    10]\n","2024-02-09 08:30:20,819 [INFO] loss: 0.0179    [4,    20]\n","2024-02-09 08:30:20,853 [INFO] loss: 0.0183    [5,    10]\n","2024-02-09 08:30:20,881 [INFO] loss: 0.0187    [5,    20]\n","2024-02-09 08:30:20,918 [INFO] loss: 0.0179    [6,    10]\n","2024-02-09 08:30:20,947 [INFO] loss: 0.0183    [6,    20]\n","2024-02-09 08:30:20,983 [INFO] loss: 0.0186    [7,    10]\n","2024-02-09 08:30:21,009 [INFO] loss: 0.0175    [7,    20]\n","2024-02-09 08:30:21,035 [INFO] loss: 0.0174    [8,    10]\n","2024-02-09 08:30:21,056 [INFO] loss: 0.0179    [8,    20]\n","2024-02-09 08:30:21,085 [INFO] loss: 0.0173    [9,    10]\n","2024-02-09 08:30:21,106 [INFO] loss: 0.0171    [9,    20]\n","2024-02-09 08:30:21,138 [INFO] loss: 0.0169    [10,    10]\n","2024-02-09 08:30:21,158 [INFO] loss: 0.0184    [10,    20]\n","2024-02-09 08:30:21,184 [INFO] loss: 0.0180    [11,    10]\n","2024-02-09 08:30:21,204 [INFO] loss: 0.0175    [11,    20]\n","2024-02-09 08:30:21,229 [INFO] loss: 0.0170    [12,    10]\n","2024-02-09 08:30:21,251 [INFO] loss: 0.0176    [12,    20]\n","2024-02-09 08:30:21,279 [INFO] loss: 0.0168    [13,    10]\n","2024-02-09 08:30:21,299 [INFO] loss: 0.0164    [13,    20]\n","2024-02-09 08:30:21,325 [INFO] loss: 0.0166    [14,    10]\n","2024-02-09 08:30:21,345 [INFO] loss: 0.0170    [14,    20]\n","2024-02-09 08:30:21,372 [INFO] loss: 0.0163    [15,    10]\n","2024-02-09 08:30:21,393 [INFO] loss: 0.0165    [15,    20]\n","2024-02-09 08:30:21,421 [INFO] loss: 0.0160    [16,    10]\n","2024-02-09 08:30:21,443 [INFO] loss: 0.0161    [16,    20]\n","2024-02-09 08:30:21,482 [INFO] loss: 0.0169    [17,    10]\n","2024-02-09 08:30:21,504 [INFO] loss: 0.0150    [17,    20]\n","2024-02-09 08:30:21,531 [INFO] loss: 0.0155    [18,    10]\n","2024-02-09 08:30:21,552 [INFO] loss: 0.0158    [18,    20]\n","2024-02-09 08:30:21,580 [INFO] loss: 0.0155    [19,    10]\n","2024-02-09 08:30:21,601 [INFO] loss: 0.0165    [19,    20]\n","2024-02-09 08:30:21,631 [INFO] loss: 0.0152    [20,    10]\n","2024-02-09 08:30:21,651 [INFO] loss: 0.0170    [20,    20]\n","2024-02-09 08:30:21,677 [INFO] loss: 0.0164    [21,    10]\n","2024-02-09 08:30:21,697 [INFO] loss: 0.0155    [21,    20]\n","2024-02-09 08:30:21,724 [INFO] loss: 0.0159    [22,    10]\n","2024-02-09 08:30:21,745 [INFO] loss: 0.0155    [22,    20]\n","2024-02-09 08:30:21,772 [INFO] loss: 0.0158    [23,    10]\n","2024-02-09 08:30:21,795 [INFO] loss: 0.0160    [23,    20]\n","2024-02-09 08:30:21,822 [INFO] loss: 0.0148    [24,    10]\n","2024-02-09 08:30:21,843 [INFO] loss: 0.0158    [24,    20]\n","2024-02-09 08:30:21,870 [INFO] loss: 0.0156    [25,    10]\n","2024-02-09 08:30:21,890 [INFO] loss: 0.0158    [25,    20]\n","2024-02-09 08:30:21,917 [INFO] loss: 0.0157    [26,    10]\n","2024-02-09 08:30:21,939 [INFO] loss: 0.0147    [26,    20]\n","2024-02-09 08:30:21,970 [INFO] loss: 0.0168    [27,    10]\n","2024-02-09 08:30:21,991 [INFO] loss: 0.0164    [27,    20]\n","2024-02-09 08:30:22,017 [INFO] loss: 0.0160    [28,    10]\n","2024-02-09 08:30:22,038 [INFO] loss: 0.0148    [28,    20]\n","2024-02-09 08:30:22,069 [INFO] loss: 0.0155    [29,    10]\n","2024-02-09 08:30:22,092 [INFO] loss: 0.0153    [29,    20]\n","2024-02-09 08:30:22,122 [INFO] loss: 0.0153    [30,    10]\n","2024-02-09 08:30:22,150 [INFO] loss: 0.0155    [30,    20]\n","2024-02-09 08:30:22,184 [INFO] loss: 0.0147    [31,    10]\n","2024-02-09 08:30:22,206 [INFO] loss: 0.0171    [31,    20]\n","2024-02-09 08:30:22,231 [INFO] loss: 0.0159    [32,    10]\n","2024-02-09 08:30:22,252 [INFO] loss: 0.0166    [32,    20]\n","2024-02-09 08:30:22,278 [INFO] loss: 0.0158    [33,    10]\n","2024-02-09 08:30:22,298 [INFO] loss: 0.0155    [33,    20]\n","2024-02-09 08:30:22,328 [INFO] loss: 0.0156    [34,    10]\n","2024-02-09 08:30:22,348 [INFO] loss: 0.0161    [34,    20]\n","2024-02-09 08:30:22,374 [INFO] loss: 0.0158    [35,    10]\n","2024-02-09 08:30:22,394 [INFO] loss: 0.0154    [35,    20]\n","2024-02-09 08:30:22,420 [INFO] loss: 0.0155    [36,    10]\n","2024-02-09 08:30:22,440 [INFO] loss: 0.0148    [36,    20]\n","2024-02-09 08:30:22,466 [INFO] loss: 0.0149    [37,    10]\n","2024-02-09 08:30:22,487 [INFO] loss: 0.0149    [37,    20]\n","2024-02-09 08:30:22,513 [INFO] loss: 0.0152    [38,    10]\n","2024-02-09 08:30:22,535 [INFO] loss: 0.0144    [38,    20]\n","2024-02-09 08:30:22,562 [INFO] loss: 0.0149    [39,    10]\n","2024-02-09 08:30:22,583 [INFO] loss: 0.0142    [39,    20]\n","2024-02-09 08:30:22,611 [INFO] loss: 0.0144    [40,    10]\n","2024-02-09 08:30:22,632 [INFO] loss: 0.0147    [40,    20]\n","2024-02-09 08:30:22,658 [INFO] loss: 0.0147    [41,    10]\n","2024-02-09 08:30:22,682 [INFO] loss: 0.0183    [41,    20]\n","2024-02-09 08:30:22,711 [INFO] loss: 0.0167    [42,    10]\n","2024-02-09 08:30:22,734 [INFO] loss: 0.0165    [42,    20]\n","2024-02-09 08:30:22,764 [INFO] loss: 0.0160    [43,    10]\n","2024-02-09 08:30:22,786 [INFO] loss: 0.0172    [43,    20]\n","2024-02-09 08:30:22,814 [INFO] loss: 0.0147    [44,    10]\n","2024-02-09 08:30:22,835 [INFO] loss: 0.0162    [44,    20]\n","2024-02-09 08:30:22,865 [INFO] loss: 0.0174    [45,    10]\n","2024-02-09 08:30:22,891 [INFO] loss: 0.0156    [45,    20]\n","2024-02-09 08:30:22,921 [INFO] loss: 0.0147    [46,    10]\n","2024-02-09 08:30:22,942 [INFO] loss: 0.0145    [46,    20]\n","2024-02-09 08:30:22,969 [INFO] loss: 0.0148    [47,    10]\n","2024-02-09 08:30:22,991 [INFO] loss: 0.0143    [47,    20]\n","2024-02-09 08:30:23,017 [INFO] loss: 0.0136    [48,    10]\n","2024-02-09 08:30:23,038 [INFO] loss: 0.0153    [48,    20]\n","2024-02-09 08:30:23,064 [INFO] loss: 0.0157    [49,    10]\n","2024-02-09 08:30:23,099 [INFO] loss: 0.0145    [49,    20]\n","2024-02-09 08:30:23,167 [INFO] loss: 0.0148    [50,    10]\n","2024-02-09 08:30:23,223 [INFO] loss: 0.0150    [50,    20]\n","2024-02-09 08:30:23,340 [INFO] Result on Train Data : {'AUC': 0.8649357684568951, 'ACC': 0.7705146036161336, 'F1 Score': 0.770214125918824, 'AUPR': 0, 'Loss': 0.44311780903650366}\n","2024-02-09 08:30:23,345 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 08:30:23,352 [INFO] moving data and model to cuda\n","2024-02-09 08:30:23,384 [INFO] Result on Test Data : {'AUC': 0.8458072590738424, 'ACC': 0.7486033519553073, 'F1 Score': 0.7481001970166057, 'AUPR': 0, 'Loss': 0.48500579098860425}\n","2024-02-09 08:30:23,389 [INFO] Result of fold 1 : {'AUC': 0.8458072590738424, 'ACC': 0.7486033519553073, 'F1 Score': 0.7481001970166057, 'AUPR': 0, 'Loss': 0.48500579098860425}\n","2024-02-09 08:30:23,394 [INFO] ---- Fold 2 ----\n","2024-02-09 08:30:23,400 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-09 08:30:23,405 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-09 08:30:23,410 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 08:30:23,412 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 3 layers and with 0.1 dropout\n","2024-02-09 08:30:23,417 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 08:30:23,420 [INFO] moving data and model to cuda\n","2024-02-09 08:30:23,456 [INFO] loss: 0.0217    [1,    10]\n","2024-02-09 08:30:23,492 [INFO] loss: 0.0208    [1,    20]\n","2024-02-09 08:30:23,528 [INFO] loss: 0.0199    [2,    10]\n","2024-02-09 08:30:23,559 [INFO] loss: 0.0203    [2,    20]\n","2024-02-09 08:30:23,598 [INFO] loss: 0.0196    [3,    10]\n","2024-02-09 08:30:23,645 [INFO] loss: 0.0199    [3,    20]\n","2024-02-09 08:30:23,686 [INFO] loss: 0.0193    [4,    10]\n","2024-02-09 08:30:23,716 [INFO] loss: 0.0194    [4,    20]\n","2024-02-09 08:30:23,758 [INFO] loss: 0.0190    [5,    10]\n","2024-02-09 08:30:23,813 [INFO] loss: 0.0187    [5,    20]\n","2024-02-09 08:30:23,849 [INFO] loss: 0.0188    [6,    10]\n","2024-02-09 08:30:23,877 [INFO] loss: 0.0184    [6,    20]\n","2024-02-09 08:30:23,919 [INFO] loss: 0.0191    [7,    10]\n","2024-02-09 08:30:23,946 [INFO] loss: 0.0171    [7,    20]\n","2024-02-09 08:30:23,980 [INFO] loss: 0.0179    [8,    10]\n","2024-02-09 08:30:24,010 [INFO] loss: 0.0191    [8,    20]\n","2024-02-09 08:30:24,043 [INFO] loss: 0.0187    [9,    10]\n","2024-02-09 08:30:24,069 [INFO] loss: 0.0178    [9,    20]\n","2024-02-09 08:30:24,103 [INFO] loss: 0.0179    [10,    10]\n","2024-02-09 08:30:24,129 [INFO] loss: 0.0180    [10,    20]\n","2024-02-09 08:30:24,162 [INFO] loss: 0.0175    [11,    10]\n","2024-02-09 08:30:24,190 [INFO] loss: 0.0177    [11,    20]\n","2024-02-09 08:30:24,251 [INFO] loss: 0.0178    [12,    10]\n","2024-02-09 08:30:24,280 [INFO] loss: 0.0181    [12,    20]\n","2024-02-09 08:30:24,316 [INFO] loss: 0.0181    [13,    10]\n","2024-02-09 08:30:24,342 [INFO] loss: 0.0183    [13,    20]\n","2024-02-09 08:30:24,377 [INFO] loss: 0.0171    [14,    10]\n","2024-02-09 08:30:24,408 [INFO] loss: 0.0181    [14,    20]\n","2024-02-09 08:30:24,443 [INFO] loss: 0.0167    [15,    10]\n","2024-02-09 08:30:24,472 [INFO] loss: 0.0173    [15,    20]\n","2024-02-09 08:30:24,511 [INFO] loss: 0.0182    [16,    10]\n","2024-02-09 08:30:24,544 [INFO] loss: 0.0171    [16,    20]\n","2024-02-09 08:30:24,584 [INFO] loss: 0.0176    [17,    10]\n","2024-02-09 08:30:24,615 [INFO] loss: 0.0173    [17,    20]\n","2024-02-09 08:30:24,656 [INFO] loss: 0.0171    [18,    10]\n","2024-02-09 08:30:24,724 [INFO] loss: 0.0165    [18,    20]\n","2024-02-09 08:30:24,765 [INFO] loss: 0.0181    [19,    10]\n","2024-02-09 08:30:24,797 [INFO] loss: 0.0167    [19,    20]\n","2024-02-09 08:30:24,848 [INFO] loss: 0.0175    [20,    10]\n","2024-02-09 08:30:24,881 [INFO] loss: 0.0172    [20,    20]\n","2024-02-09 08:30:24,940 [INFO] loss: 0.0149    [21,    10]\n","2024-02-09 08:30:24,975 [INFO] loss: 0.0202    [21,    20]\n","2024-02-09 08:30:25,013 [INFO] loss: 0.0189    [22,    10]\n","2024-02-09 08:30:25,040 [INFO] loss: 0.0183    [22,    20]\n","2024-02-09 08:30:25,075 [INFO] loss: 0.0176    [23,    10]\n","2024-02-09 08:30:25,101 [INFO] loss: 0.0176    [23,    20]\n","2024-02-09 08:30:25,136 [INFO] loss: 0.0173    [24,    10]\n","2024-02-09 08:30:25,161 [INFO] loss: 0.0169    [24,    20]\n","2024-02-09 08:30:25,197 [INFO] loss: 0.0168    [25,    10]\n","2024-02-09 08:30:25,235 [INFO] loss: 0.0175    [25,    20]\n","2024-02-09 08:30:25,286 [INFO] loss: 0.0161    [26,    10]\n","2024-02-09 08:30:25,314 [INFO] loss: 0.0172    [26,    20]\n","2024-02-09 08:30:25,382 [INFO] loss: 0.0170    [27,    10]\n","2024-02-09 08:30:25,417 [INFO] loss: 0.0161    [27,    20]\n","2024-02-09 08:30:25,467 [INFO] loss: 0.0179    [28,    10]\n","2024-02-09 08:30:25,495 [INFO] loss: 0.0161    [28,    20]\n","2024-02-09 08:30:25,548 [INFO] loss: 0.0169    [29,    10]\n","2024-02-09 08:30:25,595 [INFO] loss: 0.0167    [29,    20]\n","2024-02-09 08:30:25,630 [INFO] loss: 0.0164    [30,    10]\n","2024-02-09 08:30:25,658 [INFO] loss: 0.0161    [30,    20]\n","2024-02-09 08:30:25,694 [INFO] loss: 0.0168    [31,    10]\n","2024-02-09 08:30:25,722 [INFO] loss: 0.0173    [31,    20]\n","2024-02-09 08:30:25,759 [INFO] loss: 0.0161    [32,    10]\n","2024-02-09 08:30:25,786 [INFO] loss: 0.0163    [32,    20]\n","2024-02-09 08:30:25,820 [INFO] loss: 0.0157    [33,    10]\n","2024-02-09 08:30:25,853 [INFO] loss: 0.0164    [33,    20]\n","2024-02-09 08:30:25,892 [INFO] loss: 0.0161    [34,    10]\n","2024-02-09 08:30:25,937 [INFO] loss: 0.0158    [34,    20]\n","2024-02-09 08:30:25,977 [INFO] loss: 0.0164    [35,    10]\n","2024-02-09 08:30:26,021 [INFO] loss: 0.0154    [35,    20]\n","2024-02-09 08:30:26,109 [INFO] loss: 0.0165    [36,    10]\n","2024-02-09 08:30:26,148 [INFO] loss: 0.0168    [36,    20]\n","2024-02-09 08:30:26,229 [INFO] loss: 0.0172    [37,    10]\n","2024-02-09 08:30:26,278 [INFO] loss: 0.0161    [37,    20]\n","2024-02-09 08:30:26,337 [INFO] loss: 0.0149    [38,    10]\n","2024-02-09 08:30:26,399 [INFO] loss: 0.0174    [38,    20]\n","2024-02-09 08:30:26,472 [INFO] loss: 0.0163    [39,    10]\n","2024-02-09 08:30:26,512 [INFO] loss: 0.0164    [39,    20]\n","2024-02-09 08:30:26,557 [INFO] loss: 0.0169    [40,    10]\n","2024-02-09 08:30:26,585 [INFO] loss: 0.0173    [40,    20]\n","2024-02-09 08:30:26,634 [INFO] loss: 0.0173    [41,    10]\n","2024-02-09 08:30:26,663 [INFO] loss: 0.0162    [41,    20]\n","2024-02-09 08:30:26,698 [INFO] loss: 0.0169    [42,    10]\n","2024-02-09 08:30:26,728 [INFO] loss: 0.0176    [42,    20]\n","2024-02-09 08:30:26,767 [INFO] loss: 0.0157    [43,    10]\n","2024-02-09 08:30:26,797 [INFO] loss: 0.0170    [43,    20]\n","2024-02-09 08:30:26,835 [INFO] loss: 0.0163    [44,    10]\n","2024-02-09 08:30:26,863 [INFO] loss: 0.0164    [44,    20]\n","2024-02-09 08:30:26,903 [INFO] loss: 0.0172    [45,    10]\n","2024-02-09 08:30:26,935 [INFO] loss: 0.0154    [45,    20]\n","2024-02-09 08:30:26,969 [INFO] loss: 0.0151    [46,    10]\n","2024-02-09 08:30:27,013 [INFO] loss: 0.0168    [46,    20]\n","2024-02-09 08:30:27,048 [INFO] loss: 0.0161    [47,    10]\n","2024-02-09 08:30:27,075 [INFO] loss: 0.0162    [47,    20]\n","2024-02-09 08:30:27,109 [INFO] loss: 0.0160    [48,    10]\n","2024-02-09 08:30:27,137 [INFO] loss: 0.0144    [48,    20]\n","2024-02-09 08:30:27,171 [INFO] loss: 0.0159    [49,    10]\n","2024-02-09 08:30:27,199 [INFO] loss: 0.0160    [49,    20]\n","2024-02-09 08:30:27,254 [INFO] loss: 0.0163    [50,    10]\n","2024-02-09 08:30:27,354 [INFO] loss: 0.0154    [50,    20]\n","2024-02-09 08:30:27,507 [INFO] Result on Train Data : {'AUC': 0.848251044729918, 'ACC': 0.7454798331015299, 'F1 Score': 0.7329063689418929, 'AUPR': 0, 'Loss': 0.4716431783593219}\n","2024-02-09 08:30:27,510 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 08:30:27,514 [INFO] moving data and model to cuda\n","2024-02-09 08:30:27,546 [INFO] Result on Test Data : {'AUC': 0.8529411764705882, 'ACC': 0.7486033519553073, 'F1 Score': 0.7291253320778828, 'AUPR': 0, 'Loss': 0.5876269141832987}\n","2024-02-09 08:30:27,552 [INFO] Result of fold 2 : {'AUC': 0.8529411764705882, 'ACC': 0.7486033519553073, 'F1 Score': 0.7291253320778828, 'AUPR': 0, 'Loss': 0.5876269141832987}\n","2024-02-09 08:30:27,553 [INFO] ---- Fold 3 ----\n","2024-02-09 08:30:27,559 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-09 08:30:27,563 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-09 08:30:27,567 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 08:30:27,571 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 3 layers and with 0.1 dropout\n","2024-02-09 08:30:27,573 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 08:30:27,574 [INFO] moving data and model to cuda\n","2024-02-09 08:30:27,608 [INFO] loss: 0.0218    [1,    10]\n","2024-02-09 08:30:27,649 [INFO] loss: 0.0212    [1,    20]\n","2024-02-09 08:30:27,708 [INFO] loss: 0.0196    [2,    10]\n","2024-02-09 08:30:27,767 [INFO] loss: 0.0193    [2,    20]\n","2024-02-09 08:30:27,809 [INFO] loss: 0.0198    [3,    10]\n","2024-02-09 08:30:27,889 [INFO] loss: 0.0185    [3,    20]\n","2024-02-09 08:30:27,970 [INFO] loss: 0.0193    [4,    10]\n","2024-02-09 08:30:28,023 [INFO] loss: 0.0179    [4,    20]\n","2024-02-09 08:30:28,078 [INFO] loss: 0.0189    [5,    10]\n","2024-02-09 08:30:28,114 [INFO] loss: 0.0188    [5,    20]\n","2024-02-09 08:30:28,165 [INFO] loss: 0.0192    [6,    10]\n","2024-02-09 08:30:28,195 [INFO] loss: 0.0179    [6,    20]\n","2024-02-09 08:30:28,230 [INFO] loss: 0.0187    [7,    10]\n","2024-02-09 08:30:28,256 [INFO] loss: 0.0182    [7,    20]\n","2024-02-09 08:30:28,292 [INFO] loss: 0.0187    [8,    10]\n","2024-02-09 08:30:28,318 [INFO] loss: 0.0184    [8,    20]\n","2024-02-09 08:30:28,390 [INFO] loss: 0.0186    [9,    10]\n","2024-02-09 08:30:28,437 [INFO] loss: 0.0174    [9,    20]\n","2024-02-09 08:30:28,521 [INFO] loss: 0.0170    [10,    10]\n","2024-02-09 08:30:28,572 [INFO] loss: 0.0182    [10,    20]\n","2024-02-09 08:30:28,631 [INFO] loss: 0.0180    [11,    10]\n","2024-02-09 08:30:28,663 [INFO] loss: 0.0174    [11,    20]\n","2024-02-09 08:30:28,732 [INFO] loss: 0.0179    [12,    10]\n","2024-02-09 08:30:28,760 [INFO] loss: 0.0169    [12,    20]\n","2024-02-09 08:30:28,832 [INFO] loss: 0.0174    [13,    10]\n","2024-02-09 08:30:28,907 [INFO] loss: 0.0177    [13,    20]\n","2024-02-09 08:30:28,958 [INFO] loss: 0.0167    [14,    10]\n","2024-02-09 08:30:28,998 [INFO] loss: 0.0194    [14,    20]\n","2024-02-09 08:30:29,043 [INFO] loss: 0.0187    [15,    10]\n","2024-02-09 08:30:29,101 [INFO] loss: 0.0172    [15,    20]\n","2024-02-09 08:30:29,137 [INFO] loss: 0.0166    [16,    10]\n","2024-02-09 08:30:29,174 [INFO] loss: 0.0165    [16,    20]\n","2024-02-09 08:30:29,229 [INFO] loss: 0.0166    [17,    10]\n","2024-02-09 08:30:29,273 [INFO] loss: 0.0169    [17,    20]\n","2024-02-09 08:30:29,327 [INFO] loss: 0.0175    [18,    10]\n","2024-02-09 08:30:29,377 [INFO] loss: 0.0163    [18,    20]\n","2024-02-09 08:30:29,439 [INFO] loss: 0.0170    [19,    10]\n","2024-02-09 08:30:29,493 [INFO] loss: 0.0158    [19,    20]\n","2024-02-09 08:30:29,519 [INFO] loss: 0.0166    [20,    10]\n","2024-02-09 08:30:29,543 [INFO] loss: 0.0160    [20,    20]\n","2024-02-09 08:30:29,571 [INFO] loss: 0.0149    [21,    10]\n","2024-02-09 08:30:29,593 [INFO] loss: 0.0172    [21,    20]\n","2024-02-09 08:30:29,620 [INFO] loss: 0.0173    [22,    10]\n","2024-02-09 08:30:29,644 [INFO] loss: 0.0164    [22,    20]\n","2024-02-09 08:30:29,670 [INFO] loss: 0.0165    [23,    10]\n","2024-02-09 08:30:29,693 [INFO] loss: 0.0171    [23,    20]\n","2024-02-09 08:30:29,720 [INFO] loss: 0.0168    [24,    10]\n","2024-02-09 08:30:29,741 [INFO] loss: 0.0151    [24,    20]\n","2024-02-09 08:30:29,768 [INFO] loss: 0.0161    [25,    10]\n","2024-02-09 08:30:29,792 [INFO] loss: 0.0158    [25,    20]\n","2024-02-09 08:30:29,828 [INFO] loss: 0.0159    [26,    10]\n","2024-02-09 08:30:29,855 [INFO] loss: 0.0175    [26,    20]\n","2024-02-09 08:30:29,898 [INFO] loss: 0.0149    [27,    10]\n","2024-02-09 08:30:29,925 [INFO] loss: 0.0180    [27,    20]\n","2024-02-09 08:30:29,960 [INFO] loss: 0.0175    [28,    10]\n","2024-02-09 08:30:29,985 [INFO] loss: 0.0168    [28,    20]\n","2024-02-09 08:30:30,019 [INFO] loss: 0.0164    [29,    10]\n","2024-02-09 08:30:30,049 [INFO] loss: 0.0162    [29,    20]\n","2024-02-09 08:30:30,083 [INFO] loss: 0.0152    [30,    10]\n","2024-02-09 08:30:30,111 [INFO] loss: 0.0159    [30,    20]\n","2024-02-09 08:30:30,143 [INFO] loss: 0.0159    [31,    10]\n","2024-02-09 08:30:30,167 [INFO] loss: 0.0171    [31,    20]\n","2024-02-09 08:30:30,198 [INFO] loss: 0.0150    [32,    10]\n","2024-02-09 08:30:30,225 [INFO] loss: 0.0171    [32,    20]\n","2024-02-09 08:30:30,256 [INFO] loss: 0.0161    [33,    10]\n","2024-02-09 08:30:30,280 [INFO] loss: 0.0153    [33,    20]\n","2024-02-09 08:30:30,313 [INFO] loss: 0.0138    [34,    10]\n","2024-02-09 08:30:30,340 [INFO] loss: 0.0165    [34,    20]\n","2024-02-09 08:30:30,372 [INFO] loss: 0.0149    [35,    10]\n","2024-02-09 08:30:30,401 [INFO] loss: 0.0148    [35,    20]\n","2024-02-09 08:30:30,437 [INFO] loss: 0.0145    [36,    10]\n","2024-02-09 08:30:30,462 [INFO] loss: 0.0155    [36,    20]\n","2024-02-09 08:30:30,496 [INFO] loss: 0.0147    [37,    10]\n","2024-02-09 08:30:30,522 [INFO] loss: 0.0164    [37,    20]\n","2024-02-09 08:30:30,558 [INFO] loss: 0.0141    [38,    10]\n","2024-02-09 08:30:30,586 [INFO] loss: 0.0154    [38,    20]\n","2024-02-09 08:30:30,619 [INFO] loss: 0.0158    [39,    10]\n","2024-02-09 08:30:30,646 [INFO] loss: 0.0137    [39,    20]\n","2024-02-09 08:30:30,681 [INFO] loss: 0.0147    [40,    10]\n","2024-02-09 08:30:30,707 [INFO] loss: 0.0158    [40,    20]\n","2024-02-09 08:30:30,742 [INFO] loss: 0.0147    [41,    10]\n","2024-02-09 08:30:30,772 [INFO] loss: 0.0145    [41,    20]\n","2024-02-09 08:30:30,809 [INFO] loss: 0.0164    [42,    10]\n","2024-02-09 08:30:30,838 [INFO] loss: 0.0140    [42,    20]\n","2024-02-09 08:30:30,873 [INFO] loss: 0.0149    [43,    10]\n","2024-02-09 08:30:30,904 [INFO] loss: 0.0155    [43,    20]\n","2024-02-09 08:30:30,940 [INFO] loss: 0.0144    [44,    10]\n","2024-02-09 08:30:30,970 [INFO] loss: 0.0151    [44,    20]\n","2024-02-09 08:30:31,005 [INFO] loss: 0.0155    [45,    10]\n","2024-02-09 08:30:31,035 [INFO] loss: 0.0148    [45,    20]\n","2024-02-09 08:30:31,073 [INFO] loss: 0.0153    [46,    10]\n","2024-02-09 08:30:31,100 [INFO] loss: 0.0156    [46,    20]\n","2024-02-09 08:30:31,137 [INFO] loss: 0.0160    [47,    10]\n","2024-02-09 08:30:31,164 [INFO] loss: 0.0157    [47,    20]\n","2024-02-09 08:30:31,198 [INFO] loss: 0.0151    [48,    10]\n","2024-02-09 08:30:31,224 [INFO] loss: 0.0157    [48,    20]\n","2024-02-09 08:30:31,258 [INFO] loss: 0.0151    [49,    10]\n","2024-02-09 08:30:31,287 [INFO] loss: 0.0157    [49,    20]\n","2024-02-09 08:30:31,323 [INFO] loss: 0.0147    [50,    10]\n","2024-02-09 08:30:31,350 [INFO] loss: 0.0153    [50,    20]\n","2024-02-09 08:30:31,428 [INFO] Result on Train Data : {'AUC': 0.8547326058354617, 'ACC': 0.7538247566063978, 'F1 Score': 0.7535024259856474, 'AUPR': 0, 'Loss': 0.45950330469919287}\n","2024-02-09 08:30:31,432 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 08:30:31,436 [INFO] moving data and model to cuda\n","2024-02-09 08:30:31,479 [INFO] Result on Test Data : {'AUC': 0.8151629072681704, 'ACC': 0.6815642458100558, 'F1 Score': 0.681524487311546, 'AUPR': 0, 'Loss': 0.5155720959107081}\n","2024-02-09 08:30:31,482 [INFO] Result of fold 3 : {'AUC': 0.8151629072681704, 'ACC': 0.6815642458100558, 'F1 Score': 0.681524487311546, 'AUPR': 0, 'Loss': 0.5155720959107081}\n","2024-02-09 08:30:31,483 [INFO] ---- Fold 4 ----\n","2024-02-09 08:30:31,487 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-09 08:30:31,489 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-09 08:30:31,493 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 08:30:31,495 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 3 layers and with 0.1 dropout\n","2024-02-09 08:30:31,498 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 08:30:31,500 [INFO] moving data and model to cuda\n","2024-02-09 08:30:31,537 [INFO] loss: 0.0217    [1,    10]\n","2024-02-09 08:30:31,563 [INFO] loss: 0.0208    [1,    20]\n","2024-02-09 08:30:31,597 [INFO] loss: 0.0202    [2,    10]\n","2024-02-09 08:30:31,624 [INFO] loss: 0.0195    [2,    20]\n","2024-02-09 08:30:31,658 [INFO] loss: 0.0195    [3,    10]\n","2024-02-09 08:30:31,685 [INFO] loss: 0.0181    [3,    20]\n","2024-02-09 08:30:31,718 [INFO] loss: 0.0190    [4,    10]\n","2024-02-09 08:30:31,745 [INFO] loss: 0.0194    [4,    20]\n","2024-02-09 08:30:31,779 [INFO] loss: 0.0186    [5,    10]\n","2024-02-09 08:30:31,808 [INFO] loss: 0.0180    [5,    20]\n","2024-02-09 08:30:31,844 [INFO] loss: 0.0181    [6,    10]\n","2024-02-09 08:30:31,878 [INFO] loss: 0.0177    [6,    20]\n","2024-02-09 08:30:31,917 [INFO] loss: 0.0188    [7,    10]\n","2024-02-09 08:30:31,949 [INFO] loss: 0.0175    [7,    20]\n","2024-02-09 08:30:31,988 [INFO] loss: 0.0172    [8,    10]\n","2024-02-09 08:30:32,015 [INFO] loss: 0.0188    [8,    20]\n","2024-02-09 08:30:32,051 [INFO] loss: 0.0178    [9,    10]\n","2024-02-09 08:30:32,076 [INFO] loss: 0.0182    [9,    20]\n","2024-02-09 08:30:32,107 [INFO] loss: 0.0190    [10,    10]\n","2024-02-09 08:30:32,136 [INFO] loss: 0.0167    [10,    20]\n","2024-02-09 08:30:32,175 [INFO] loss: 0.0186    [11,    10]\n","2024-02-09 08:30:32,201 [INFO] loss: 0.0165    [11,    20]\n","2024-02-09 08:30:32,234 [INFO] loss: 0.0184    [12,    10]\n","2024-02-09 08:30:32,267 [INFO] loss: 0.0182    [12,    20]\n","2024-02-09 08:30:32,305 [INFO] loss: 0.0179    [13,    10]\n","2024-02-09 08:30:32,333 [INFO] loss: 0.0170    [13,    20]\n","2024-02-09 08:30:32,370 [INFO] loss: 0.0171    [14,    10]\n","2024-02-09 08:30:32,400 [INFO] loss: 0.0167    [14,    20]\n","2024-02-09 08:30:32,437 [INFO] loss: 0.0168    [15,    10]\n","2024-02-09 08:30:32,466 [INFO] loss: 0.0168    [15,    20]\n","2024-02-09 08:30:32,503 [INFO] loss: 0.0173    [16,    10]\n","2024-02-09 08:30:32,537 [INFO] loss: 0.0166    [16,    20]\n","2024-02-09 08:30:32,578 [INFO] loss: 0.0174    [17,    10]\n","2024-02-09 08:30:32,607 [INFO] loss: 0.0175    [17,    20]\n","2024-02-09 08:30:32,642 [INFO] loss: 0.0158    [18,    10]\n","2024-02-09 08:30:32,665 [INFO] loss: 0.0176    [18,    20]\n","2024-02-09 08:30:32,692 [INFO] loss: 0.0167    [19,    10]\n","2024-02-09 08:30:32,713 [INFO] loss: 0.0167    [19,    20]\n","2024-02-09 08:30:32,740 [INFO] loss: 0.0167    [20,    10]\n","2024-02-09 08:30:32,763 [INFO] loss: 0.0160    [20,    20]\n","2024-02-09 08:30:32,790 [INFO] loss: 0.0164    [21,    10]\n","2024-02-09 08:30:32,814 [INFO] loss: 0.0156    [21,    20]\n","2024-02-09 08:30:32,840 [INFO] loss: 0.0154    [22,    10]\n","2024-02-09 08:30:32,860 [INFO] loss: 0.0174    [22,    20]\n","2024-02-09 08:30:32,888 [INFO] loss: 0.0161    [23,    10]\n","2024-02-09 08:30:32,909 [INFO] loss: 0.0168    [23,    20]\n","2024-02-09 08:30:32,936 [INFO] loss: 0.0162    [24,    10]\n","2024-02-09 08:30:32,957 [INFO] loss: 0.0161    [24,    20]\n","2024-02-09 08:30:32,982 [INFO] loss: 0.0162    [25,    10]\n","2024-02-09 08:30:33,003 [INFO] loss: 0.0162    [25,    20]\n","2024-02-09 08:30:33,030 [INFO] loss: 0.0152    [26,    10]\n","2024-02-09 08:30:33,051 [INFO] loss: 0.0169    [26,    20]\n","2024-02-09 08:30:33,076 [INFO] loss: 0.0162    [27,    10]\n","2024-02-09 08:30:33,096 [INFO] loss: 0.0156    [27,    20]\n","2024-02-09 08:30:33,122 [INFO] loss: 0.0163    [28,    10]\n","2024-02-09 08:30:33,142 [INFO] loss: 0.0153    [28,    20]\n","2024-02-09 08:30:33,169 [INFO] loss: 0.0151    [29,    10]\n","2024-02-09 08:30:33,193 [INFO] loss: 0.0152    [29,    20]\n","2024-02-09 08:30:33,220 [INFO] loss: 0.0154    [30,    10]\n","2024-02-09 08:30:33,242 [INFO] loss: 0.0164    [30,    20]\n","2024-02-09 08:30:33,270 [INFO] loss: 0.0148    [31,    10]\n","2024-02-09 08:30:33,291 [INFO] loss: 0.0165    [31,    20]\n","2024-02-09 08:30:33,319 [INFO] loss: 0.0146    [32,    10]\n","2024-02-09 08:30:33,339 [INFO] loss: 0.0158    [32,    20]\n","2024-02-09 08:30:33,364 [INFO] loss: 0.0156    [33,    10]\n","2024-02-09 08:30:33,385 [INFO] loss: 0.0159    [33,    20]\n","2024-02-09 08:30:33,421 [INFO] loss: 0.0151    [34,    10]\n","2024-02-09 08:30:33,443 [INFO] loss: 0.0160    [34,    20]\n","2024-02-09 08:30:33,470 [INFO] loss: 0.0151    [35,    10]\n","2024-02-09 08:30:33,493 [INFO] loss: 0.0153    [35,    20]\n","2024-02-09 08:30:33,520 [INFO] loss: 0.0157    [36,    10]\n","2024-02-09 08:30:33,540 [INFO] loss: 0.0161    [36,    20]\n","2024-02-09 08:30:33,580 [INFO] loss: 0.0147    [37,    10]\n","2024-02-09 08:30:33,601 [INFO] loss: 0.0162    [37,    20]\n","2024-02-09 08:30:33,628 [INFO] loss: 0.0154    [38,    10]\n","2024-02-09 08:30:33,649 [INFO] loss: 0.0166    [38,    20]\n","2024-02-09 08:30:33,677 [INFO] loss: 0.0150    [39,    10]\n","2024-02-09 08:30:33,698 [INFO] loss: 0.0133    [39,    20]\n","2024-02-09 08:30:33,725 [INFO] loss: 0.0145    [40,    10]\n","2024-02-09 08:30:33,748 [INFO] loss: 0.0148    [40,    20]\n","2024-02-09 08:30:33,776 [INFO] loss: 0.0158    [41,    10]\n","2024-02-09 08:30:33,797 [INFO] loss: 0.0146    [41,    20]\n","2024-02-09 08:30:33,824 [INFO] loss: 0.0161    [42,    10]\n","2024-02-09 08:30:33,845 [INFO] loss: 0.0153    [42,    20]\n","2024-02-09 08:30:33,873 [INFO] loss: 0.0138    [43,    10]\n","2024-02-09 08:30:33,897 [INFO] loss: 0.0153    [43,    20]\n","2024-02-09 08:30:33,928 [INFO] loss: 0.0138    [44,    10]\n","2024-02-09 08:30:33,949 [INFO] loss: 0.0163    [44,    20]\n","2024-02-09 08:30:33,976 [INFO] loss: 0.0155    [45,    10]\n","2024-02-09 08:30:33,996 [INFO] loss: 0.0141    [45,    20]\n","2024-02-09 08:30:34,022 [INFO] loss: 0.0164    [46,    10]\n","2024-02-09 08:30:34,043 [INFO] loss: 0.0159    [46,    20]\n","2024-02-09 08:30:34,069 [INFO] loss: 0.0147    [47,    10]\n","2024-02-09 08:30:34,090 [INFO] loss: 0.0154    [47,    20]\n","2024-02-09 08:30:34,116 [INFO] loss: 0.0157    [48,    10]\n","2024-02-09 08:30:34,137 [INFO] loss: 0.0143    [48,    20]\n","2024-02-09 08:30:34,163 [INFO] loss: 0.0156    [49,    10]\n","2024-02-09 08:30:34,183 [INFO] loss: 0.0152    [49,    20]\n","2024-02-09 08:30:34,210 [INFO] loss: 0.0153    [50,    10]\n","2024-02-09 08:30:34,230 [INFO] loss: 0.0152    [50,    20]\n","2024-02-09 08:30:34,276 [INFO] Result on Train Data : {'AUC': 0.8684271664214358, 'ACC': 0.7760778859527121, 'F1 Score': 0.7755151115549824, 'AUPR': 0, 'Loss': 0.44920519123906677}\n","2024-02-09 08:30:34,277 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 08:30:34,279 [INFO] moving data and model to cuda\n","2024-02-09 08:30:34,299 [INFO] Result on Test Data : {'AUC': 0.8410126582278481, 'ACC': 0.7039106145251397, 'F1 Score': 0.7038736460967007, 'AUPR': 0, 'Loss': 0.5343165397644043}\n","2024-02-09 08:30:34,300 [INFO] Result of fold 4 : {'AUC': 0.8410126582278481, 'ACC': 0.7039106145251397, 'F1 Score': 0.7038736460967007, 'AUPR': 0, 'Loss': 0.5343165397644043}\n","2024-02-09 08:30:34,304 [INFO] ---- Fold 5 ----\n","2024-02-09 08:30:34,307 [INFO] Initializing SimplePytorchData with X shape : torch.Size([716, 64]) and y shape : torch.Size([716, 1])\n","2024-02-09 08:30:34,309 [INFO] Initializing SimplePytorchData with X shape : torch.Size([182, 64]) and y shape : torch.Size([182, 1])\n","2024-02-09 08:30:34,311 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 08:30:34,313 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 3 layers and with 0.1 dropout\n","2024-02-09 08:30:34,315 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 08:30:34,317 [INFO] moving data and model to cuda\n","2024-02-09 08:30:34,343 [INFO] loss: 0.0214    [1,    10]\n","2024-02-09 08:30:34,364 [INFO] loss: 0.0201    [1,    20]\n","2024-02-09 08:30:34,390 [INFO] loss: 0.0185    [2,    10]\n","2024-02-09 08:30:34,410 [INFO] loss: 0.0196    [2,    20]\n","2024-02-09 08:30:34,438 [INFO] loss: 0.0188    [3,    10]\n","2024-02-09 08:30:34,461 [INFO] loss: 0.0193    [3,    20]\n","2024-02-09 08:30:34,490 [INFO] loss: 0.0188    [4,    10]\n","2024-02-09 08:30:34,511 [INFO] loss: 0.0174    [4,    20]\n","2024-02-09 08:30:34,539 [INFO] loss: 0.0185    [5,    10]\n","2024-02-09 08:30:34,559 [INFO] loss: 0.0191    [5,    20]\n","2024-02-09 08:30:34,589 [INFO] loss: 0.0181    [6,    10]\n","2024-02-09 08:30:34,615 [INFO] loss: 0.0185    [6,    20]\n","2024-02-09 08:30:34,641 [INFO] loss: 0.0176    [7,    10]\n","2024-02-09 08:30:34,663 [INFO] loss: 0.0176    [7,    20]\n","2024-02-09 08:30:34,690 [INFO] loss: 0.0185    [8,    10]\n","2024-02-09 08:30:34,712 [INFO] loss: 0.0170    [8,    20]\n","2024-02-09 08:30:34,738 [INFO] loss: 0.0174    [9,    10]\n","2024-02-09 08:30:34,762 [INFO] loss: 0.0177    [9,    20]\n","2024-02-09 08:30:34,790 [INFO] loss: 0.0167    [10,    10]\n","2024-02-09 08:30:34,811 [INFO] loss: 0.0178    [10,    20]\n","2024-02-09 08:30:34,838 [INFO] loss: 0.0162    [11,    10]\n","2024-02-09 08:30:34,860 [INFO] loss: 0.0184    [11,    20]\n","2024-02-09 08:30:34,888 [INFO] loss: 0.0168    [12,    10]\n","2024-02-09 08:30:34,909 [INFO] loss: 0.0171    [12,    20]\n","2024-02-09 08:30:34,936 [INFO] loss: 0.0165    [13,    10]\n","2024-02-09 08:30:34,957 [INFO] loss: 0.0183    [13,    20]\n","2024-02-09 08:30:34,984 [INFO] loss: 0.0162    [14,    10]\n","2024-02-09 08:30:35,005 [INFO] loss: 0.0176    [14,    20]\n","2024-02-09 08:30:35,032 [INFO] loss: 0.0169    [15,    10]\n","2024-02-09 08:30:35,053 [INFO] loss: 0.0153    [15,    20]\n","2024-02-09 08:30:35,082 [INFO] loss: 0.0171    [16,    10]\n","2024-02-09 08:30:35,103 [INFO] loss: 0.0155    [16,    20]\n","2024-02-09 08:30:35,130 [INFO] loss: 0.0155    [17,    10]\n","2024-02-09 08:30:35,152 [INFO] loss: 0.0167    [17,    20]\n","2024-02-09 08:30:35,180 [INFO] loss: 0.0162    [18,    10]\n","2024-02-09 08:30:35,202 [INFO] loss: 0.0158    [18,    20]\n","2024-02-09 08:30:35,229 [INFO] loss: 0.0159    [19,    10]\n","2024-02-09 08:30:35,250 [INFO] loss: 0.0155    [19,    20]\n","2024-02-09 08:30:35,277 [INFO] loss: 0.0147    [20,    10]\n","2024-02-09 08:30:35,298 [INFO] loss: 0.0156    [20,    20]\n","2024-02-09 08:30:35,327 [INFO] loss: 0.0154    [21,    10]\n","2024-02-09 08:30:35,351 [INFO] loss: 0.0161    [21,    20]\n","2024-02-09 08:30:35,378 [INFO] loss: 0.0160    [22,    10]\n","2024-02-09 08:30:35,399 [INFO] loss: 0.0163    [22,    20]\n","2024-02-09 08:30:35,425 [INFO] loss: 0.0154    [23,    10]\n","2024-02-09 08:30:35,446 [INFO] loss: 0.0147    [23,    20]\n","2024-02-09 08:30:35,473 [INFO] loss: 0.0146    [24,    10]\n","2024-02-09 08:30:35,494 [INFO] loss: 0.0157    [24,    20]\n","2024-02-09 08:30:35,522 [INFO] loss: 0.0147    [25,    10]\n","2024-02-09 08:30:35,542 [INFO] loss: 0.0150    [25,    20]\n","2024-02-09 08:30:35,572 [INFO] loss: 0.0140    [26,    10]\n","2024-02-09 08:30:35,594 [INFO] loss: 0.0156    [26,    20]\n","2024-02-09 08:30:35,628 [INFO] loss: 0.0158    [27,    10]\n","2024-02-09 08:30:35,649 [INFO] loss: 0.0142    [27,    20]\n","2024-02-09 08:30:35,679 [INFO] loss: 0.0140    [28,    10]\n","2024-02-09 08:30:35,700 [INFO] loss: 0.0145    [28,    20]\n","2024-02-09 08:30:35,727 [INFO] loss: 0.0160    [29,    10]\n","2024-02-09 08:30:35,749 [INFO] loss: 0.0131    [29,    20]\n","2024-02-09 08:30:35,776 [INFO] loss: 0.0151    [30,    10]\n","2024-02-09 08:30:35,798 [INFO] loss: 0.0134    [30,    20]\n","2024-02-09 08:30:35,825 [INFO] loss: 0.0139    [31,    10]\n","2024-02-09 08:30:35,847 [INFO] loss: 0.0148    [31,    20]\n","2024-02-09 08:30:35,873 [INFO] loss: 0.0188    [32,    10]\n","2024-02-09 08:30:35,897 [INFO] loss: 0.0160    [32,    20]\n","2024-02-09 08:30:35,925 [INFO] loss: 0.0146    [33,    10]\n","2024-02-09 08:30:35,947 [INFO] loss: 0.0146    [33,    20]\n","2024-02-09 08:30:35,976 [INFO] loss: 0.0153    [34,    10]\n","2024-02-09 08:30:35,997 [INFO] loss: 0.0143    [34,    20]\n","2024-02-09 08:30:36,022 [INFO] loss: 0.0150    [35,    10]\n","2024-02-09 08:30:36,044 [INFO] loss: 0.0139    [35,    20]\n","2024-02-09 08:30:36,070 [INFO] loss: 0.0141    [36,    10]\n","2024-02-09 08:30:36,090 [INFO] loss: 0.0139    [36,    20]\n","2024-02-09 08:30:36,116 [INFO] loss: 0.0160    [37,    10]\n","2024-02-09 08:30:36,137 [INFO] loss: 0.0137    [37,    20]\n","2024-02-09 08:30:36,163 [INFO] loss: 0.0129    [38,    10]\n","2024-02-09 08:30:36,183 [INFO] loss: 0.0143    [38,    20]\n","2024-02-09 08:30:36,210 [INFO] loss: 0.0122    [39,    10]\n","2024-02-09 08:30:36,232 [INFO] loss: 0.0139    [39,    20]\n","2024-02-09 08:30:36,261 [INFO] loss: 0.0144    [40,    10]\n","2024-02-09 08:30:36,283 [INFO] loss: 0.0148    [40,    20]\n","2024-02-09 08:30:36,310 [INFO] loss: 0.0151    [41,    10]\n","2024-02-09 08:30:36,333 [INFO] loss: 0.0131    [41,    20]\n","2024-02-09 08:30:36,364 [INFO] loss: 0.0143    [42,    10]\n","2024-02-09 08:30:36,386 [INFO] loss: 0.0134    [42,    20]\n","2024-02-09 08:30:36,414 [INFO] loss: 0.0124    [43,    10]\n","2024-02-09 08:30:36,436 [INFO] loss: 0.0145    [43,    20]\n","2024-02-09 08:30:36,464 [INFO] loss: 0.0130    [44,    10]\n","2024-02-09 08:30:36,485 [INFO] loss: 0.0137    [44,    20]\n","2024-02-09 08:30:36,514 [INFO] loss: 0.0134    [45,    10]\n","2024-02-09 08:30:36,535 [INFO] loss: 0.0138    [45,    20]\n","2024-02-09 08:30:36,562 [INFO] loss: 0.0127    [46,    10]\n","2024-02-09 08:30:36,587 [INFO] loss: 0.0133    [46,    20]\n","2024-02-09 08:30:36,615 [INFO] loss: 0.0126    [47,    10]\n","2024-02-09 08:30:36,642 [INFO] loss: 0.0135    [47,    20]\n","2024-02-09 08:30:36,672 [INFO] loss: 0.0147    [48,    10]\n","2024-02-09 08:30:36,694 [INFO] loss: 0.0126    [48,    20]\n","2024-02-09 08:30:36,720 [INFO] loss: 0.0145    [49,    10]\n","2024-02-09 08:30:36,741 [INFO] loss: 0.0139    [49,    20]\n","2024-02-09 08:30:36,769 [INFO] loss: 0.0132    [50,    10]\n","2024-02-09 08:30:36,792 [INFO] loss: 0.0136    [50,    20]\n","2024-02-09 08:30:36,838 [INFO] Result on Train Data : {'AUC': 0.9051264642302499, 'ACC': 0.8086592178770949, 'F1 Score': 0.8057918734792223, 'AUPR': 0, 'Loss': 0.3883110990990763}\n","2024-02-09 08:30:36,839 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 08:30:36,841 [INFO] moving data and model to cuda\n","2024-02-09 08:30:36,860 [INFO] Result on Test Data : {'AUC': 0.8313953488372092, 'ACC': 0.7252747252747253, 'F1 Score': 0.7231349640988195, 'AUPR': 0, 'Loss': 0.5451339334249496}\n","2024-02-09 08:30:36,861 [INFO] Result of fold 5 : {'AUC': 0.8313953488372092, 'ACC': 0.7252747252747253, 'F1 Score': 0.7231349640988195, 'AUPR': 0, 'Loss': 0.5451339334249496}\n","2024-02-09 08:30:36,863 [INFO] 5-fold result: avg_auc: 0.8372638699755317, avg_acc: 0.721591257904107, avg_f1: 0.7171517253203109, avg_aupr: 0.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<base.evaluation.Result at 0x7f778e973c40>"]},"metadata":{},"execution_count":42}],"source":["trainer = SimpleTrainer()\n","tester = SimpleTester()\n","factory = SimpleMDAClassifierFactory(simple_classifier_config)\n","spliter = SimplePytorchDataTrainTestSplit(data)\n","cross_validation(k=5, data_size=data.X.shape[0], train_test_spliter=spliter, model_factory=factory,\n","                    trainer=trainer, tester=tester, config=classifier_optimizer_config)"]},{"cell_type":"code","source":[],"metadata":{"id":"5cpQ0kPkjuHb","executionInfo":{"status":"ok","timestamp":1707467437231,"user_tz":-210,"elapsed":17,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"5cpQ0kPkjuHb","execution_count":42,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}