{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fg4sTOLBNbFJ","executionInfo":{"status":"ok","timestamp":1707463992375,"user_tz":-210,"elapsed":3307,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"dd922886-437e-4723-f5b6-978e0706b540"},"id":"Fg4sTOLBNbFJ","execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Academic/Topics/AI/Machine\\ Learning\\ Dr.\\ Montazeri/Project/ml_mda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkz5A_SiNcle","executionInfo":{"status":"ok","timestamp":1707463992375,"user_tz":-210,"elapsed":5,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"fbc739a9-dc4f-4446-93e0-2ee392a8300b"},"id":"gkz5A_SiNcle","execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Academic/Topics/AI/Machine Learning Dr. Montazeri/Project/ml_mda\n"]}]},{"cell_type":"code","source":["!pip install torch_geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODp_C8LiNecw","executionInfo":{"status":"ok","timestamp":1707463997089,"user_tz":-210,"elapsed":4717,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"2c1e08bd-c7ce-492a-e946-5e3b02382bb7"},"id":"ODp_C8LiNecw","execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"]}]},{"cell_type":"code","source":["!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IaKc5GwjNgRJ","executionInfo":{"status":"ok","timestamp":1707464003127,"user_tz":-210,"elapsed":6044,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"785d2634-2b6a-4320-a606-bd4c26fd01b4"},"id":"IaKc5GwjNgRJ","execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\n","Requirement already satisfied: pyg_lib in /usr/local/lib/python3.10/dist-packages (0.4.0+pt21cu121)\n","Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt21cu121)\n","Requirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt21cu121)\n","Requirement already satisfied: torch_cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt21cu121)\n","Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt21cu121)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n"]}]},{"cell_type":"markdown","source":["# Requirements"],"metadata":{"id":"Syp1fG3XMOu8"},"id":"Syp1fG3XMOu8"},{"cell_type":"code","source":["import torch\n","\n","from base import OptimizerConfig, cross_validation\n","from base import SimplePytorchData, SimplePytorchDataTrainTestSplit\n","from base import SimpleTrainer, SimpleTester\n","from src.config import Node2VecConfig, Node2VecOptimizerConfig, SimpleClassifierConfig, GraphAutoEncoderConfig\n","from src.features import get_associations, get_homogeneous_graph, get_gae_pair_embedd_for_training_data\n","from src.models import SimpleMDAClassifier, SimpleMDAClassifierFactory\n","from src.utils import train_test_sampler, prj_logger\n","from torch_geometric.nn import GCNConv"],"metadata":{"id":"aQN35hGYL9zT","executionInfo":{"status":"ok","timestamp":1707464003127,"user_tz":-210,"elapsed":7,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"aQN35hGYL9zT","execution_count":41,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"fAZ0nEWSMSOU","executionInfo":{"status":"ok","timestamp":1707464003128,"user_tz":-210,"elapsed":7,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"fAZ0nEWSMSOU","execution_count":42,"outputs":[]},{"cell_type":"code","source":["import logging\n","import sys\n","\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n","    handlers=[\n","        logging.StreamHandler(stream=sys.stdout)\n","    ],\n","    force=True\n",")"],"metadata":{"id":"ZhHjiOAeJPHm","executionInfo":{"status":"ok","timestamp":1707464003128,"user_tz":-210,"elapsed":6,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"ZhHjiOAeJPHm","execution_count":43,"outputs":[]},{"cell_type":"code","source":["logger = prj_logger.getLogger(__name__)"],"metadata":{"id":"54ZqlIyeQr6w","executionInfo":{"status":"ok","timestamp":1707464003128,"user_tz":-210,"elapsed":6,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":44,"outputs":[],"id":"54ZqlIyeQr6w"},{"cell_type":"markdown","source":["# Graph Auto Encoder Embedding"],"metadata":{"id":"w-tFOU11MKi9"},"id":"w-tFOU11MKi9"},{"cell_type":"markdown","source":["## Config"],"metadata":{"id":"2IOz4u3RwiZF"},"id":"2IOz4u3RwiZF"},{"cell_type":"code","source":["gae_optimizer_config = OptimizerConfig()\n","gae_optimizer_config.optimizer = torch.optim.Adam\n","gae_optimizer_config.criterion = torch.nn.BCEWithLogitsLoss()\n","gae_optimizer_config.lr = 0.01\n","gae_optimizer_config.n_epoch = 80\n","gae_optimizer_config.exp_name = \"Optimizer for Graph Auto Encoder\"\n","gae_optimizer_config.device = device"],"metadata":{"id":"n53NBIn6f9YK","executionInfo":{"status":"ok","timestamp":1707464003128,"user_tz":-210,"elapsed":6,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"n53NBIn6f9YK","execution_count":45,"outputs":[]},{"cell_type":"code","source":["gae_model_config = GraphAutoEncoderConfig()\n","gae_model_config.model_name = \"Graph Auto Encoder Model\"\n","gae_model_config.device = device\n","gae_model_config.input_dim = get_homogeneous_graph(device).x.shape[0]\n","gae_model_config.hidden_dim = 32\n","gae_model_config.output_dim = 32\n","gae_model_config.num_layers = 3\n","gae_model_config.dropout = 0.5\n","gae_model_config.with_embedd = True\n","gae_model_config.GCN = GCNConv"],"metadata":{"id":"fqtqeaRFgBUf","executionInfo":{"status":"ok","timestamp":1707464005223,"user_tz":-210,"elapsed":2101,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"19c9a64b-add0-4a20-aef5-3747435cabb6"},"id":"fqtqeaRFgBUf","execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 07:33:22,797 [INFO] Calling get_homogeneous_graph\n","2024-02-09 07:33:24,742 [INFO] homogeneous data : Data(x=[66911, 1], edge_index=[2, 633662])\n"]}]},{"cell_type":"markdown","source":["## Embedding"],"metadata":{"id":"5iziBfwEwj6L"},"id":"5iziBfwEwj6L"},{"cell_type":"code","source":["md_embed = get_gae_pair_embedd_for_training_data(gae_model_config, gae_optimizer_config)"],"metadata":{"id":"v3fuUI_AfiBH","executionInfo":{"status":"ok","timestamp":1707464095469,"user_tz":-210,"elapsed":90251,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ea158dac-9d01-408b-eb5a-f7d5485bc968"},"id":"v3fuUI_AfiBH","execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 07:33:24,768 [INFO] Calling get_gae_pair_embedd on cuda device ...\n","2024-02-09 07:33:24,769 [INFO] Calling get_homogeneous_graph\n","2024-02-09 07:33:26,353 [INFO] homogeneous data : Data(x=[66911, 1], edge_index=[2, 633662])\n","2024-02-09 07:33:26,356 [INFO] Calling get_node2vec_embedd on cuda device ...\n","2024-02-09 07:33:26,357 [INFO] Creating GraphAutoEncoderModel ...\n","2024-02-09 07:33:26,361 [INFO] Initializing GraphAutoEncoderModel with config : {'model_name': 'Graph Auto Encoder Model', 'input_dim': 66911, 'hidden_dim': 32, 'output_dim': 32, 'num_layers': 3, 'dropout': 0.5, 'with_embedd': True, 'GCN': <class 'torch_geometric.nn.conv.gcn_conv.GCNConv'>}\n","2024-02-09 07:33:26,363 [INFO] Initializing GCNAutoEncoder ...\n","2024-02-09 07:33:26,372 [INFO] Initial GCNEncoder with 66911 input_dimension,\n","            32 hidden dimension, 32 output dimension,\n","            3 layers and with 0.5 dropout\n","2024-02-09 07:33:26,402 [INFO] Initial LinkDecoder\n","2024-02-09 07:33:26,403 [INFO] Calling get_homogeneous_graph\n","2024-02-09 07:33:27,053 [INFO] homogeneous data : Data(x=[66911, 1], edge_index=[2, 633662])\n","2024-02-09 07:33:27,058 [INFO] Reshape Homogeneous graph : torch.Size([66911])\n","2024-02-09 07:33:27,061 [INFO] Training GraphAutoEncoderModel ...\n","2024-02-09 07:33:27,063 [INFO] Running GraphAutoEncoderTrainer with Optimizer for Graph Auto Encoder\n","2024-02-09 07:33:27,066 [INFO] Creating <class 'torch.optim.adam.Adam'> with lr : 0.01\n","2024-02-09 07:33:27,068 [INFO] moving model to cuda\n","2024-02-09 07:33:27,072 [INFO] moving data x and edge_index to cuda\n","2024-02-09 07:33:28,194 [INFO] loss: 0.6931    [epoch:     1]\n","2024-02-09 07:33:29,193 [INFO] loss: 0.6784    [epoch:     2]\n","2024-02-09 07:33:30,625 [INFO] loss: 0.6470    [epoch:     3]\n","2024-02-09 07:33:32,481 [INFO] loss: 0.6046    [epoch:     4]\n","2024-02-09 07:33:34,434 [INFO] loss: 0.5597    [epoch:     5]\n","2024-02-09 07:33:36,113 [INFO] loss: 0.5334    [epoch:     6]\n","2024-02-09 07:33:37,535 [INFO] loss: 0.5366    [epoch:     7]\n","2024-02-09 07:33:39,105 [INFO] loss: 0.5522    [epoch:     8]\n","2024-02-09 07:33:40,128 [INFO] loss: 0.5544    [epoch:     9]\n","2024-02-09 07:33:41,132 [INFO] loss: 0.5447    [epoch:    10]\n","2024-02-09 07:33:42,114 [INFO] loss: 0.5266    [epoch:    11]\n","2024-02-09 07:33:43,094 [INFO] loss: 0.5130    [epoch:    12]\n","2024-02-09 07:33:44,081 [INFO] loss: 0.5115    [epoch:    13]\n","2024-02-09 07:33:45,031 [INFO] loss: 0.5087    [epoch:    14]\n","2024-02-09 07:33:46,011 [INFO] loss: 0.5106    [epoch:    15]\n","2024-02-09 07:33:46,953 [INFO] loss: 0.5062    [epoch:    16]\n","2024-02-09 07:33:47,894 [INFO] loss: 0.5025    [epoch:    17]\n","2024-02-09 07:33:48,823 [INFO] loss: 0.4915    [epoch:    18]\n","2024-02-09 07:33:50,017 [INFO] loss: 0.4811    [epoch:    19]\n","2024-02-09 07:33:51,592 [INFO] loss: 0.4753    [epoch:    20]\n","2024-02-09 07:33:52,806 [INFO] loss: 0.4781    [epoch:    21]\n","2024-02-09 07:33:53,737 [INFO] loss: 0.4743    [epoch:    22]\n","2024-02-09 07:33:54,915 [INFO] loss: 0.4712    [epoch:    23]\n","2024-02-09 07:33:55,855 [INFO] loss: 0.4662    [epoch:    24]\n","2024-02-09 07:33:56,811 [INFO] loss: 0.4508    [epoch:    25]\n","2024-02-09 07:33:57,771 [INFO] loss: 0.4460    [epoch:    26]\n","2024-02-09 07:33:58,727 [INFO] loss: 0.4427    [epoch:    27]\n","2024-02-09 07:33:59,660 [INFO] loss: 0.4401    [epoch:    28]\n","2024-02-09 07:34:00,619 [INFO] loss: 0.4417    [epoch:    29]\n","2024-02-09 07:34:01,574 [INFO] loss: 0.4457    [epoch:    30]\n","2024-02-09 07:34:02,617 [INFO] loss: 0.4400    [epoch:    31]\n","2024-02-09 07:34:04,184 [INFO] loss: 0.4329    [epoch:    32]\n","2024-02-09 07:34:05,534 [INFO] loss: 0.4338    [epoch:    33]\n","2024-02-09 07:34:06,498 [INFO] loss: 0.4273    [epoch:    34]\n","2024-02-09 07:34:07,493 [INFO] loss: 0.4262    [epoch:    35]\n","2024-02-09 07:34:08,458 [INFO] loss: 0.4283    [epoch:    36]\n","2024-02-09 07:34:09,457 [INFO] loss: 0.4281    [epoch:    37]\n","2024-02-09 07:34:10,419 [INFO] loss: 0.4244    [epoch:    38]\n","2024-02-09 07:34:11,417 [INFO] loss: 0.4278    [epoch:    39]\n","2024-02-09 07:34:12,362 [INFO] loss: 0.4351    [epoch:    40]\n","2024-02-09 07:34:13,336 [INFO] loss: 0.4322    [epoch:    41]\n","2024-02-09 07:34:14,328 [INFO] loss: 0.4242    [epoch:    42]\n","2024-02-09 07:34:15,339 [INFO] loss: 0.4340    [epoch:    43]\n","2024-02-09 07:34:16,901 [INFO] loss: 0.4337    [epoch:    44]\n","2024-02-09 07:34:18,384 [INFO] loss: 0.4223    [epoch:    45]\n","2024-02-09 07:34:19,419 [INFO] loss: 0.4189    [epoch:    46]\n","2024-02-09 07:34:20,404 [INFO] loss: 0.4233    [epoch:    47]\n","2024-02-09 07:34:21,364 [INFO] loss: 0.4257    [epoch:    48]\n","2024-02-09 07:34:22,331 [INFO] loss: 0.4203    [epoch:    49]\n","2024-02-09 07:34:23,290 [INFO] loss: 0.4185    [epoch:    50]\n","2024-02-09 07:34:24,247 [INFO] loss: 0.4210    [epoch:    51]\n","2024-02-09 07:34:25,189 [INFO] loss: 0.4237    [epoch:    52]\n","2024-02-09 07:34:26,170 [INFO] loss: 0.4248    [epoch:    53]\n","2024-02-09 07:34:27,136 [INFO] loss: 0.4216    [epoch:    54]\n","2024-02-09 07:34:28,086 [INFO] loss: 0.4209    [epoch:    55]\n","2024-02-09 07:34:29,605 [INFO] loss: 0.4253    [epoch:    56]\n","2024-02-09 07:34:31,185 [INFO] loss: 0.4254    [epoch:    57]\n","2024-02-09 07:34:32,202 [INFO] loss: 0.4177    [epoch:    58]\n","2024-02-09 07:34:33,395 [INFO] loss: 0.4257    [epoch:    59]\n","2024-02-09 07:34:34,491 [INFO] loss: 0.4210    [epoch:    60]\n","2024-02-09 07:34:35,455 [INFO] loss: 0.4250    [epoch:    61]\n","2024-02-09 07:34:36,414 [INFO] loss: 0.4180    [epoch:    62]\n","2024-02-09 07:34:37,371 [INFO] loss: 0.4272    [epoch:    63]\n","2024-02-09 07:34:38,325 [INFO] loss: 0.4162    [epoch:    64]\n","2024-02-09 07:34:39,266 [INFO] loss: 0.4185    [epoch:    65]\n","2024-02-09 07:34:40,188 [INFO] loss: 0.4188    [epoch:    66]\n","2024-02-09 07:34:41,185 [INFO] loss: 0.4160    [epoch:    67]\n","2024-02-09 07:34:42,747 [INFO] loss: 0.4254    [epoch:    68]\n","2024-02-09 07:34:44,231 [INFO] loss: 0.4224    [epoch:    69]\n","2024-02-09 07:34:45,184 [INFO] loss: 0.4217    [epoch:    70]\n","2024-02-09 07:34:46,100 [INFO] loss: 0.4190    [epoch:    71]\n","2024-02-09 07:34:47,042 [INFO] loss: 0.4228    [epoch:    72]\n","2024-02-09 07:34:47,995 [INFO] loss: 0.4196    [epoch:    73]\n","2024-02-09 07:34:48,940 [INFO] loss: 0.4203    [epoch:    74]\n","2024-02-09 07:34:49,890 [INFO] loss: 0.4152    [epoch:    75]\n","2024-02-09 07:34:50,852 [INFO] loss: 0.4188    [epoch:    76]\n","2024-02-09 07:34:51,789 [INFO] loss: 0.4159    [epoch:    77]\n","2024-02-09 07:34:52,737 [INFO] loss: 0.4153    [epoch:    78]\n","2024-02-09 07:34:53,661 [INFO] loss: 0.4197    [epoch:    79]\n","2024-02-09 07:34:54,993 [INFO] loss: 0.4211    [epoch:    80]\n","2024-02-09 07:34:54,997 [INFO] loss of GraphAutoEncoderModel model : 0.4211347997188568\n","2024-02-09 07:34:54,998 [INFO] Moving x to cuda\n","2024-02-09 07:34:55,010 [INFO] node embedding shape : torch.Size([66911, 32])\n","2024-02-09 07:34:55,013 [INFO] disease embedding shape : torch.Size([898, 32])\n","2024-02-09 07:34:55,014 [INFO] microbe embedding shape : torch.Size([898, 32])\n","2024-02-09 07:34:55,016 [INFO] microbe disease combination embedding shape : torch.Size([898, 64])\n"]}]},{"cell_type":"markdown","source":["# Classification"],"metadata":{"id":"T_hIMihJMts8"},"id":"T_hIMihJMts8"},{"cell_type":"markdown","source":["## Data"],"metadata":{"id":"ocxVXIz1MqLJ"},"id":"ocxVXIz1MqLJ"},{"cell_type":"code","source":["associations = get_associations()\n","y = torch.tensor(associations['increased'].tolist(), dtype=torch.float32).reshape(-1, 1).to(device)"],"metadata":{"id":"jEfB8KA7gPx2","executionInfo":{"status":"ok","timestamp":1707464095469,"user_tz":-210,"elapsed":28,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":48,"outputs":[],"id":"jEfB8KA7gPx2"},{"cell_type":"code","source":["# Train Test Split\n","train_indices, test_indices = train_test_sampler(y.shape[0], 0.7)\n","\n","data = SimplePytorchData(md_embed, y)\n","train_data = SimplePytorchData(md_embed[train_indices], y[train_indices])\n","test_data = SimplePytorchData(md_embed[test_indices], y[test_indices])"],"metadata":{"id":"DNdQlgzMMtHN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707464095470,"user_tz":-210,"elapsed":9,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"c7a8dc61-6382-4076-bfa5-9c7065062c9e"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 07:34:55,048 [INFO] Initializing SimplePytorchData with X shape : torch.Size([898, 64]) and y shape : torch.Size([898, 1])\n","2024-02-09 07:34:55,052 [INFO] Initializing SimplePytorchData with X shape : torch.Size([628, 64]) and y shape : torch.Size([628, 1])\n","2024-02-09 07:34:55,054 [INFO] Initializing SimplePytorchData with X shape : torch.Size([270, 64]) and y shape : torch.Size([270, 1])\n"]}],"id":"DNdQlgzMMtHN"},{"cell_type":"markdown","source":["## Classifier"],"metadata":{"id":"ye_6wl6nxmhs"},"id":"ye_6wl6nxmhs"},{"cell_type":"code","source":["simple_classifier_config = SimpleClassifierConfig()\n","simple_classifier_config.model_name = \"simple classifier\"\n","simple_classifier_config.input_dim = md_embed.shape[1]\n","simple_classifier_config.hidden_dim = 32\n","simple_classifier_config.output_dim = 1\n","simple_classifier_config.num_layers = 2\n","simple_classifier_config.dropout = 0.1"],"metadata":{"id":"BFTQsCl8M9bv","executionInfo":{"status":"ok","timestamp":1707464095470,"user_tz":-210,"elapsed":8,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"BFTQsCl8M9bv","execution_count":50,"outputs":[]},{"cell_type":"code","source":["mda_classifier = SimpleMDAClassifier(simple_classifier_config)"],"metadata":{"id":"1ciyBQ4QM_0U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707464095470,"user_tz":-210,"elapsed":8,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"6172779d-801d-4dda-c8b4-6533a2540bad"},"id":"1ciyBQ4QM_0U","execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 07:34:55,071 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 07:34:55,072 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n"]}]},{"cell_type":"markdown","source":["## Optimizer"],"metadata":{"id":"s_5cdKvOx4q5"},"id":"s_5cdKvOx4q5"},{"cell_type":"code","source":["classifier_optimizer_config = OptimizerConfig()\n","classifier_optimizer_config.optimizer = torch.optim.Adam\n","classifier_optimizer_config.criterion = torch.nn.BCEWithLogitsLoss()\n","classifier_optimizer_config.lr = 0.01\n","classifier_optimizer_config.batch_size = 32\n","classifier_optimizer_config.n_epoch = 50\n","classifier_optimizer_config.exp_name = \"adam optimizer\"\n","classifier_optimizer_config.save = False\n","classifier_optimizer_config.save_path = None\n","classifier_optimizer_config.device = device\n","classifier_optimizer_config.report_size = 10  # batch to report ratio\n","classifier_optimizer_config.threshold = 0.5"],"metadata":{"id":"3D6yhiPpNEc8","executionInfo":{"status":"ok","timestamp":1707464095470,"user_tz":-210,"elapsed":7,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"3D6yhiPpNEc8","execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["## Train Test Approach"],"metadata":{"id":"4iI5bMmJNQV3"},"id":"4iI5bMmJNQV3"},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"h24KnmDZNAgD"},"id":"h24KnmDZNAgD"},{"cell_type":"code","source":["train_result = SimpleTrainer().train(model=mda_classifier,\n","                                     data=train_data,\n","                                     config=classifier_optimizer_config)"],"metadata":{"id":"OqKrF7HmNFx1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707464097943,"user_tz":-210,"elapsed":2479,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"5542957e-f6ba-40f1-9ed2-621a8f196084"},"id":"OqKrF7HmNFx1","execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 07:34:55,091 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 07:34:55,092 [INFO] moving data and model to cuda\n","2024-02-09 07:34:55,132 [INFO] loss: 0.0212    [1,    10]\n","2024-02-09 07:34:55,162 [INFO] loss: 0.0213    [1,    20]\n","2024-02-09 07:34:55,189 [INFO] loss: 0.0210    [2,    10]\n","2024-02-09 07:34:55,213 [INFO] loss: 0.0208    [2,    20]\n","2024-02-09 07:34:55,234 [INFO] loss: 0.0203    [3,    10]\n","2024-02-09 07:34:55,256 [INFO] loss: 0.0199    [3,    20]\n","2024-02-09 07:34:55,280 [INFO] loss: 0.0199    [4,    10]\n","2024-02-09 07:34:55,301 [INFO] loss: 0.0197    [4,    20]\n","2024-02-09 07:34:55,323 [INFO] loss: 0.0195    [5,    10]\n","2024-02-09 07:34:55,346 [INFO] loss: 0.0200    [5,    20]\n","2024-02-09 07:34:55,367 [INFO] loss: 0.0194    [6,    10]\n","2024-02-09 07:34:55,389 [INFO] loss: 0.0192    [6,    20]\n","2024-02-09 07:34:55,411 [INFO] loss: 0.0194    [7,    10]\n","2024-02-09 07:34:55,432 [INFO] loss: 0.0193    [7,    20]\n","2024-02-09 07:34:55,453 [INFO] loss: 0.0194    [8,    10]\n","2024-02-09 07:34:55,474 [INFO] loss: 0.0179    [8,    20]\n","2024-02-09 07:34:55,495 [INFO] loss: 0.0178    [9,    10]\n","2024-02-09 07:34:55,516 [INFO] loss: 0.0192    [9,    20]\n","2024-02-09 07:34:55,538 [INFO] loss: 0.0182    [10,    10]\n","2024-02-09 07:34:55,560 [INFO] loss: 0.0185    [10,    20]\n","2024-02-09 07:34:55,581 [INFO] loss: 0.0178    [11,    10]\n","2024-02-09 07:34:55,605 [INFO] loss: 0.0176    [11,    20]\n","2024-02-09 07:34:55,626 [INFO] loss: 0.0179    [12,    10]\n","2024-02-09 07:34:55,653 [INFO] loss: 0.0178    [12,    20]\n","2024-02-09 07:34:55,676 [INFO] loss: 0.0170    [13,    10]\n","2024-02-09 07:34:55,700 [INFO] loss: 0.0186    [13,    20]\n","2024-02-09 07:34:55,724 [INFO] loss: 0.0175    [14,    10]\n","2024-02-09 07:34:55,748 [INFO] loss: 0.0180    [14,    20]\n","2024-02-09 07:34:55,772 [INFO] loss: 0.0181    [15,    10]\n","2024-02-09 07:34:55,795 [INFO] loss: 0.0175    [15,    20]\n","2024-02-09 07:34:55,817 [INFO] loss: 0.0157    [16,    10]\n","2024-02-09 07:34:55,838 [INFO] loss: 0.0191    [16,    20]\n","2024-02-09 07:34:55,860 [INFO] loss: 0.0171    [17,    10]\n","2024-02-09 07:34:55,883 [INFO] loss: 0.0177    [17,    20]\n","2024-02-09 07:34:55,906 [INFO] loss: 0.0179    [18,    10]\n","2024-02-09 07:34:55,929 [INFO] loss: 0.0166    [18,    20]\n","2024-02-09 07:34:55,950 [INFO] loss: 0.0178    [19,    10]\n","2024-02-09 07:34:55,971 [INFO] loss: 0.0173    [19,    20]\n","2024-02-09 07:34:55,992 [INFO] loss: 0.0184    [20,    10]\n","2024-02-09 07:34:56,013 [INFO] loss: 0.0163    [20,    20]\n","2024-02-09 07:34:56,036 [INFO] loss: 0.0166    [21,    10]\n","2024-02-09 07:34:56,060 [INFO] loss: 0.0173    [21,    20]\n","2024-02-09 07:34:56,083 [INFO] loss: 0.0164    [22,    10]\n","2024-02-09 07:34:56,105 [INFO] loss: 0.0180    [22,    20]\n","2024-02-09 07:34:56,126 [INFO] loss: 0.0182    [23,    10]\n","2024-02-09 07:34:56,148 [INFO] loss: 0.0169    [23,    20]\n","2024-02-09 07:34:56,173 [INFO] loss: 0.0179    [24,    10]\n","2024-02-09 07:34:56,198 [INFO] loss: 0.0163    [24,    20]\n","2024-02-09 07:34:56,222 [INFO] loss: 0.0173    [25,    10]\n","2024-02-09 07:34:56,250 [INFO] loss: 0.0163    [25,    20]\n","2024-02-09 07:34:56,275 [INFO] loss: 0.0169    [26,    10]\n","2024-02-09 07:34:56,307 [INFO] loss: 0.0174    [26,    20]\n","2024-02-09 07:34:56,332 [INFO] loss: 0.0178    [27,    10]\n","2024-02-09 07:34:56,354 [INFO] loss: 0.0159    [27,    20]\n","2024-02-09 07:34:56,375 [INFO] loss: 0.0164    [28,    10]\n","2024-02-09 07:34:56,398 [INFO] loss: 0.0172    [28,    20]\n","2024-02-09 07:34:56,425 [INFO] loss: 0.0164    [29,    10]\n","2024-02-09 07:34:56,449 [INFO] loss: 0.0181    [29,    20]\n","2024-02-09 07:34:56,472 [INFO] loss: 0.0169    [30,    10]\n","2024-02-09 07:34:56,500 [INFO] loss: 0.0165    [30,    20]\n","2024-02-09 07:34:56,524 [INFO] loss: 0.0168    [31,    10]\n","2024-02-09 07:34:56,553 [INFO] loss: 0.0164    [31,    20]\n","2024-02-09 07:34:56,580 [INFO] loss: 0.0167    [32,    10]\n","2024-02-09 07:34:56,605 [INFO] loss: 0.0167    [32,    20]\n","2024-02-09 07:34:56,634 [INFO] loss: 0.0165    [33,    10]\n","2024-02-09 07:34:56,662 [INFO] loss: 0.0166    [33,    20]\n","2024-02-09 07:34:56,688 [INFO] loss: 0.0160    [34,    10]\n","2024-02-09 07:34:56,723 [INFO] loss: 0.0159    [34,    20]\n","2024-02-09 07:34:56,751 [INFO] loss: 0.0172    [35,    10]\n","2024-02-09 07:34:56,777 [INFO] loss: 0.0169    [35,    20]\n","2024-02-09 07:34:56,804 [INFO] loss: 0.0166    [36,    10]\n","2024-02-09 07:34:56,834 [INFO] loss: 0.0167    [36,    20]\n","2024-02-09 07:34:56,860 [INFO] loss: 0.0178    [37,    10]\n","2024-02-09 07:34:56,887 [INFO] loss: 0.0154    [37,    20]\n","2024-02-09 07:34:56,914 [INFO] loss: 0.0169    [38,    10]\n","2024-02-09 07:34:56,939 [INFO] loss: 0.0158    [38,    20]\n","2024-02-09 07:34:56,957 [INFO] loss: 0.0171    [39,    10]\n","2024-02-09 07:34:56,976 [INFO] loss: 0.0154    [39,    20]\n","2024-02-09 07:34:56,994 [INFO] loss: 0.0172    [40,    10]\n","2024-02-09 07:34:57,013 [INFO] loss: 0.0158    [40,    20]\n","2024-02-09 07:34:57,032 [INFO] loss: 0.0165    [41,    10]\n","2024-02-09 07:34:57,050 [INFO] loss: 0.0165    [41,    20]\n","2024-02-09 07:34:57,069 [INFO] loss: 0.0166    [42,    10]\n","2024-02-09 07:34:57,088 [INFO] loss: 0.0162    [42,    20]\n","2024-02-09 07:34:57,106 [INFO] loss: 0.0156    [43,    10]\n","2024-02-09 07:34:57,125 [INFO] loss: 0.0176    [43,    20]\n","2024-02-09 07:34:57,144 [INFO] loss: 0.0164    [44,    10]\n","2024-02-09 07:34:57,162 [INFO] loss: 0.0164    [44,    20]\n","2024-02-09 07:34:57,181 [INFO] loss: 0.0165    [45,    10]\n","2024-02-09 07:34:57,199 [INFO] loss: 0.0162    [45,    20]\n","2024-02-09 07:34:57,219 [INFO] loss: 0.0159    [46,    10]\n","2024-02-09 07:34:57,238 [INFO] loss: 0.0167    [46,    20]\n","2024-02-09 07:34:57,256 [INFO] loss: 0.0165    [47,    10]\n","2024-02-09 07:34:57,276 [INFO] loss: 0.0171    [47,    20]\n","2024-02-09 07:34:57,295 [INFO] loss: 0.0160    [48,    10]\n","2024-02-09 07:34:57,313 [INFO] loss: 0.0173    [48,    20]\n","2024-02-09 07:34:57,332 [INFO] loss: 0.0160    [49,    10]\n","2024-02-09 07:34:57,351 [INFO] loss: 0.0163    [49,    20]\n","2024-02-09 07:34:57,370 [INFO] loss: 0.0153    [50,    10]\n","2024-02-09 07:34:57,389 [INFO] loss: 0.0165    [50,    20]\n","2024-02-09 07:34:57,429 [INFO] Result on Train Data : {'AUC': 0.8551708049334632, 'ACC': 0.7452229299363057, 'F1 Score': 0.7434640522875816, 'AUPR': 0, 'Loss': 0.4896334305405617}\n"]}]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"0eQGNWm_NMVG"},"id":"0eQGNWm_NMVG"},{"cell_type":"code","source":["test_result = SimpleTester().test(model=mda_classifier,\n","                                  data=test_data,\n","                                  config=classifier_optimizer_config)"],"metadata":{"id":"U05mXL_fNHpG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707464097943,"user_tz":-210,"elapsed":14,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"cf3ef6a6-d578-48e6-c4df-8cbd23a33989"},"id":"U05mXL_fNHpG","execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 07:34:57,438 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 07:34:57,440 [INFO] moving data and model to cuda\n","2024-02-09 07:34:57,464 [INFO] Result on Test Data : {'AUC': 0.8587058112045742, 'ACC': 0.7481481481481481, 'F1 Score': 0.7454101724998613, 'AUPR': 0, 'Loss': 0.49913786848386127}\n"]}]},{"cell_type":"code","source":["test_result.get_result()"],"metadata":{"id":"oqgiZQqRWWGF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707464097943,"user_tz":-210,"elapsed":9,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"3e8fb645-4879-4bbd-e764-f9926c92fa26"},"id":"oqgiZQqRWWGF","execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'AUC': 0.8587058112045742,\n"," 'ACC': 0.7481481481481481,\n"," 'F1 Score': 0.7454101724998613,\n"," 'AUPR': 0,\n"," 'Loss': 0.49913786848386127}"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","source":["## Cross Validation"],"metadata":{"id":"ti8vEX_cNNwy"},"id":"ti8vEX_cNNwy"},{"cell_type":"code","execution_count":56,"id":"initial_id","metadata":{"id":"initial_id","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707464109594,"user_tz":-210,"elapsed":11659,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"2f90008b-3c8f-4b3a-bd16-1e29d06904c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-09 07:34:57,482 [INFO] Initializing SimpleMDAClassifierFactory with model : simple classifier\n","2024-02-09 07:34:57,484 [INFO] Initializing SimplePytorchDataTrainTestSplit\n","2024-02-09 07:34:57,486 [INFO] Start 5-fold Cross Validation with config : adam optimizer\n","2024-02-09 07:34:57,494 [INFO] ---- Fold 1 ----\n","2024-02-09 07:34:57,496 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-09 07:34:57,498 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-09 07:34:57,499 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 07:34:57,500 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-09 07:34:57,502 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 07:34:57,503 [INFO] moving data and model to cuda\n","2024-02-09 07:34:57,526 [INFO] loss: 0.0234    [1,    10]\n","2024-02-09 07:34:57,545 [INFO] loss: 0.0216    [1,    20]\n","2024-02-09 07:34:57,571 [INFO] loss: 0.0211    [2,    10]\n","2024-02-09 07:34:57,589 [INFO] loss: 0.0209    [2,    20]\n","2024-02-09 07:34:57,612 [INFO] loss: 0.0210    [3,    10]\n","2024-02-09 07:34:57,633 [INFO] loss: 0.0197    [3,    20]\n","2024-02-09 07:34:57,656 [INFO] loss: 0.0201    [4,    10]\n","2024-02-09 07:34:57,675 [INFO] loss: 0.0188    [4,    20]\n","2024-02-09 07:34:57,699 [INFO] loss: 0.0189    [5,    10]\n","2024-02-09 07:34:57,719 [INFO] loss: 0.0188    [5,    20]\n","2024-02-09 07:34:57,748 [INFO] loss: 0.0177    [6,    10]\n","2024-02-09 07:34:57,769 [INFO] loss: 0.0191    [6,    20]\n","2024-02-09 07:34:57,792 [INFO] loss: 0.0190    [7,    10]\n","2024-02-09 07:34:57,813 [INFO] loss: 0.0178    [7,    20]\n","2024-02-09 07:34:57,839 [INFO] loss: 0.0182    [8,    10]\n","2024-02-09 07:34:57,857 [INFO] loss: 0.0183    [8,    20]\n","2024-02-09 07:34:57,881 [INFO] loss: 0.0178    [9,    10]\n","2024-02-09 07:34:57,901 [INFO] loss: 0.0183    [9,    20]\n","2024-02-09 07:34:57,925 [INFO] loss: 0.0186    [10,    10]\n","2024-02-09 07:34:57,943 [INFO] loss: 0.0170    [10,    20]\n","2024-02-09 07:34:57,966 [INFO] loss: 0.0180    [11,    10]\n","2024-02-09 07:34:57,987 [INFO] loss: 0.0178    [11,    20]\n","2024-02-09 07:34:58,010 [INFO] loss: 0.0177    [12,    10]\n","2024-02-09 07:34:58,028 [INFO] loss: 0.0170    [12,    20]\n","2024-02-09 07:34:58,052 [INFO] loss: 0.0181    [13,    10]\n","2024-02-09 07:34:58,071 [INFO] loss: 0.0181    [13,    20]\n","2024-02-09 07:34:58,094 [INFO] loss: 0.0179    [14,    10]\n","2024-02-09 07:34:58,113 [INFO] loss: 0.0168    [14,    20]\n","2024-02-09 07:34:58,137 [INFO] loss: 0.0170    [15,    10]\n","2024-02-09 07:34:58,156 [INFO] loss: 0.0166    [15,    20]\n","2024-02-09 07:34:58,179 [INFO] loss: 0.0176    [16,    10]\n","2024-02-09 07:34:58,197 [INFO] loss: 0.0168    [16,    20]\n","2024-02-09 07:34:58,220 [INFO] loss: 0.0171    [17,    10]\n","2024-02-09 07:34:58,238 [INFO] loss: 0.0164    [17,    20]\n","2024-02-09 07:34:58,261 [INFO] loss: 0.0163    [18,    10]\n","2024-02-09 07:34:58,279 [INFO] loss: 0.0175    [18,    20]\n","2024-02-09 07:34:58,303 [INFO] loss: 0.0161    [19,    10]\n","2024-02-09 07:34:58,323 [INFO] loss: 0.0170    [19,    20]\n","2024-02-09 07:34:58,348 [INFO] loss: 0.0163    [20,    10]\n","2024-02-09 07:34:58,368 [INFO] loss: 0.0167    [20,    20]\n","2024-02-09 07:34:58,392 [INFO] loss: 0.0165    [21,    10]\n","2024-02-09 07:34:58,410 [INFO] loss: 0.0169    [21,    20]\n","2024-02-09 07:34:58,435 [INFO] loss: 0.0182    [22,    10]\n","2024-02-09 07:34:58,455 [INFO] loss: 0.0163    [22,    20]\n","2024-02-09 07:34:58,478 [INFO] loss: 0.0176    [23,    10]\n","2024-02-09 07:34:58,497 [INFO] loss: 0.0163    [23,    20]\n","2024-02-09 07:34:58,521 [INFO] loss: 0.0165    [24,    10]\n","2024-02-09 07:34:58,539 [INFO] loss: 0.0157    [24,    20]\n","2024-02-09 07:34:58,564 [INFO] loss: 0.0173    [25,    10]\n","2024-02-09 07:34:58,584 [INFO] loss: 0.0165    [25,    20]\n","2024-02-09 07:34:58,608 [INFO] loss: 0.0177    [26,    10]\n","2024-02-09 07:34:58,626 [INFO] loss: 0.0171    [26,    20]\n","2024-02-09 07:34:58,650 [INFO] loss: 0.0164    [27,    10]\n","2024-02-09 07:34:58,669 [INFO] loss: 0.0172    [27,    20]\n","2024-02-09 07:34:58,692 [INFO] loss: 0.0158    [28,    10]\n","2024-02-09 07:34:58,710 [INFO] loss: 0.0176    [28,    20]\n","2024-02-09 07:34:58,736 [INFO] loss: 0.0170    [29,    10]\n","2024-02-09 07:34:58,756 [INFO] loss: 0.0171    [29,    20]\n","2024-02-09 07:34:58,787 [INFO] loss: 0.0150    [30,    10]\n","2024-02-09 07:34:58,805 [INFO] loss: 0.0169    [30,    20]\n","2024-02-09 07:34:58,827 [INFO] loss: 0.0169    [31,    10]\n","2024-02-09 07:34:58,846 [INFO] loss: 0.0160    [31,    20]\n","2024-02-09 07:34:58,870 [INFO] loss: 0.0172    [32,    10]\n","2024-02-09 07:34:58,888 [INFO] loss: 0.0162    [32,    20]\n","2024-02-09 07:34:58,914 [INFO] loss: 0.0150    [33,    10]\n","2024-02-09 07:34:58,933 [INFO] loss: 0.0175    [33,    20]\n","2024-02-09 07:34:58,957 [INFO] loss: 0.0163    [34,    10]\n","2024-02-09 07:34:58,976 [INFO] loss: 0.0161    [34,    20]\n","2024-02-09 07:34:59,001 [INFO] loss: 0.0152    [35,    10]\n","2024-02-09 07:34:59,020 [INFO] loss: 0.0168    [35,    20]\n","2024-02-09 07:34:59,044 [INFO] loss: 0.0162    [36,    10]\n","2024-02-09 07:34:59,064 [INFO] loss: 0.0161    [36,    20]\n","2024-02-09 07:34:59,088 [INFO] loss: 0.0167    [37,    10]\n","2024-02-09 07:34:59,109 [INFO] loss: 0.0163    [37,    20]\n","2024-02-09 07:34:59,133 [INFO] loss: 0.0166    [38,    10]\n","2024-02-09 07:34:59,153 [INFO] loss: 0.0161    [38,    20]\n","2024-02-09 07:34:59,176 [INFO] loss: 0.0156    [39,    10]\n","2024-02-09 07:34:59,194 [INFO] loss: 0.0159    [39,    20]\n","2024-02-09 07:34:59,219 [INFO] loss: 0.0168    [40,    10]\n","2024-02-09 07:34:59,238 [INFO] loss: 0.0162    [40,    20]\n","2024-02-09 07:34:59,262 [INFO] loss: 0.0170    [41,    10]\n","2024-02-09 07:34:59,280 [INFO] loss: 0.0153    [41,    20]\n","2024-02-09 07:34:59,303 [INFO] loss: 0.0148    [42,    10]\n","2024-02-09 07:34:59,321 [INFO] loss: 0.0160    [42,    20]\n","2024-02-09 07:34:59,343 [INFO] loss: 0.0165    [43,    10]\n","2024-02-09 07:34:59,361 [INFO] loss: 0.0158    [43,    20]\n","2024-02-09 07:34:59,385 [INFO] loss: 0.0161    [44,    10]\n","2024-02-09 07:34:59,404 [INFO] loss: 0.0163    [44,    20]\n","2024-02-09 07:34:59,428 [INFO] loss: 0.0166    [45,    10]\n","2024-02-09 07:34:59,448 [INFO] loss: 0.0160    [45,    20]\n","2024-02-09 07:34:59,474 [INFO] loss: 0.0163    [46,    10]\n","2024-02-09 07:34:59,493 [INFO] loss: 0.0160    [46,    20]\n","2024-02-09 07:34:59,518 [INFO] loss: 0.0156    [47,    10]\n","2024-02-09 07:34:59,536 [INFO] loss: 0.0156    [47,    20]\n","2024-02-09 07:34:59,561 [INFO] loss: 0.0161    [48,    10]\n","2024-02-09 07:34:59,580 [INFO] loss: 0.0151    [48,    20]\n","2024-02-09 07:34:59,604 [INFO] loss: 0.0159    [49,    10]\n","2024-02-09 07:34:59,622 [INFO] loss: 0.0161    [49,    20]\n","2024-02-09 07:34:59,645 [INFO] loss: 0.0164    [50,    10]\n","2024-02-09 07:34:59,664 [INFO] loss: 0.0152    [50,    20]\n","2024-02-09 07:34:59,707 [INFO] Result on Train Data : {'AUC': 0.8645993031358885, 'ACC': 0.7788595271210014, 'F1 Score': 0.7785699758854122, 'AUPR': 0, 'Loss': 0.4845746120680933}\n","2024-02-09 07:34:59,709 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 07:34:59,712 [INFO] moving data and model to cuda\n","2024-02-09 07:34:59,730 [INFO] Result on Test Data : {'AUC': 0.836111111111111, 'ACC': 0.7597765363128491, 'F1 Score': 0.7560921507114111, 'AUPR': 0, 'Loss': 0.5397115051746368}\n","2024-02-09 07:34:59,731 [INFO] Result of fold 1 : {'AUC': 0.836111111111111, 'ACC': 0.7597765363128491, 'F1 Score': 0.7560921507114111, 'AUPR': 0, 'Loss': 0.5397115051746368}\n","2024-02-09 07:34:59,732 [INFO] ---- Fold 2 ----\n","2024-02-09 07:34:59,735 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-09 07:34:59,737 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-09 07:34:59,739 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 07:34:59,740 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-09 07:34:59,742 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 07:34:59,743 [INFO] moving data and model to cuda\n","2024-02-09 07:34:59,769 [INFO] loss: 0.0221    [1,    10]\n","2024-02-09 07:34:59,794 [INFO] loss: 0.0215    [1,    20]\n","2024-02-09 07:34:59,823 [INFO] loss: 0.0209    [2,    10]\n","2024-02-09 07:34:59,842 [INFO] loss: 0.0207    [2,    20]\n","2024-02-09 07:34:59,866 [INFO] loss: 0.0191    [3,    10]\n","2024-02-09 07:34:59,888 [INFO] loss: 0.0202    [3,    20]\n","2024-02-09 07:34:59,912 [INFO] loss: 0.0192    [4,    10]\n","2024-02-09 07:34:59,931 [INFO] loss: 0.0191    [4,    20]\n","2024-02-09 07:34:59,956 [INFO] loss: 0.0185    [5,    10]\n","2024-02-09 07:34:59,974 [INFO] loss: 0.0191    [5,    20]\n","2024-02-09 07:34:59,997 [INFO] loss: 0.0189    [6,    10]\n","2024-02-09 07:35:00,016 [INFO] loss: 0.0186    [6,    20]\n","2024-02-09 07:35:00,040 [INFO] loss: 0.0184    [7,    10]\n","2024-02-09 07:35:00,060 [INFO] loss: 0.0188    [7,    20]\n","2024-02-09 07:35:00,084 [INFO] loss: 0.0189    [8,    10]\n","2024-02-09 07:35:00,102 [INFO] loss: 0.0180    [8,    20]\n","2024-02-09 07:35:00,128 [INFO] loss: 0.0177    [9,    10]\n","2024-02-09 07:35:00,147 [INFO] loss: 0.0179    [9,    20]\n","2024-02-09 07:35:00,171 [INFO] loss: 0.0179    [10,    10]\n","2024-02-09 07:35:00,189 [INFO] loss: 0.0178    [10,    20]\n","2024-02-09 07:35:00,213 [INFO] loss: 0.0169    [11,    10]\n","2024-02-09 07:35:00,232 [INFO] loss: 0.0180    [11,    20]\n","2024-02-09 07:35:00,258 [INFO] loss: 0.0185    [12,    10]\n","2024-02-09 07:35:00,277 [INFO] loss: 0.0165    [12,    20]\n","2024-02-09 07:35:00,301 [INFO] loss: 0.0168    [13,    10]\n","2024-02-09 07:35:00,321 [INFO] loss: 0.0175    [13,    20]\n","2024-02-09 07:35:00,344 [INFO] loss: 0.0174    [14,    10]\n","2024-02-09 07:35:00,363 [INFO] loss: 0.0173    [14,    20]\n","2024-02-09 07:35:00,387 [INFO] loss: 0.0162    [15,    10]\n","2024-02-09 07:35:00,407 [INFO] loss: 0.0181    [15,    20]\n","2024-02-09 07:35:00,431 [INFO] loss: 0.0172    [16,    10]\n","2024-02-09 07:35:00,451 [INFO] loss: 0.0167    [16,    20]\n","2024-02-09 07:35:00,474 [INFO] loss: 0.0179    [17,    10]\n","2024-02-09 07:35:00,493 [INFO] loss: 0.0172    [17,    20]\n","2024-02-09 07:35:00,517 [INFO] loss: 0.0167    [18,    10]\n","2024-02-09 07:35:00,536 [INFO] loss: 0.0174    [18,    20]\n","2024-02-09 07:35:00,559 [INFO] loss: 0.0170    [19,    10]\n","2024-02-09 07:35:00,582 [INFO] loss: 0.0169    [19,    20]\n","2024-02-09 07:35:00,606 [INFO] loss: 0.0163    [20,    10]\n","2024-02-09 07:35:00,625 [INFO] loss: 0.0167    [20,    20]\n","2024-02-09 07:35:00,651 [INFO] loss: 0.0164    [21,    10]\n","2024-02-09 07:35:00,671 [INFO] loss: 0.0162    [21,    20]\n","2024-02-09 07:35:00,694 [INFO] loss: 0.0163    [22,    10]\n","2024-02-09 07:35:00,712 [INFO] loss: 0.0165    [22,    20]\n","2024-02-09 07:35:00,738 [INFO] loss: 0.0163    [23,    10]\n","2024-02-09 07:35:00,757 [INFO] loss: 0.0167    [23,    20]\n","2024-02-09 07:35:00,782 [INFO] loss: 0.0177    [24,    10]\n","2024-02-09 07:35:00,802 [INFO] loss: 0.0165    [24,    20]\n","2024-02-09 07:35:00,834 [INFO] loss: 0.0158    [25,    10]\n","2024-02-09 07:35:00,852 [INFO] loss: 0.0163    [25,    20]\n","2024-02-09 07:35:00,882 [INFO] loss: 0.0160    [26,    10]\n","2024-02-09 07:35:00,904 [INFO] loss: 0.0169    [26,    20]\n","2024-02-09 07:35:00,929 [INFO] loss: 0.0164    [27,    10]\n","2024-02-09 07:35:00,948 [INFO] loss: 0.0156    [27,    20]\n","2024-02-09 07:35:00,972 [INFO] loss: 0.0161    [28,    10]\n","2024-02-09 07:35:00,990 [INFO] loss: 0.0155    [28,    20]\n","2024-02-09 07:35:01,013 [INFO] loss: 0.0174    [29,    10]\n","2024-02-09 07:35:01,033 [INFO] loss: 0.0164    [29,    20]\n","2024-02-09 07:35:01,060 [INFO] loss: 0.0161    [30,    10]\n","2024-02-09 07:35:01,081 [INFO] loss: 0.0157    [30,    20]\n","2024-02-09 07:35:01,106 [INFO] loss: 0.0167    [31,    10]\n","2024-02-09 07:35:01,125 [INFO] loss: 0.0161    [31,    20]\n","2024-02-09 07:35:01,149 [INFO] loss: 0.0156    [32,    10]\n","2024-02-09 07:35:01,167 [INFO] loss: 0.0162    [32,    20]\n","2024-02-09 07:35:01,190 [INFO] loss: 0.0165    [33,    10]\n","2024-02-09 07:35:01,208 [INFO] loss: 0.0148    [33,    20]\n","2024-02-09 07:35:01,232 [INFO] loss: 0.0162    [34,    10]\n","2024-02-09 07:35:01,251 [INFO] loss: 0.0159    [34,    20]\n","2024-02-09 07:35:01,274 [INFO] loss: 0.0148    [35,    10]\n","2024-02-09 07:35:01,293 [INFO] loss: 0.0160    [35,    20]\n","2024-02-09 07:35:01,315 [INFO] loss: 0.0150    [36,    10]\n","2024-02-09 07:35:01,337 [INFO] loss: 0.0167    [36,    20]\n","2024-02-09 07:35:01,360 [INFO] loss: 0.0167    [37,    10]\n","2024-02-09 07:35:01,381 [INFO] loss: 0.0146    [37,    20]\n","2024-02-09 07:35:01,404 [INFO] loss: 0.0166    [38,    10]\n","2024-02-09 07:35:01,424 [INFO] loss: 0.0150    [38,    20]\n","2024-02-09 07:35:01,448 [INFO] loss: 0.0159    [39,    10]\n","2024-02-09 07:35:01,468 [INFO] loss: 0.0153    [39,    20]\n","2024-02-09 07:35:01,491 [INFO] loss: 0.0153    [40,    10]\n","2024-02-09 07:35:01,509 [INFO] loss: 0.0164    [40,    20]\n","2024-02-09 07:35:01,534 [INFO] loss: 0.0150    [41,    10]\n","2024-02-09 07:35:01,555 [INFO] loss: 0.0165    [41,    20]\n","2024-02-09 07:35:01,581 [INFO] loss: 0.0151    [42,    10]\n","2024-02-09 07:35:01,603 [INFO] loss: 0.0164    [42,    20]\n","2024-02-09 07:35:01,628 [INFO] loss: 0.0157    [43,    10]\n","2024-02-09 07:35:01,647 [INFO] loss: 0.0164    [43,    20]\n","2024-02-09 07:35:01,672 [INFO] loss: 0.0154    [44,    10]\n","2024-02-09 07:35:01,692 [INFO] loss: 0.0160    [44,    20]\n","2024-02-09 07:35:01,717 [INFO] loss: 0.0159    [45,    10]\n","2024-02-09 07:35:01,736 [INFO] loss: 0.0147    [45,    20]\n","2024-02-09 07:35:01,760 [INFO] loss: 0.0157    [46,    10]\n","2024-02-09 07:35:01,779 [INFO] loss: 0.0164    [46,    20]\n","2024-02-09 07:35:01,802 [INFO] loss: 0.0165    [47,    10]\n","2024-02-09 07:35:01,824 [INFO] loss: 0.0161    [47,    20]\n","2024-02-09 07:35:01,855 [INFO] loss: 0.0175    [48,    10]\n","2024-02-09 07:35:01,873 [INFO] loss: 0.0151    [48,    20]\n","2024-02-09 07:35:01,897 [INFO] loss: 0.0142    [49,    10]\n","2024-02-09 07:35:01,916 [INFO] loss: 0.0174    [49,    20]\n","2024-02-09 07:35:01,939 [INFO] loss: 0.0153    [50,    10]\n","2024-02-09 07:35:01,961 [INFO] loss: 0.0153    [50,    20]\n","2024-02-09 07:35:02,007 [INFO] Result on Train Data : {'AUC': 0.8626564942199663, 'ACC': 0.7635605006954103, 'F1 Score': 0.7635051466604752, 'AUPR': 0, 'Loss': 0.4726793675319008}\n","2024-02-09 07:35:02,008 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 07:35:02,011 [INFO] moving data and model to cuda\n","2024-02-09 07:35:02,030 [INFO] Result on Test Data : {'AUC': 0.7807192807192808, 'ACC': 0.6536312849162011, 'F1 Score': 0.6531007751937985, 'AUPR': 0, 'Loss': 0.5726538300514221}\n","2024-02-09 07:35:02,031 [INFO] Result of fold 2 : {'AUC': 0.7807192807192808, 'ACC': 0.6536312849162011, 'F1 Score': 0.6531007751937985, 'AUPR': 0, 'Loss': 0.5726538300514221}\n","2024-02-09 07:35:02,032 [INFO] ---- Fold 3 ----\n","2024-02-09 07:35:02,034 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-09 07:35:02,036 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-09 07:35:02,037 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 07:35:02,038 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-09 07:35:02,039 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 07:35:02,040 [INFO] moving data and model to cuda\n","2024-02-09 07:35:02,069 [INFO] loss: 0.0217    [1,    10]\n","2024-02-09 07:35:02,088 [INFO] loss: 0.0216    [1,    20]\n","2024-02-09 07:35:02,115 [INFO] loss: 0.0214    [2,    10]\n","2024-02-09 07:35:02,134 [INFO] loss: 0.0213    [2,    20]\n","2024-02-09 07:35:02,160 [INFO] loss: 0.0205    [3,    10]\n","2024-02-09 07:35:02,180 [INFO] loss: 0.0203    [3,    20]\n","2024-02-09 07:35:02,203 [INFO] loss: 0.0200    [4,    10]\n","2024-02-09 07:35:02,223 [INFO] loss: 0.0194    [4,    20]\n","2024-02-09 07:35:02,250 [INFO] loss: 0.0195    [5,    10]\n","2024-02-09 07:35:02,269 [INFO] loss: 0.0192    [5,    20]\n","2024-02-09 07:35:02,293 [INFO] loss: 0.0183    [6,    10]\n","2024-02-09 07:35:02,312 [INFO] loss: 0.0190    [6,    20]\n","2024-02-09 07:35:02,336 [INFO] loss: 0.0188    [7,    10]\n","2024-02-09 07:35:02,355 [INFO] loss: 0.0181    [7,    20]\n","2024-02-09 07:35:02,379 [INFO] loss: 0.0182    [8,    10]\n","2024-02-09 07:35:02,398 [INFO] loss: 0.0182    [8,    20]\n","2024-02-09 07:35:02,422 [INFO] loss: 0.0175    [9,    10]\n","2024-02-09 07:35:02,442 [INFO] loss: 0.0186    [9,    20]\n","2024-02-09 07:35:02,467 [INFO] loss: 0.0172    [10,    10]\n","2024-02-09 07:35:02,487 [INFO] loss: 0.0191    [10,    20]\n","2024-02-09 07:35:02,510 [INFO] loss: 0.0174    [11,    10]\n","2024-02-09 07:35:02,528 [INFO] loss: 0.0192    [11,    20]\n","2024-02-09 07:35:02,551 [INFO] loss: 0.0177    [12,    10]\n","2024-02-09 07:35:02,569 [INFO] loss: 0.0184    [12,    20]\n","2024-02-09 07:35:02,594 [INFO] loss: 0.0185    [13,    10]\n","2024-02-09 07:35:02,615 [INFO] loss: 0.0178    [13,    20]\n","2024-02-09 07:35:02,639 [INFO] loss: 0.0176    [14,    10]\n","2024-02-09 07:35:02,658 [INFO] loss: 0.0180    [14,    20]\n","2024-02-09 07:35:02,684 [INFO] loss: 0.0182    [15,    10]\n","2024-02-09 07:35:02,703 [INFO] loss: 0.0174    [15,    20]\n","2024-02-09 07:35:02,727 [INFO] loss: 0.0179    [16,    10]\n","2024-02-09 07:35:02,746 [INFO] loss: 0.0178    [16,    20]\n","2024-02-09 07:35:02,770 [INFO] loss: 0.0169    [17,    10]\n","2024-02-09 07:35:02,790 [INFO] loss: 0.0184    [17,    20]\n","2024-02-09 07:35:02,815 [INFO] loss: 0.0163    [18,    10]\n","2024-02-09 07:35:02,838 [INFO] loss: 0.0165    [18,    20]\n","2024-02-09 07:35:02,866 [INFO] loss: 0.0167    [19,    10]\n","2024-02-09 07:35:02,891 [INFO] loss: 0.0186    [19,    20]\n","2024-02-09 07:35:02,919 [INFO] loss: 0.0173    [20,    10]\n","2024-02-09 07:35:02,942 [INFO] loss: 0.0169    [20,    20]\n","2024-02-09 07:35:02,966 [INFO] loss: 0.0164    [21,    10]\n","2024-02-09 07:35:02,986 [INFO] loss: 0.0180    [21,    20]\n","2024-02-09 07:35:03,010 [INFO] loss: 0.0169    [22,    10]\n","2024-02-09 07:35:03,030 [INFO] loss: 0.0176    [22,    20]\n","2024-02-09 07:35:03,055 [INFO] loss: 0.0167    [23,    10]\n","2024-02-09 07:35:03,075 [INFO] loss: 0.0171    [23,    20]\n","2024-02-09 07:35:03,099 [INFO] loss: 0.0174    [24,    10]\n","2024-02-09 07:35:03,118 [INFO] loss: 0.0164    [24,    20]\n","2024-02-09 07:35:03,144 [INFO] loss: 0.0161    [25,    10]\n","2024-02-09 07:35:03,164 [INFO] loss: 0.0163    [25,    20]\n","2024-02-09 07:35:03,188 [INFO] loss: 0.0161    [26,    10]\n","2024-02-09 07:35:03,207 [INFO] loss: 0.0163    [26,    20]\n","2024-02-09 07:35:03,230 [INFO] loss: 0.0172    [27,    10]\n","2024-02-09 07:35:03,248 [INFO] loss: 0.0170    [27,    20]\n","2024-02-09 07:35:03,271 [INFO] loss: 0.0162    [28,    10]\n","2024-02-09 07:35:03,289 [INFO] loss: 0.0169    [28,    20]\n","2024-02-09 07:35:03,312 [INFO] loss: 0.0169    [29,    10]\n","2024-02-09 07:35:03,330 [INFO] loss: 0.0175    [29,    20]\n","2024-02-09 07:35:03,353 [INFO] loss: 0.0160    [30,    10]\n","2024-02-09 07:35:03,371 [INFO] loss: 0.0171    [30,    20]\n","2024-02-09 07:35:03,394 [INFO] loss: 0.0165    [31,    10]\n","2024-02-09 07:35:03,412 [INFO] loss: 0.0173    [31,    20]\n","2024-02-09 07:35:03,435 [INFO] loss: 0.0167    [32,    10]\n","2024-02-09 07:35:03,456 [INFO] loss: 0.0170    [32,    20]\n","2024-02-09 07:35:03,482 [INFO] loss: 0.0163    [33,    10]\n","2024-02-09 07:35:03,501 [INFO] loss: 0.0168    [33,    20]\n","2024-02-09 07:35:03,525 [INFO] loss: 0.0164    [34,    10]\n","2024-02-09 07:35:03,543 [INFO] loss: 0.0170    [34,    20]\n","2024-02-09 07:35:03,566 [INFO] loss: 0.0162    [35,    10]\n","2024-02-09 07:35:03,586 [INFO] loss: 0.0170    [35,    20]\n","2024-02-09 07:35:03,609 [INFO] loss: 0.0161    [36,    10]\n","2024-02-09 07:35:03,628 [INFO] loss: 0.0172    [36,    20]\n","2024-02-09 07:35:03,653 [INFO] loss: 0.0155    [37,    10]\n","2024-02-09 07:35:03,673 [INFO] loss: 0.0177    [37,    20]\n","2024-02-09 07:35:03,699 [INFO] loss: 0.0176    [38,    10]\n","2024-02-09 07:35:03,719 [INFO] loss: 0.0155    [38,    20]\n","2024-02-09 07:35:03,744 [INFO] loss: 0.0158    [39,    10]\n","2024-02-09 07:35:03,763 [INFO] loss: 0.0155    [39,    20]\n","2024-02-09 07:35:03,787 [INFO] loss: 0.0163    [40,    10]\n","2024-02-09 07:35:03,808 [INFO] loss: 0.0155    [40,    20]\n","2024-02-09 07:35:03,831 [INFO] loss: 0.0154    [41,    10]\n","2024-02-09 07:35:03,849 [INFO] loss: 0.0166    [41,    20]\n","2024-02-09 07:35:03,873 [INFO] loss: 0.0151    [42,    10]\n","2024-02-09 07:35:03,895 [INFO] loss: 0.0169    [42,    20]\n","2024-02-09 07:35:03,922 [INFO] loss: 0.0149    [43,    10]\n","2024-02-09 07:35:03,941 [INFO] loss: 0.0162    [43,    20]\n","2024-02-09 07:35:03,964 [INFO] loss: 0.0148    [44,    10]\n","2024-02-09 07:35:03,982 [INFO] loss: 0.0167    [44,    20]\n","2024-02-09 07:35:04,007 [INFO] loss: 0.0165    [45,    10]\n","2024-02-09 07:35:04,026 [INFO] loss: 0.0148    [45,    20]\n","2024-02-09 07:35:04,051 [INFO] loss: 0.0147    [46,    10]\n","2024-02-09 07:35:04,069 [INFO] loss: 0.0167    [46,    20]\n","2024-02-09 07:35:04,093 [INFO] loss: 0.0158    [47,    10]\n","2024-02-09 07:35:04,111 [INFO] loss: 0.0164    [47,    20]\n","2024-02-09 07:35:04,135 [INFO] loss: 0.0160    [48,    10]\n","2024-02-09 07:35:04,152 [INFO] loss: 0.0150    [48,    20]\n","2024-02-09 07:35:04,176 [INFO] loss: 0.0153    [49,    10]\n","2024-02-09 07:35:04,195 [INFO] loss: 0.0157    [49,    20]\n","2024-02-09 07:35:04,218 [INFO] loss: 0.0156    [50,    10]\n","2024-02-09 07:35:04,236 [INFO] loss: 0.0157    [50,    20]\n","2024-02-09 07:35:04,287 [INFO] Result on Train Data : {'AUC': 0.8663679004318952, 'ACC': 0.7510431154381085, 'F1 Score': 0.7503457693926681, 'AUPR': 0, 'Loss': 0.4709569565627886}\n","2024-02-09 07:35:04,288 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 07:35:04,290 [INFO] moving data and model to cuda\n","2024-02-09 07:35:04,308 [INFO] Result on Test Data : {'AUC': 0.8431224899598393, 'ACC': 0.6983240223463687, 'F1 Score': 0.6983146067415731, 'AUPR': 0, 'Loss': 0.5137664874394735}\n","2024-02-09 07:35:04,309 [INFO] Result of fold 3 : {'AUC': 0.8431224899598393, 'ACC': 0.6983240223463687, 'F1 Score': 0.6983146067415731, 'AUPR': 0, 'Loss': 0.5137664874394735}\n","2024-02-09 07:35:04,312 [INFO] ---- Fold 4 ----\n","2024-02-09 07:35:04,314 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-09 07:35:04,316 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-09 07:35:04,318 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 07:35:04,319 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-09 07:35:04,321 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 07:35:04,323 [INFO] moving data and model to cuda\n","2024-02-09 07:35:04,344 [INFO] loss: 0.0229    [1,    10]\n","2024-02-09 07:35:04,363 [INFO] loss: 0.0213    [1,    20]\n","2024-02-09 07:35:04,388 [INFO] loss: 0.0215    [2,    10]\n","2024-02-09 07:35:04,407 [INFO] loss: 0.0207    [2,    20]\n","2024-02-09 07:35:04,431 [INFO] loss: 0.0208    [3,    10]\n","2024-02-09 07:35:04,451 [INFO] loss: 0.0200    [3,    20]\n","2024-02-09 07:35:04,479 [INFO] loss: 0.0195    [4,    10]\n","2024-02-09 07:35:04,498 [INFO] loss: 0.0210    [4,    20]\n","2024-02-09 07:35:04,523 [INFO] loss: 0.0189    [5,    10]\n","2024-02-09 07:35:04,542 [INFO] loss: 0.0197    [5,    20]\n","2024-02-09 07:35:04,566 [INFO] loss: 0.0194    [6,    10]\n","2024-02-09 07:35:04,587 [INFO] loss: 0.0191    [6,    20]\n","2024-02-09 07:35:04,612 [INFO] loss: 0.0190    [7,    10]\n","2024-02-09 07:35:04,635 [INFO] loss: 0.0195    [7,    20]\n","2024-02-09 07:35:04,663 [INFO] loss: 0.0189    [8,    10]\n","2024-02-09 07:35:04,683 [INFO] loss: 0.0193    [8,    20]\n","2024-02-09 07:35:04,707 [INFO] loss: 0.0183    [9,    10]\n","2024-02-09 07:35:04,725 [INFO] loss: 0.0192    [9,    20]\n","2024-02-09 07:35:04,750 [INFO] loss: 0.0188    [10,    10]\n","2024-02-09 07:35:04,769 [INFO] loss: 0.0186    [10,    20]\n","2024-02-09 07:35:04,794 [INFO] loss: 0.0180    [11,    10]\n","2024-02-09 07:35:04,812 [INFO] loss: 0.0186    [11,    20]\n","2024-02-09 07:35:04,836 [INFO] loss: 0.0192    [12,    10]\n","2024-02-09 07:35:04,854 [INFO] loss: 0.0178    [12,    20]\n","2024-02-09 07:35:04,877 [INFO] loss: 0.0181    [13,    10]\n","2024-02-09 07:35:04,896 [INFO] loss: 0.0185    [13,    20]\n","2024-02-09 07:35:04,925 [INFO] loss: 0.0179    [14,    10]\n","2024-02-09 07:35:04,946 [INFO] loss: 0.0180    [14,    20]\n","2024-02-09 07:35:04,970 [INFO] loss: 0.0182    [15,    10]\n","2024-02-09 07:35:04,992 [INFO] loss: 0.0170    [15,    20]\n","2024-02-09 07:35:05,017 [INFO] loss: 0.0170    [16,    10]\n","2024-02-09 07:35:05,037 [INFO] loss: 0.0186    [16,    20]\n","2024-02-09 07:35:05,062 [INFO] loss: 0.0188    [17,    10]\n","2024-02-09 07:35:05,080 [INFO] loss: 0.0177    [17,    20]\n","2024-02-09 07:35:05,105 [INFO] loss: 0.0180    [18,    10]\n","2024-02-09 07:35:05,124 [INFO] loss: 0.0172    [18,    20]\n","2024-02-09 07:35:05,148 [INFO] loss: 0.0183    [19,    10]\n","2024-02-09 07:35:05,167 [INFO] loss: 0.0174    [19,    20]\n","2024-02-09 07:35:05,190 [INFO] loss: 0.0164    [20,    10]\n","2024-02-09 07:35:05,209 [INFO] loss: 0.0175    [20,    20]\n","2024-02-09 07:35:05,231 [INFO] loss: 0.0184    [21,    10]\n","2024-02-09 07:35:05,251 [INFO] loss: 0.0176    [21,    20]\n","2024-02-09 07:35:05,274 [INFO] loss: 0.0184    [22,    10]\n","2024-02-09 07:35:05,292 [INFO] loss: 0.0171    [22,    20]\n","2024-02-09 07:35:05,317 [INFO] loss: 0.0170    [23,    10]\n","2024-02-09 07:35:05,338 [INFO] loss: 0.0182    [23,    20]\n","2024-02-09 07:35:05,362 [INFO] loss: 0.0171    [24,    10]\n","2024-02-09 07:35:05,380 [INFO] loss: 0.0170    [24,    20]\n","2024-02-09 07:35:05,403 [INFO] loss: 0.0175    [25,    10]\n","2024-02-09 07:35:05,424 [INFO] loss: 0.0169    [25,    20]\n","2024-02-09 07:35:05,448 [INFO] loss: 0.0169    [26,    10]\n","2024-02-09 07:35:05,467 [INFO] loss: 0.0178    [26,    20]\n","2024-02-09 07:35:05,490 [INFO] loss: 0.0167    [27,    10]\n","2024-02-09 07:35:05,509 [INFO] loss: 0.0185    [27,    20]\n","2024-02-09 07:35:05,531 [INFO] loss: 0.0183    [28,    10]\n","2024-02-09 07:35:05,549 [INFO] loss: 0.0166    [28,    20]\n","2024-02-09 07:35:05,572 [INFO] loss: 0.0173    [29,    10]\n","2024-02-09 07:35:05,591 [INFO] loss: 0.0170    [29,    20]\n","2024-02-09 07:35:05,614 [INFO] loss: 0.0168    [30,    10]\n","2024-02-09 07:35:05,634 [INFO] loss: 0.0176    [30,    20]\n","2024-02-09 07:35:05,657 [INFO] loss: 0.0170    [31,    10]\n","2024-02-09 07:35:05,675 [INFO] loss: 0.0165    [31,    20]\n","2024-02-09 07:35:05,698 [INFO] loss: 0.0168    [32,    10]\n","2024-02-09 07:35:05,716 [INFO] loss: 0.0165    [32,    20]\n","2024-02-09 07:35:05,739 [INFO] loss: 0.0163    [33,    10]\n","2024-02-09 07:35:05,756 [INFO] loss: 0.0166    [33,    20]\n","2024-02-09 07:35:05,779 [INFO] loss: 0.0166    [34,    10]\n","2024-02-09 07:35:05,798 [INFO] loss: 0.0162    [34,    20]\n","2024-02-09 07:35:05,820 [INFO] loss: 0.0168    [35,    10]\n","2024-02-09 07:35:05,840 [INFO] loss: 0.0170    [35,    20]\n","2024-02-09 07:35:05,867 [INFO] loss: 0.0170    [36,    10]\n","2024-02-09 07:35:05,886 [INFO] loss: 0.0167    [36,    20]\n","2024-02-09 07:35:05,911 [INFO] loss: 0.0168    [37,    10]\n","2024-02-09 07:35:05,930 [INFO] loss: 0.0174    [37,    20]\n","2024-02-09 07:35:05,961 [INFO] loss: 0.0178    [38,    10]\n","2024-02-09 07:35:05,979 [INFO] loss: 0.0163    [38,    20]\n","2024-02-09 07:35:06,003 [INFO] loss: 0.0170    [39,    10]\n","2024-02-09 07:35:06,022 [INFO] loss: 0.0164    [39,    20]\n","2024-02-09 07:35:06,048 [INFO] loss: 0.0174    [40,    10]\n","2024-02-09 07:35:06,068 [INFO] loss: 0.0159    [40,    20]\n","2024-02-09 07:35:06,093 [INFO] loss: 0.0170    [41,    10]\n","2024-02-09 07:35:06,112 [INFO] loss: 0.0160    [41,    20]\n","2024-02-09 07:35:06,136 [INFO] loss: 0.0169    [42,    10]\n","2024-02-09 07:35:06,155 [INFO] loss: 0.0170    [42,    20]\n","2024-02-09 07:35:06,178 [INFO] loss: 0.0156    [43,    10]\n","2024-02-09 07:35:06,196 [INFO] loss: 0.0183    [43,    20]\n","2024-02-09 07:35:06,220 [INFO] loss: 0.0170    [44,    10]\n","2024-02-09 07:35:06,238 [INFO] loss: 0.0166    [44,    20]\n","2024-02-09 07:35:06,262 [INFO] loss: 0.0166    [45,    10]\n","2024-02-09 07:35:06,281 [INFO] loss: 0.0165    [45,    20]\n","2024-02-09 07:35:06,304 [INFO] loss: 0.0168    [46,    10]\n","2024-02-09 07:35:06,323 [INFO] loss: 0.0164    [46,    20]\n","2024-02-09 07:35:06,347 [INFO] loss: 0.0183    [47,    10]\n","2024-02-09 07:35:06,366 [INFO] loss: 0.0152    [47,    20]\n","2024-02-09 07:35:06,390 [INFO] loss: 0.0174    [48,    10]\n","2024-02-09 07:35:06,410 [INFO] loss: 0.0159    [48,    20]\n","2024-02-09 07:35:06,434 [INFO] loss: 0.0160    [49,    10]\n","2024-02-09 07:35:06,453 [INFO] loss: 0.0169    [49,    20]\n","2024-02-09 07:35:06,480 [INFO] loss: 0.0156    [50,    10]\n","2024-02-09 07:35:06,498 [INFO] loss: 0.0175    [50,    20]\n","2024-02-09 07:35:06,545 [INFO] Result on Train Data : {'AUC': 0.8427134122745918, 'ACC': 0.7385257301808067, 'F1 Score': 0.737904664401942, 'AUPR': 0, 'Loss': 0.505656053190646}\n","2024-02-09 07:35:06,546 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 07:35:06,550 [INFO] moving data and model to cuda\n","2024-02-09 07:35:06,570 [INFO] Result on Test Data : {'AUC': 0.8830827067669174, 'ACC': 0.7932960893854749, 'F1 Score': 0.791184538260239, 'AUPR': 0, 'Loss': 0.45787029961744946}\n","2024-02-09 07:35:06,574 [INFO] Result of fold 4 : {'AUC': 0.8830827067669174, 'ACC': 0.7932960893854749, 'F1 Score': 0.791184538260239, 'AUPR': 0, 'Loss': 0.45787029961744946}\n","2024-02-09 07:35:06,576 [INFO] ---- Fold 5 ----\n","2024-02-09 07:35:06,580 [INFO] Initializing SimplePytorchData with X shape : torch.Size([716, 64]) and y shape : torch.Size([716, 1])\n","2024-02-09 07:35:06,583 [INFO] Initializing SimplePytorchData with X shape : torch.Size([182, 64]) and y shape : torch.Size([182, 1])\n","2024-02-09 07:35:06,585 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-09 07:35:06,585 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-09 07:35:06,587 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-09 07:35:06,588 [INFO] moving data and model to cuda\n","2024-02-09 07:35:06,613 [INFO] loss: 0.0215    [1,    10]\n","2024-02-09 07:35:06,633 [INFO] loss: 0.0212    [1,    20]\n","2024-02-09 07:35:06,655 [INFO] loss: 0.0205    [2,    10]\n","2024-02-09 07:35:06,673 [INFO] loss: 0.0196    [2,    20]\n","2024-02-09 07:35:06,697 [INFO] loss: 0.0202    [3,    10]\n","2024-02-09 07:35:06,716 [INFO] loss: 0.0191    [3,    20]\n","2024-02-09 07:35:06,739 [INFO] loss: 0.0201    [4,    10]\n","2024-02-09 07:35:06,757 [INFO] loss: 0.0187    [4,    20]\n","2024-02-09 07:35:06,781 [INFO] loss: 0.0186    [5,    10]\n","2024-02-09 07:35:06,799 [INFO] loss: 0.0201    [5,    20]\n","2024-02-09 07:35:06,822 [INFO] loss: 0.0188    [6,    10]\n","2024-02-09 07:35:06,840 [INFO] loss: 0.0191    [6,    20]\n","2024-02-09 07:35:06,862 [INFO] loss: 0.0191    [7,    10]\n","2024-02-09 07:35:06,880 [INFO] loss: 0.0178    [7,    20]\n","2024-02-09 07:35:06,906 [INFO] loss: 0.0183    [8,    10]\n","2024-02-09 07:35:06,927 [INFO] loss: 0.0177    [8,    20]\n","2024-02-09 07:35:06,959 [INFO] loss: 0.0185    [9,    10]\n","2024-02-09 07:35:06,988 [INFO] loss: 0.0191    [9,    20]\n","2024-02-09 07:35:07,023 [INFO] loss: 0.0180    [10,    10]\n","2024-02-09 07:35:07,047 [INFO] loss: 0.0177    [10,    20]\n","2024-02-09 07:35:07,081 [INFO] loss: 0.0175    [11,    10]\n","2024-02-09 07:35:07,104 [INFO] loss: 0.0185    [11,    20]\n","2024-02-09 07:35:07,136 [INFO] loss: 0.0180    [12,    10]\n","2024-02-09 07:35:07,161 [INFO] loss: 0.0172    [12,    20]\n","2024-02-09 07:35:07,197 [INFO] loss: 0.0167    [13,    10]\n","2024-02-09 07:35:07,226 [INFO] loss: 0.0182    [13,    20]\n","2024-02-09 07:35:07,257 [INFO] loss: 0.0179    [14,    10]\n","2024-02-09 07:35:07,283 [INFO] loss: 0.0172    [14,    20]\n","2024-02-09 07:35:07,314 [INFO] loss: 0.0176    [15,    10]\n","2024-02-09 07:35:07,338 [INFO] loss: 0.0184    [15,    20]\n","2024-02-09 07:35:07,366 [INFO] loss: 0.0180    [16,    10]\n","2024-02-09 07:35:07,391 [INFO] loss: 0.0169    [16,    20]\n","2024-02-09 07:35:07,421 [INFO] loss: 0.0172    [17,    10]\n","2024-02-09 07:35:07,446 [INFO] loss: 0.0168    [17,    20]\n","2024-02-09 07:35:07,476 [INFO] loss: 0.0172    [18,    10]\n","2024-02-09 07:35:07,501 [INFO] loss: 0.0172    [18,    20]\n","2024-02-09 07:35:07,532 [INFO] loss: 0.0160    [19,    10]\n","2024-02-09 07:35:07,558 [INFO] loss: 0.0181    [19,    20]\n","2024-02-09 07:35:07,589 [INFO] loss: 0.0172    [20,    10]\n","2024-02-09 07:35:07,613 [INFO] loss: 0.0170    [20,    20]\n","2024-02-09 07:35:07,641 [INFO] loss: 0.0172    [21,    10]\n","2024-02-09 07:35:07,664 [INFO] loss: 0.0175    [21,    20]\n","2024-02-09 07:35:07,694 [INFO] loss: 0.0167    [22,    10]\n","2024-02-09 07:35:07,719 [INFO] loss: 0.0174    [22,    20]\n","2024-02-09 07:35:07,746 [INFO] loss: 0.0179    [23,    10]\n","2024-02-09 07:35:07,768 [INFO] loss: 0.0162    [23,    20]\n","2024-02-09 07:35:07,795 [INFO] loss: 0.0169    [24,    10]\n","2024-02-09 07:35:07,818 [INFO] loss: 0.0164    [24,    20]\n","2024-02-09 07:35:07,845 [INFO] loss: 0.0174    [25,    10]\n","2024-02-09 07:35:07,867 [INFO] loss: 0.0161    [25,    20]\n","2024-02-09 07:35:07,894 [INFO] loss: 0.0163    [26,    10]\n","2024-02-09 07:35:07,922 [INFO] loss: 0.0168    [26,    20]\n","2024-02-09 07:35:07,953 [INFO] loss: 0.0171    [27,    10]\n","2024-02-09 07:35:07,978 [INFO] loss: 0.0166    [27,    20]\n","2024-02-09 07:35:08,009 [INFO] loss: 0.0162    [28,    10]\n","2024-02-09 07:35:08,039 [INFO] loss: 0.0168    [28,    20]\n","2024-02-09 07:35:08,073 [INFO] loss: 0.0170    [29,    10]\n","2024-02-09 07:35:08,095 [INFO] loss: 0.0167    [29,    20]\n","2024-02-09 07:35:08,127 [INFO] loss: 0.0178    [30,    10]\n","2024-02-09 07:35:08,151 [INFO] loss: 0.0161    [30,    20]\n","2024-02-09 07:35:08,183 [INFO] loss: 0.0162    [31,    10]\n","2024-02-09 07:35:08,207 [INFO] loss: 0.0174    [31,    20]\n","2024-02-09 07:35:08,233 [INFO] loss: 0.0167    [32,    10]\n","2024-02-09 07:35:08,256 [INFO] loss: 0.0160    [32,    20]\n","2024-02-09 07:35:08,286 [INFO] loss: 0.0160    [33,    10]\n","2024-02-09 07:35:08,307 [INFO] loss: 0.0167    [33,    20]\n","2024-02-09 07:35:08,338 [INFO] loss: 0.0164    [34,    10]\n","2024-02-09 07:35:08,362 [INFO] loss: 0.0172    [34,    20]\n","2024-02-09 07:35:08,390 [INFO] loss: 0.0175    [35,    10]\n","2024-02-09 07:35:08,414 [INFO] loss: 0.0151    [35,    20]\n","2024-02-09 07:35:08,444 [INFO] loss: 0.0161    [36,    10]\n","2024-02-09 07:35:08,468 [INFO] loss: 0.0160    [36,    20]\n","2024-02-09 07:35:08,495 [INFO] loss: 0.0173    [37,    10]\n","2024-02-09 07:35:08,517 [INFO] loss: 0.0159    [37,    20]\n","2024-02-09 07:35:08,545 [INFO] loss: 0.0170    [38,    10]\n","2024-02-09 07:35:08,567 [INFO] loss: 0.0154    [38,    20]\n","2024-02-09 07:35:08,597 [INFO] loss: 0.0156    [39,    10]\n","2024-02-09 07:35:08,624 [INFO] loss: 0.0178    [39,    20]\n","2024-02-09 07:35:08,652 [INFO] loss: 0.0162    [40,    10]\n","2024-02-09 07:35:08,678 [INFO] loss: 0.0163    [40,    20]\n","2024-02-09 07:35:08,709 [INFO] loss: 0.0157    [41,    10]\n","2024-02-09 07:35:08,732 [INFO] loss: 0.0164    [41,    20]\n","2024-02-09 07:35:08,761 [INFO] loss: 0.0160    [42,    10]\n","2024-02-09 07:35:08,785 [INFO] loss: 0.0161    [42,    20]\n","2024-02-09 07:35:08,813 [INFO] loss: 0.0152    [43,    10]\n","2024-02-09 07:35:08,837 [INFO] loss: 0.0170    [43,    20]\n","2024-02-09 07:35:08,863 [INFO] loss: 0.0159    [44,    10]\n","2024-02-09 07:35:08,885 [INFO] loss: 0.0154    [44,    20]\n","2024-02-09 07:35:08,917 [INFO] loss: 0.0158    [45,    10]\n","2024-02-09 07:35:08,939 [INFO] loss: 0.0158    [45,    20]\n","2024-02-09 07:35:08,967 [INFO] loss: 0.0160    [46,    10]\n","2024-02-09 07:35:08,989 [INFO] loss: 0.0160    [46,    20]\n","2024-02-09 07:35:09,018 [INFO] loss: 0.0160    [47,    10]\n","2024-02-09 07:35:09,039 [INFO] loss: 0.0149    [47,    20]\n","2024-02-09 07:35:09,070 [INFO] loss: 0.0163    [48,    10]\n","2024-02-09 07:35:09,100 [INFO] loss: 0.0158    [48,    20]\n","2024-02-09 07:35:09,133 [INFO] loss: 0.0164    [49,    10]\n","2024-02-09 07:35:09,160 [INFO] loss: 0.0152    [49,    20]\n","2024-02-09 07:35:09,194 [INFO] loss: 0.0154    [50,    10]\n","2024-02-09 07:35:09,224 [INFO] loss: 0.0151    [50,    20]\n","2024-02-09 07:35:09,299 [INFO] Result on Train Data : {'AUC': 0.8277267616191905, 'ACC': 0.7318435754189944, 'F1 Score': 0.7243569692740792, 'AUPR': 0, 'Loss': 0.4987136708653491}\n","2024-02-09 07:35:09,301 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-09 07:35:09,303 [INFO] moving data and model to cuda\n","2024-02-09 07:35:09,331 [INFO] Result on Test Data : {'AUC': 0.7711771177117711, 'ACC': 0.6648351648351648, 'F1 Score': 0.664582011541134, 'AUPR': 0, 'Loss': 0.6195479432741801}\n","2024-02-09 07:35:09,332 [INFO] Result of fold 5 : {'AUC': 0.7711771177117711, 'ACC': 0.6648351648351648, 'F1 Score': 0.664582011541134, 'AUPR': 0, 'Loss': 0.6195479432741801}\n","2024-02-09 07:35:09,334 [INFO] 5-fold result: avg_auc: 0.822842541253784, avg_acc: 0.7139726195592118, avg_f1: 0.7126548164896311, avg_aupr: 0.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<base.evaluation.Result at 0x7d8387b13c40>"]},"metadata":{},"execution_count":56}],"source":["trainer = SimpleTrainer()\n","tester = SimpleTester()\n","factory = SimpleMDAClassifierFactory(simple_classifier_config)\n","spliter = SimplePytorchDataTrainTestSplit(data)\n","cross_validation(k=5, data_size=data.X.shape[0], train_test_spliter=spliter, model_factory=factory,\n","                    trainer=trainer, tester=tester, config=classifier_optimizer_config)"]},{"cell_type":"code","source":[],"metadata":{"id":"5cpQ0kPkjuHb","executionInfo":{"status":"ok","timestamp":1707464109594,"user_tz":-210,"elapsed":5,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"5cpQ0kPkjuHb","execution_count":56,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}