{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"initial_id","executionInfo":{"status":"ok","timestamp":1707589731396,"user_tz":-210,"elapsed":19237,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"9c87f5c6-a36a-4c95-8588-2fa6d98936df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install torch_geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODp_C8LiNecw","executionInfo":{"status":"ok","timestamp":1707589740729,"user_tz":-210,"elapsed":9338,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"5b4ed8dc-45c5-4910-b631-33867611c38a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch_geometric\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n","Installing collected packages: torch_geometric\n","Successfully installed torch_geometric-2.4.0\n"]}]},{"cell_type":"code","source":["!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IaKc5GwjNgRJ","executionInfo":{"status":"ok","timestamp":1707589755638,"user_tz":-210,"elapsed":14914,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"0db0d609-bcc1-4eeb-e30f-2f471f316d69"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\n","Collecting pyg_lib\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/pyg_lib-0.4.0%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_scatter\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (10.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_sparse\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_cluster\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_cluster-1.6.3%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_spline_conv\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (932 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m932.1/932.1 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n","Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n","Successfully installed pyg_lib-0.4.0+pt21cu121 torch_cluster-1.6.3+pt21cu121 torch_scatter-2.1.2+pt21cu121 torch_sparse-0.6.18+pt21cu121 torch_spline_conv-1.2.2+pt21cu121\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Academic/Topics/AI/Machine\\ Learning\\ Dr.\\ Montazeri/Project/ml_mda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M3IK7yupzyY1","executionInfo":{"status":"ok","timestamp":1707589756261,"user_tz":-210,"elapsed":628,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"3d54aa6b-5a3e-4441-852f-e898d97620e9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Academic/Topics/AI/Machine Learning Dr. Montazeri/Project/ml_mda\n"]}]},{"cell_type":"markdown","source":["# Requirements"],"metadata":{"id":"aaXjUjVnYll3"}},{"cell_type":"code","source":["import logging\n","import sys\n","\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n","    handlers=[\n","        logging.StreamHandler(stream=sys.stdout)\n","    ],\n","    force=True\n",")"],"metadata":{"id":"yXpOIvR5YklZ","executionInfo":{"status":"ok","timestamp":1707589756261,"user_tz":-210,"elapsed":4,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["logger = logging.getLogger(__name__)"],"metadata":{"id":"QWVnpkjfYrzA","executionInfo":{"status":"ok","timestamp":1707589756261,"user_tz":-210,"elapsed":3,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"2sZbUAxgOldC","executionInfo":{"status":"ok","timestamp":1707589761663,"user_tz":-210,"elapsed":5405,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from src.optimization import MatrixFeatureBasedMDAClassifierTrainer, MatrixFeatureBasedMDAClassifierTester\n","from src.config import MatrixDecomposerConfig, SimpleClassifierConfig\n","from src.models import MDFeatureBasedMDAClassifier, MDFeatureBasedMDAClassifierFactory\n","from src.data import MicrobeDiseaseAssociationData, MicrobeDiseaseAssociationTrainTestSpliter\n","from src.features import get_associations, get_entities\n","from src.utils import train_test_sampler\n","from base import cross_validation, OptimizerConfig\n"],"metadata":{"id":"cHjWWIUoPOMF","executionInfo":{"status":"ok","timestamp":1707589776728,"user_tz":-210,"elapsed":15070,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"86e0f344-1c0a-4189-fc79-e7180cba05eb"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-10 18:29:31,749 [INFO] NumExpr defaulting to 2 threads.\n"]}]},{"cell_type":"markdown","source":["# Classification"],"metadata":{"id":"T_hIMihJMts8"}},{"cell_type":"markdown","source":["## Data"],"metadata":{"id":"ocxVXIz1MqLJ"}},{"cell_type":"code","source":["associations = get_associations()\n","\n","train_indices, test_indices = train_test_sampler(associations.shape[0], 0.7)\n","\n","data = MicrobeDiseaseAssociationData(associations)\n","\n","train_data = MicrobeDiseaseAssociationData(associations.iloc[train_indices])\n","test_data = MicrobeDiseaseAssociationData(associations.iloc[test_indices])"],"metadata":{"id":"mvgDdf_8OfRt","executionInfo":{"status":"ok","timestamp":1707589777299,"user_tz":-210,"elapsed":574,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Classifier"],"metadata":{"id":"ye_6wl6nxmhs"}},{"cell_type":"code","source":["microbe_ids = get_entities().loc[get_entities()['type'] == 'Microbe']['id'].tolist()\n","disease_ids = get_entities().loc[get_entities()['type'] == 'Disease']['id'].tolist()"],"metadata":{"id":"PLZr69Ms1NiF","executionInfo":{"status":"ok","timestamp":1707589778371,"user_tz":-210,"elapsed":1075,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["md_config = MatrixDecomposerConfig()\n","md_config.model_name = \"NMF MDA Classifier\"\n","md_config.microbe_ids = microbe_ids\n","md_config.disease_ids = disease_ids\n","md_config.n_components = 40\n","md_config.random_state = 1\n","md_config.decomposer = 'NMF'"],"metadata":{"id":"ROf3FrGd1BBi","executionInfo":{"status":"ok","timestamp":1707589778372,"user_tz":-210,"elapsed":5,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["simple_classifier_config = SimpleClassifierConfig()\n","simple_classifier_config.model_name = \"simple classifier\"\n","simple_classifier_config.input_dim = md_config.n_components * 2\n","simple_classifier_config.hidden_dim = 32\n","simple_classifier_config.output_dim = 1\n","simple_classifier_config.num_layers = 2\n","simple_classifier_config.dropout = 0.1"],"metadata":{"id":"BFTQsCl8M9bv","executionInfo":{"status":"ok","timestamp":1707589778372,"user_tz":-210,"elapsed":4,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["mda_classifier = MDFeatureBasedMDAClassifier(simple_classifier_config, md_config)"],"metadata":{"id":"1ciyBQ4QM_0U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707589778372,"user_tz":-210,"elapsed":4,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"cc5b61b1-0a9e-4669-8593-cff0b19e19f8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-10 18:29:37,792 [INFO] Initializing MDFeatureBasedMDAClassifier with model : simple classifier\n","2024-02-10 18:29:37,796 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-10 18:29:37,798 [INFO] Initial SimpleMLP with 80 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-10 18:29:37,834 [INFO] Initializing MatrixFeatureExtractor\n","2024-02-10 18:29:37,836 [INFO] Initializing MFFeatureExtractor with model : None and decomposer : NMF\n"]}]},{"cell_type":"markdown","source":["## Optimizer"],"metadata":{"id":"s_5cdKvOx4q5"}},{"cell_type":"code","source":["classifier_optimizer_config = OptimizerConfig()\n","classifier_optimizer_config.optimizer = torch.optim.Adam\n","classifier_optimizer_config.criterion = torch.nn.BCEWithLogitsLoss()\n","classifier_optimizer_config.lr = 0.01\n","classifier_optimizer_config.batch_size = 32\n","classifier_optimizer_config.n_epoch = 50\n","classifier_optimizer_config.exp_name = \"adam optimizer\"\n","classifier_optimizer_config.save = False\n","classifier_optimizer_config.save_path = None\n","classifier_optimizer_config.device = device\n","classifier_optimizer_config.report_size = 10  # batch to report ratio\n","classifier_optimizer_config.threshold = 0.5"],"metadata":{"id":"3D6yhiPpNEc8","executionInfo":{"status":"ok","timestamp":1707589778372,"user_tz":-210,"elapsed":3,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Train Test Approach"],"metadata":{"id":"4iI5bMmJNQV3"}},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"h24KnmDZNAgD"}},{"cell_type":"code","source":["train_result = MatrixFeatureBasedMDAClassifierTrainer().train(model=mda_classifier,\n","                                                          data=train_data,\n","                                                          config=classifier_optimizer_config)"],"metadata":{"id":"OqKrF7HmNFx1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707589865799,"user_tz":-210,"elapsed":87430,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"ffe0f94d-0e1e-4012-9ba5-ae22ee685a86"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-10 18:29:37,857 [INFO] Call Training with adam optimizer\n","2024-02-10 18:29:37,869 [INFO] Calling build with associations :      disease  microbe  increased\n","190    59444    54894          1\n","293    66623    10559          1\n","251    43621    42610          1\n","93     50863    31268          1\n","424    43621      431          1\n","..       ...      ...        ...\n","845     7877     8218          0\n","769      654    20724          0\n","784    12403    50024          0\n","71     33293    39272          1\n","189    13213    14120          1\n","\n","[628 rows x 3 columns]\n","2024-02-10 18:29:37,960 [INFO] interaction matrix with shape (5179, 5645) has built\n","2024-02-10 18:29:38,231 [INFO] mask matrix with shape (5179, 5645) has built. This matrix shows not non elements.\n","2024-02-10 18:29:39,742 [INFO] interaction has been imputed to delete nans\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["2024-02-10 18:31:03,614 [INFO] Initializing SimplePytorchData with X shape : torch.Size([628, 80]) and y shape : torch.Size([628, 1])\n","2024-02-10 18:31:03,616 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-10 18:31:03,619 [INFO] moving data and model to cpu\n","2024-02-10 18:31:03,766 [INFO] loss: 0.0545    [1,    10]\n","2024-02-10 18:31:03,784 [INFO] loss: 0.0270    [1,    20]\n","2024-02-10 18:31:03,801 [INFO] loss: 0.0225    [2,    10]\n","2024-02-10 18:31:03,819 [INFO] loss: 0.0217    [2,    20]\n","2024-02-10 18:31:03,838 [INFO] loss: 0.0146    [3,    10]\n","2024-02-10 18:31:03,855 [INFO] loss: 0.0185    [3,    20]\n","2024-02-10 18:31:03,873 [INFO] loss: 0.0145    [4,    10]\n","2024-02-10 18:31:03,899 [INFO] loss: 0.0158    [4,    20]\n","2024-02-10 18:31:03,917 [INFO] loss: 0.0138    [5,    10]\n","2024-02-10 18:31:03,936 [INFO] loss: 0.0153    [5,    20]\n","2024-02-10 18:31:03,953 [INFO] loss: 0.0135    [6,    10]\n","2024-02-10 18:31:03,972 [INFO] loss: 0.0148    [6,    20]\n","2024-02-10 18:31:03,990 [INFO] loss: 0.0133    [7,    10]\n","2024-02-10 18:31:04,007 [INFO] loss: 0.0140    [7,    20]\n","2024-02-10 18:31:04,023 [INFO] loss: 0.0132    [8,    10]\n","2024-02-10 18:31:04,041 [INFO] loss: 0.0143    [8,    20]\n","2024-02-10 18:31:04,058 [INFO] loss: 0.0144    [9,    10]\n","2024-02-10 18:31:04,075 [INFO] loss: 0.0121    [9,    20]\n","2024-02-10 18:31:04,093 [INFO] loss: 0.0135    [10,    10]\n","2024-02-10 18:31:04,111 [INFO] loss: 0.0133    [10,    20]\n","2024-02-10 18:31:04,128 [INFO] loss: 0.0109    [11,    10]\n","2024-02-10 18:31:04,145 [INFO] loss: 0.0149    [11,    20]\n","2024-02-10 18:31:04,166 [INFO] loss: 0.0118    [12,    10]\n","2024-02-10 18:31:04,183 [INFO] loss: 0.0139    [12,    20]\n","2024-02-10 18:31:04,201 [INFO] loss: 0.0103    [13,    10]\n","2024-02-10 18:31:04,218 [INFO] loss: 0.0142    [13,    20]\n","2024-02-10 18:31:04,235 [INFO] loss: 0.0126    [14,    10]\n","2024-02-10 18:31:04,251 [INFO] loss: 0.0125    [14,    20]\n","2024-02-10 18:31:04,268 [INFO] loss: 0.0122    [15,    10]\n","2024-02-10 18:31:04,285 [INFO] loss: 0.0120    [15,    20]\n","2024-02-10 18:31:04,302 [INFO] loss: 0.0114    [16,    10]\n","2024-02-10 18:31:04,319 [INFO] loss: 0.0129    [16,    20]\n","2024-02-10 18:31:04,337 [INFO] loss: 0.0105    [17,    10]\n","2024-02-10 18:31:04,355 [INFO] loss: 0.0135    [17,    20]\n","2024-02-10 18:31:04,373 [INFO] loss: 0.0117    [18,    10]\n","2024-02-10 18:31:04,393 [INFO] loss: 0.0133    [18,    20]\n","2024-02-10 18:31:04,411 [INFO] loss: 0.0115    [19,    10]\n","2024-02-10 18:31:04,428 [INFO] loss: 0.0125    [19,    20]\n","2024-02-10 18:31:04,445 [INFO] loss: 0.0124    [20,    10]\n","2024-02-10 18:31:04,462 [INFO] loss: 0.0117    [20,    20]\n","2024-02-10 18:31:04,479 [INFO] loss: 0.0104    [21,    10]\n","2024-02-10 18:31:04,497 [INFO] loss: 0.0116    [21,    20]\n","2024-02-10 18:31:04,514 [INFO] loss: 0.0118    [22,    10]\n","2024-02-10 18:31:04,531 [INFO] loss: 0.0103    [22,    20]\n","2024-02-10 18:31:04,548 [INFO] loss: 0.0102    [23,    10]\n","2024-02-10 18:31:04,565 [INFO] loss: 0.0109    [23,    20]\n","2024-02-10 18:31:04,582 [INFO] loss: 0.0107    [24,    10]\n","2024-02-10 18:31:04,599 [INFO] loss: 0.0107    [24,    20]\n","2024-02-10 18:31:04,616 [INFO] loss: 0.0097    [25,    10]\n","2024-02-10 18:31:04,633 [INFO] loss: 0.0131    [25,    20]\n","2024-02-10 18:31:04,650 [INFO] loss: 0.0100    [26,    10]\n","2024-02-10 18:31:04,668 [INFO] loss: 0.0103    [26,    20]\n","2024-02-10 18:31:04,687 [INFO] loss: 0.0103    [27,    10]\n","2024-02-10 18:31:04,706 [INFO] loss: 0.0106    [27,    20]\n","2024-02-10 18:31:04,734 [INFO] loss: 0.0104    [28,    10]\n","2024-02-10 18:31:04,755 [INFO] loss: 0.0107    [28,    20]\n","2024-02-10 18:31:04,776 [INFO] loss: 0.0088    [29,    10]\n","2024-02-10 18:31:04,799 [INFO] loss: 0.0108    [29,    20]\n","2024-02-10 18:31:04,816 [INFO] loss: 0.0090    [30,    10]\n","2024-02-10 18:31:04,835 [INFO] loss: 0.0105    [30,    20]\n","2024-02-10 18:31:04,857 [INFO] loss: 0.0089    [31,    10]\n","2024-02-10 18:31:04,876 [INFO] loss: 0.0108    [31,    20]\n","2024-02-10 18:31:04,894 [INFO] loss: 0.0091    [32,    10]\n","2024-02-10 18:31:04,910 [INFO] loss: 0.0098    [32,    20]\n","2024-02-10 18:31:04,928 [INFO] loss: 0.0082    [33,    10]\n","2024-02-10 18:31:04,946 [INFO] loss: 0.0104    [33,    20]\n","2024-02-10 18:31:04,964 [INFO] loss: 0.0097    [34,    10]\n","2024-02-10 18:31:04,982 [INFO] loss: 0.0080    [34,    20]\n","2024-02-10 18:31:05,000 [INFO] loss: 0.0107    [35,    10]\n","2024-02-10 18:31:05,018 [INFO] loss: 0.0083    [35,    20]\n","2024-02-10 18:31:05,037 [INFO] loss: 0.0092    [36,    10]\n","2024-02-10 18:31:05,054 [INFO] loss: 0.0096    [36,    20]\n","2024-02-10 18:31:05,073 [INFO] loss: 0.0084    [37,    10]\n","2024-02-10 18:31:05,092 [INFO] loss: 0.0092    [37,    20]\n","2024-02-10 18:31:05,111 [INFO] loss: 0.0083    [38,    10]\n","2024-02-10 18:31:05,129 [INFO] loss: 0.0088    [38,    20]\n","2024-02-10 18:31:05,149 [INFO] loss: 0.0079    [39,    10]\n","2024-02-10 18:31:05,171 [INFO] loss: 0.0102    [39,    20]\n","2024-02-10 18:31:05,191 [INFO] loss: 0.0078    [40,    10]\n","2024-02-10 18:31:05,209 [INFO] loss: 0.0088    [40,    20]\n","2024-02-10 18:31:05,228 [INFO] loss: 0.0074    [41,    10]\n","2024-02-10 18:31:05,248 [INFO] loss: 0.0097    [41,    20]\n","2024-02-10 18:31:05,267 [INFO] loss: 0.0084    [42,    10]\n","2024-02-10 18:31:05,285 [INFO] loss: 0.0073    [42,    20]\n","2024-02-10 18:31:05,303 [INFO] loss: 0.0074    [43,    10]\n","2024-02-10 18:31:05,321 [INFO] loss: 0.0082    [43,    20]\n","2024-02-10 18:31:05,339 [INFO] loss: 0.0085    [44,    10]\n","2024-02-10 18:31:05,359 [INFO] loss: 0.0085    [44,    20]\n","2024-02-10 18:31:05,377 [INFO] loss: 0.0086    [45,    10]\n","2024-02-10 18:31:05,396 [INFO] loss: 0.0079    [45,    20]\n","2024-02-10 18:31:05,414 [INFO] loss: 0.0066    [46,    10]\n","2024-02-10 18:31:05,435 [INFO] loss: 0.0090    [46,    20]\n","2024-02-10 18:31:05,458 [INFO] loss: 0.0081    [47,    10]\n","2024-02-10 18:31:05,477 [INFO] loss: 0.0080    [47,    20]\n","2024-02-10 18:31:05,495 [INFO] loss: 0.0070    [48,    10]\n","2024-02-10 18:31:05,512 [INFO] loss: 0.0085    [48,    20]\n","2024-02-10 18:31:05,530 [INFO] loss: 0.0075    [49,    10]\n","2024-02-10 18:31:05,548 [INFO] loss: 0.0067    [49,    20]\n","2024-02-10 18:31:05,566 [INFO] loss: 0.0067    [50,    10]\n","2024-02-10 18:31:05,583 [INFO] loss: 0.0093    [50,    20]\n","2024-02-10 18:31:05,622 [INFO] Result on Train Data : {'AUC': 0.9782544753790761, 'ACC': 0.9219745222929936, 'F1 Score': 0.9219743244511047, 'AUPR': 0, 'Loss': 0.20361672192811966}\n"]}]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"0eQGNWm_NMVG"}},{"cell_type":"code","source":["test_result = MatrixFeatureBasedMDAClassifierTester().test(model=mda_classifier,\n","                                                       data=test_data,\n","                                                       config=classifier_optimizer_config)"],"metadata":{"id":"U05mXL_fNHpG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707589866383,"user_tz":-210,"elapsed":591,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"b41f92c0-2dd9-48f2-f505-30b2e82a0b25"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-10 18:31:05,634 [INFO] Call Testing with adam optimizer\n","2024-02-10 18:31:05,725 [INFO] Initializing SimplePytorchData with X shape : torch.Size([270, 80]) and y shape : torch.Size([270, 1])\n","2024-02-10 18:31:05,729 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-10 18:31:05,732 [INFO] moving data and model to cpu\n","2024-02-10 18:31:05,769 [INFO] Result on Test Data : {'AUC': 0.9586282578875172, 'ACC': 0.8888888888888888, 'F1 Score': 0.8888644970089457, 'AUPR': 0, 'Loss': 0.28061404824256897}\n"]}]},{"cell_type":"code","source":["test_result.get_result()"],"metadata":{"id":"oqgiZQqRWWGF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707589866384,"user_tz":-210,"elapsed":8,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"3132c832-cc24-46db-d417-315ac3a7643b"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'AUC': 0.9586282578875172,\n"," 'ACC': 0.8888888888888888,\n"," 'F1 Score': 0.8888644970089457,\n"," 'AUPR': 0,\n"," 'Loss': 0.28061404824256897}"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["## Cross Validation"],"metadata":{"id":"ti8vEX_cNNwy"}},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707590271989,"user_tz":-210,"elapsed":405611,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"dcb2a58f-0132-496e-c4b0-e707acf490ae","id":"mwsonMO2O3DC"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-10 18:31:05,798 [INFO] Initializing MDFeatureBasedMDAClassifierFactory\n","2024-02-10 18:31:05,801 [INFO] Initializing MicrobeDiseaseAssociationTrainTestSpliter\n","2024-02-10 18:31:05,803 [INFO] Start 5-fold Cross Validation with config : adam optimizer\n","2024-02-10 18:31:05,805 [INFO] ---- Fold 1 ----\n","2024-02-10 18:31:05,808 [INFO] Initializing MDFeatureBasedMDAClassifier with model : simple classifier\n","2024-02-10 18:31:05,810 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-10 18:31:05,812 [INFO] Initial SimpleMLP with 80 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-10 18:31:05,814 [INFO] Initializing MatrixFeatureExtractor\n","2024-02-10 18:31:05,815 [INFO] Initializing MFFeatureExtractor with model : None and decomposer : NMF\n","2024-02-10 18:31:05,816 [INFO] Call Training with adam optimizer\n","2024-02-10 18:31:05,822 [INFO] Calling build with associations :      disease  microbe  increased\n","0      50863    33211          1\n","1      43621    40832          1\n","2      33293    47880          1\n","3      13213    53186          1\n","4      33293    14909          1\n","..       ...      ...        ...\n","892    22068    20153          0\n","893    64642    53920          0\n","895    25026    44316          0\n","896    31069    60226          0\n","897    64642     4251          0\n","\n","[719 rows x 3 columns]\n","2024-02-10 18:31:05,939 [INFO] interaction matrix with shape (5179, 5645) has built\n","2024-02-10 18:31:06,262 [INFO] mask matrix with shape (5179, 5645) has built. This matrix shows not non elements.\n","2024-02-10 18:31:08,313 [INFO] interaction has been imputed to delete nans\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["2024-02-10 18:32:29,791 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 80]) and y shape : torch.Size([719, 1])\n","2024-02-10 18:32:29,793 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-10 18:32:29,796 [INFO] moving data and model to cpu\n","2024-02-10 18:32:29,821 [INFO] loss: 0.0243    [1,    10]\n","2024-02-10 18:32:29,844 [INFO] loss: 0.0246    [1,    20]\n","2024-02-10 18:32:29,870 [INFO] loss: 0.0175    [2,    10]\n","2024-02-10 18:32:29,886 [INFO] loss: 0.0147    [2,    20]\n","2024-02-10 18:32:29,909 [INFO] loss: 0.0137    [3,    10]\n","2024-02-10 18:32:29,927 [INFO] loss: 0.0156    [3,    20]\n","2024-02-10 18:32:29,950 [INFO] loss: 0.0130    [4,    10]\n","2024-02-10 18:32:29,969 [INFO] loss: 0.0155    [4,    20]\n","2024-02-10 18:32:29,991 [INFO] loss: 0.0123    [5,    10]\n","2024-02-10 18:32:30,010 [INFO] loss: 0.0160    [5,    20]\n","2024-02-10 18:32:30,032 [INFO] loss: 0.0137    [6,    10]\n","2024-02-10 18:32:30,049 [INFO] loss: 0.0134    [6,    20]\n","2024-02-10 18:32:30,071 [INFO] loss: 0.0134    [7,    10]\n","2024-02-10 18:32:30,088 [INFO] loss: 0.0132    [7,    20]\n","2024-02-10 18:32:30,110 [INFO] loss: 0.0136    [8,    10]\n","2024-02-10 18:32:30,127 [INFO] loss: 0.0124    [8,    20]\n","2024-02-10 18:32:30,152 [INFO] loss: 0.0120    [9,    10]\n","2024-02-10 18:32:30,173 [INFO] loss: 0.0140    [9,    20]\n","2024-02-10 18:32:30,197 [INFO] loss: 0.0118    [10,    10]\n","2024-02-10 18:32:30,228 [INFO] loss: 0.0122    [10,    20]\n","2024-02-10 18:32:30,254 [INFO] loss: 0.0127    [11,    10]\n","2024-02-10 18:32:30,274 [INFO] loss: 0.0118    [11,    20]\n","2024-02-10 18:32:30,300 [INFO] loss: 0.0123    [12,    10]\n","2024-02-10 18:32:30,321 [INFO] loss: 0.0105    [12,    20]\n","2024-02-10 18:32:30,347 [INFO] loss: 0.0119    [13,    10]\n","2024-02-10 18:32:30,370 [INFO] loss: 0.0124    [13,    20]\n","2024-02-10 18:32:30,397 [INFO] loss: 0.0120    [14,    10]\n","2024-02-10 18:32:30,416 [INFO] loss: 0.0112    [14,    20]\n","2024-02-10 18:32:30,437 [INFO] loss: 0.0103    [15,    10]\n","2024-02-10 18:32:30,456 [INFO] loss: 0.0093    [15,    20]\n","2024-02-10 18:32:30,477 [INFO] loss: 0.0100    [16,    10]\n","2024-02-10 18:32:30,496 [INFO] loss: 0.0113    [16,    20]\n","2024-02-10 18:32:30,518 [INFO] loss: 0.0100    [17,    10]\n","2024-02-10 18:32:30,536 [INFO] loss: 0.0099    [17,    20]\n","2024-02-10 18:32:30,558 [INFO] loss: 0.0111    [18,    10]\n","2024-02-10 18:32:30,577 [INFO] loss: 0.0100    [18,    20]\n","2024-02-10 18:32:30,599 [INFO] loss: 0.0094    [19,    10]\n","2024-02-10 18:32:30,616 [INFO] loss: 0.0110    [19,    20]\n","2024-02-10 18:32:30,639 [INFO] loss: 0.0088    [20,    10]\n","2024-02-10 18:32:30,659 [INFO] loss: 0.0084    [20,    20]\n","2024-02-10 18:32:30,680 [INFO] loss: 0.0094    [21,    10]\n","2024-02-10 18:32:30,697 [INFO] loss: 0.0084    [21,    20]\n","2024-02-10 18:32:30,718 [INFO] loss: 0.0096    [22,    10]\n","2024-02-10 18:32:30,735 [INFO] loss: 0.0082    [22,    20]\n","2024-02-10 18:32:30,756 [INFO] loss: 0.0073    [23,    10]\n","2024-02-10 18:32:30,777 [INFO] loss: 0.0096    [23,    20]\n","2024-02-10 18:32:30,805 [INFO] loss: 0.0100    [24,    10]\n","2024-02-10 18:32:30,826 [INFO] loss: 0.0093    [24,    20]\n","2024-02-10 18:32:30,846 [INFO] loss: 0.0078    [25,    10]\n","2024-02-10 18:32:30,870 [INFO] loss: 0.0090    [25,    20]\n","2024-02-10 18:32:30,896 [INFO] loss: 0.0084    [26,    10]\n","2024-02-10 18:32:30,912 [INFO] loss: 0.0090    [26,    20]\n","2024-02-10 18:32:30,933 [INFO] loss: 0.0080    [27,    10]\n","2024-02-10 18:32:30,951 [INFO] loss: 0.0071    [27,    20]\n","2024-02-10 18:32:30,973 [INFO] loss: 0.0068    [28,    10]\n","2024-02-10 18:32:30,992 [INFO] loss: 0.0085    [28,    20]\n","2024-02-10 18:32:31,013 [INFO] loss: 0.0076    [29,    10]\n","2024-02-10 18:32:31,031 [INFO] loss: 0.0073    [29,    20]\n","2024-02-10 18:32:31,052 [INFO] loss: 0.0076    [30,    10]\n","2024-02-10 18:32:31,071 [INFO] loss: 0.0091    [30,    20]\n","2024-02-10 18:32:31,094 [INFO] loss: 0.0085    [31,    10]\n","2024-02-10 18:32:31,112 [INFO] loss: 0.0071    [31,    20]\n","2024-02-10 18:32:31,134 [INFO] loss: 0.0064    [32,    10]\n","2024-02-10 18:32:31,153 [INFO] loss: 0.0086    [32,    20]\n","2024-02-10 18:32:31,183 [INFO] loss: 0.0067    [33,    10]\n","2024-02-10 18:32:31,202 [INFO] loss: 0.0071    [33,    20]\n","2024-02-10 18:32:31,224 [INFO] loss: 0.0066    [34,    10]\n","2024-02-10 18:32:31,241 [INFO] loss: 0.0069    [34,    20]\n","2024-02-10 18:32:31,262 [INFO] loss: 0.0064    [35,    10]\n","2024-02-10 18:32:31,281 [INFO] loss: 0.0068    [35,    20]\n","2024-02-10 18:32:31,302 [INFO] loss: 0.0074    [36,    10]\n","2024-02-10 18:32:31,319 [INFO] loss: 0.0060    [36,    20]\n","2024-02-10 18:32:31,342 [INFO] loss: 0.0067    [37,    10]\n","2024-02-10 18:32:31,360 [INFO] loss: 0.0058    [37,    20]\n","2024-02-10 18:32:31,382 [INFO] loss: 0.0066    [38,    10]\n","2024-02-10 18:32:31,399 [INFO] loss: 0.0068    [38,    20]\n","2024-02-10 18:32:31,421 [INFO] loss: 0.0070    [39,    10]\n","2024-02-10 18:32:31,437 [INFO] loss: 0.0066    [39,    20]\n","2024-02-10 18:32:31,460 [INFO] loss: 0.0064    [40,    10]\n","2024-02-10 18:32:31,477 [INFO] loss: 0.0073    [40,    20]\n","2024-02-10 18:32:31,500 [INFO] loss: 0.0067    [41,    10]\n","2024-02-10 18:32:31,518 [INFO] loss: 0.0064    [41,    20]\n","2024-02-10 18:32:31,539 [INFO] loss: 0.0068    [42,    10]\n","2024-02-10 18:32:31,556 [INFO] loss: 0.0049    [42,    20]\n","2024-02-10 18:32:31,577 [INFO] loss: 0.0060    [43,    10]\n","2024-02-10 18:32:31,595 [INFO] loss: 0.0060    [43,    20]\n","2024-02-10 18:32:31,616 [INFO] loss: 0.0074    [44,    10]\n","2024-02-10 18:32:31,633 [INFO] loss: 0.0069    [44,    20]\n","2024-02-10 18:32:31,654 [INFO] loss: 0.0074    [45,    10]\n","2024-02-10 18:32:31,674 [INFO] loss: 0.0053    [45,    20]\n","2024-02-10 18:32:31,704 [INFO] loss: 0.0066    [46,    10]\n","2024-02-10 18:32:31,722 [INFO] loss: 0.0056    [46,    20]\n","2024-02-10 18:32:31,746 [INFO] loss: 0.0063    [47,    10]\n","2024-02-10 18:32:31,764 [INFO] loss: 0.0062    [47,    20]\n","2024-02-10 18:32:31,787 [INFO] loss: 0.0059    [48,    10]\n","2024-02-10 18:32:31,804 [INFO] loss: 0.0060    [48,    20]\n","2024-02-10 18:32:31,826 [INFO] loss: 0.0049    [49,    10]\n","2024-02-10 18:32:31,844 [INFO] loss: 0.0059    [49,    20]\n","2024-02-10 18:32:31,865 [INFO] loss: 0.0059    [50,    10]\n","2024-02-10 18:32:31,883 [INFO] loss: 0.0073    [50,    20]\n","2024-02-10 18:32:31,940 [INFO] Result on Train Data : {'AUC': 0.9865113759479957, 'ACC': 0.9415855354659249, 'F1 Score': 0.9415854224698236, 'AUPR': 0, 'Loss': 0.14869731567476108}\n","2024-02-10 18:32:31,943 [INFO] Call Testing with adam optimizer\n","2024-02-10 18:32:32,000 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 80]) and y shape : torch.Size([179, 1])\n","2024-02-10 18:32:32,002 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-10 18:32:32,006 [INFO] moving data and model to cpu\n","2024-02-10 18:32:32,030 [INFO] Result on Test Data : {'AUC': 0.7576971214017522, 'ACC': 0.6536312849162011, 'F1 Score': 0.6496843434343436, 'AUPR': 0, 'Loss': 1.3808979193369548}\n","2024-02-10 18:32:32,032 [INFO] Result of fold 1 : {'AUC': 0.7576971214017522, 'ACC': 0.6536312849162011, 'F1 Score': 0.6496843434343436, 'AUPR': 0, 'Loss': 1.3808979193369548}\n","2024-02-10 18:32:32,038 [INFO] ---- Fold 2 ----\n","2024-02-10 18:32:32,042 [INFO] Initializing MDFeatureBasedMDAClassifier with model : simple classifier\n","2024-02-10 18:32:32,045 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-10 18:32:32,048 [INFO] Initial SimpleMLP with 80 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-10 18:32:32,052 [INFO] Initializing MatrixFeatureExtractor\n","2024-02-10 18:32:32,055 [INFO] Initializing MFFeatureExtractor with model : None and decomposer : NMF\n","2024-02-10 18:32:32,058 [INFO] Call Training with adam optimizer\n","2024-02-10 18:32:32,065 [INFO] Calling build with associations :      disease  microbe  increased\n","0      50863    33211          1\n","2      33293    47880          1\n","3      13213    53186          1\n","4      33293    14909          1\n","5      33293    35937          1\n","..       ...      ...        ...\n","891    55164    18341          0\n","893    64642    53920          0\n","894    25026    60601          0\n","896    31069    60226          0\n","897    64642     4251          0\n","\n","[719 rows x 3 columns]\n","2024-02-10 18:32:32,171 [INFO] interaction matrix with shape (5179, 5645) has built\n","2024-02-10 18:32:32,475 [INFO] mask matrix with shape (5179, 5645) has built. This matrix shows not non elements.\n","2024-02-10 18:32:34,471 [INFO] interaction has been imputed to delete nans\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["2024-02-10 18:33:56,802 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 80]) and y shape : torch.Size([719, 1])\n","2024-02-10 18:33:56,804 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-10 18:33:56,807 [INFO] moving data and model to cpu\n","2024-02-10 18:33:56,829 [INFO] loss: 0.0270    [1,    10]\n","2024-02-10 18:33:56,845 [INFO] loss: 0.0219    [1,    20]\n","2024-02-10 18:33:56,865 [INFO] loss: 0.0194    [2,    10]\n","2024-02-10 18:33:56,885 [INFO] loss: 0.0175    [2,    20]\n","2024-02-10 18:33:56,911 [INFO] loss: 0.0151    [3,    10]\n","2024-02-10 18:33:56,927 [INFO] loss: 0.0150    [3,    20]\n","2024-02-10 18:33:56,951 [INFO] loss: 0.0147    [4,    10]\n","2024-02-10 18:33:56,970 [INFO] loss: 0.0135    [4,    20]\n","2024-02-10 18:33:56,992 [INFO] loss: 0.0135    [5,    10]\n","2024-02-10 18:33:57,008 [INFO] loss: 0.0127    [5,    20]\n","2024-02-10 18:33:57,030 [INFO] loss: 0.0147    [6,    10]\n","2024-02-10 18:33:57,047 [INFO] loss: 0.0133    [6,    20]\n","2024-02-10 18:33:57,066 [INFO] loss: 0.0120    [7,    10]\n","2024-02-10 18:33:57,084 [INFO] loss: 0.0126    [7,    20]\n","2024-02-10 18:33:57,104 [INFO] loss: 0.0119    [8,    10]\n","2024-02-10 18:33:57,120 [INFO] loss: 0.0140    [8,    20]\n","2024-02-10 18:33:57,140 [INFO] loss: 0.0124    [9,    10]\n","2024-02-10 18:33:57,161 [INFO] loss: 0.0114    [9,    20]\n","2024-02-10 18:33:57,181 [INFO] loss: 0.0118    [10,    10]\n","2024-02-10 18:33:57,199 [INFO] loss: 0.0118    [10,    20]\n","2024-02-10 18:33:57,221 [INFO] loss: 0.0111    [11,    10]\n","2024-02-10 18:33:57,237 [INFO] loss: 0.0112    [11,    20]\n","2024-02-10 18:33:57,259 [INFO] loss: 0.0115    [12,    10]\n","2024-02-10 18:33:57,276 [INFO] loss: 0.0107    [12,    20]\n","2024-02-10 18:33:57,296 [INFO] loss: 0.0106    [13,    10]\n","2024-02-10 18:33:57,313 [INFO] loss: 0.0108    [13,    20]\n","2024-02-10 18:33:57,335 [INFO] loss: 0.0110    [14,    10]\n","2024-02-10 18:33:57,352 [INFO] loss: 0.0115    [14,    20]\n","2024-02-10 18:33:57,373 [INFO] loss: 0.0118    [15,    10]\n","2024-02-10 18:33:57,389 [INFO] loss: 0.0093    [15,    20]\n","2024-02-10 18:33:57,409 [INFO] loss: 0.0106    [16,    10]\n","2024-02-10 18:33:57,427 [INFO] loss: 0.0102    [16,    20]\n","2024-02-10 18:33:57,449 [INFO] loss: 0.0110    [17,    10]\n","2024-02-10 18:33:57,466 [INFO] loss: 0.0106    [17,    20]\n","2024-02-10 18:33:57,486 [INFO] loss: 0.0093    [18,    10]\n","2024-02-10 18:33:57,503 [INFO] loss: 0.0109    [18,    20]\n","2024-02-10 18:33:57,524 [INFO] loss: 0.0109    [19,    10]\n","2024-02-10 18:33:57,540 [INFO] loss: 0.0108    [19,    20]\n","2024-02-10 18:33:57,560 [INFO] loss: 0.0110    [20,    10]\n","2024-02-10 18:33:57,577 [INFO] loss: 0.0089    [20,    20]\n","2024-02-10 18:33:57,598 [INFO] loss: 0.0098    [21,    10]\n","2024-02-10 18:33:57,615 [INFO] loss: 0.0121    [21,    20]\n","2024-02-10 18:33:57,635 [INFO] loss: 0.0097    [22,    10]\n","2024-02-10 18:33:57,652 [INFO] loss: 0.0105    [22,    20]\n","2024-02-10 18:33:57,674 [INFO] loss: 0.0096    [23,    10]\n","2024-02-10 18:33:57,692 [INFO] loss: 0.0105    [23,    20]\n","2024-02-10 18:33:57,712 [INFO] loss: 0.0101    [24,    10]\n","2024-02-10 18:33:57,729 [INFO] loss: 0.0093    [24,    20]\n","2024-02-10 18:33:57,749 [INFO] loss: 0.0091    [25,    10]\n","2024-02-10 18:33:57,765 [INFO] loss: 0.0101    [25,    20]\n","2024-02-10 18:33:57,785 [INFO] loss: 0.0089    [26,    10]\n","2024-02-10 18:33:57,803 [INFO] loss: 0.0108    [26,    20]\n","2024-02-10 18:33:57,823 [INFO] loss: 0.0097    [27,    10]\n","2024-02-10 18:33:57,840 [INFO] loss: 0.0113    [27,    20]\n","2024-02-10 18:33:57,863 [INFO] loss: 0.0102    [28,    10]\n","2024-02-10 18:33:57,880 [INFO] loss: 0.0110    [28,    20]\n","2024-02-10 18:33:57,902 [INFO] loss: 0.0098    [29,    10]\n","2024-02-10 18:33:57,925 [INFO] loss: 0.0102    [29,    20]\n","2024-02-10 18:33:57,949 [INFO] loss: 0.0088    [30,    10]\n","2024-02-10 18:33:57,965 [INFO] loss: 0.0116    [30,    20]\n","2024-02-10 18:33:57,986 [INFO] loss: 0.0092    [31,    10]\n","2024-02-10 18:33:58,002 [INFO] loss: 0.0094    [31,    20]\n","2024-02-10 18:33:58,023 [INFO] loss: 0.0093    [32,    10]\n","2024-02-10 18:33:58,041 [INFO] loss: 0.0085    [32,    20]\n","2024-02-10 18:33:58,061 [INFO] loss: 0.0086    [33,    10]\n","2024-02-10 18:33:58,077 [INFO] loss: 0.0094    [33,    20]\n","2024-02-10 18:33:58,099 [INFO] loss: 0.0096    [34,    10]\n","2024-02-10 18:33:58,115 [INFO] loss: 0.0085    [34,    20]\n","2024-02-10 18:33:58,135 [INFO] loss: 0.0073    [35,    10]\n","2024-02-10 18:33:58,152 [INFO] loss: 0.0106    [35,    20]\n","2024-02-10 18:33:58,174 [INFO] loss: 0.0084    [36,    10]\n","2024-02-10 18:33:58,192 [INFO] loss: 0.0103    [36,    20]\n","2024-02-10 18:33:58,213 [INFO] loss: 0.0088    [37,    10]\n","2024-02-10 18:33:58,229 [INFO] loss: 0.0088    [37,    20]\n","2024-02-10 18:33:58,250 [INFO] loss: 0.0082    [38,    10]\n","2024-02-10 18:33:58,266 [INFO] loss: 0.0087    [38,    20]\n","2024-02-10 18:33:58,288 [INFO] loss: 0.0078    [39,    10]\n","2024-02-10 18:33:58,304 [INFO] loss: 0.0085    [39,    20]\n","2024-02-10 18:33:58,326 [INFO] loss: 0.0088    [40,    10]\n","2024-02-10 18:33:58,342 [INFO] loss: 0.0090    [40,    20]\n","2024-02-10 18:33:58,363 [INFO] loss: 0.0088    [41,    10]\n","2024-02-10 18:33:58,380 [INFO] loss: 0.0096    [41,    20]\n","2024-02-10 18:33:58,400 [INFO] loss: 0.0092    [42,    10]\n","2024-02-10 18:33:58,418 [INFO] loss: 0.0082    [42,    20]\n","2024-02-10 18:33:58,438 [INFO] loss: 0.0088    [43,    10]\n","2024-02-10 18:33:58,455 [INFO] loss: 0.0086    [43,    20]\n","2024-02-10 18:33:58,476 [INFO] loss: 0.0086    [44,    10]\n","2024-02-10 18:33:58,493 [INFO] loss: 0.0086    [44,    20]\n","2024-02-10 18:33:58,514 [INFO] loss: 0.0086    [45,    10]\n","2024-02-10 18:33:58,531 [INFO] loss: 0.0080    [45,    20]\n","2024-02-10 18:33:58,552 [INFO] loss: 0.0099    [46,    10]\n","2024-02-10 18:33:58,569 [INFO] loss: 0.0080    [46,    20]\n","2024-02-10 18:33:58,590 [INFO] loss: 0.0086    [47,    10]\n","2024-02-10 18:33:58,610 [INFO] loss: 0.0075    [47,    20]\n","2024-02-10 18:33:58,630 [INFO] loss: 0.0072    [48,    10]\n","2024-02-10 18:33:58,647 [INFO] loss: 0.0090    [48,    20]\n","2024-02-10 18:33:58,667 [INFO] loss: 0.0073    [49,    10]\n","2024-02-10 18:33:58,684 [INFO] loss: 0.0074    [49,    20]\n","2024-02-10 18:33:58,705 [INFO] loss: 0.0073    [50,    10]\n","2024-02-10 18:33:58,723 [INFO] loss: 0.0093    [50,    20]\n","2024-02-10 18:33:58,771 [INFO] Result on Train Data : {'AUC': 0.969773290003095, 'ACC': 0.9068150208623088, 'F1 Score': 0.9067276955217755, 'AUPR': 0, 'Loss': 0.22499554118384485}\n","2024-02-10 18:33:58,773 [INFO] Call Testing with adam optimizer\n","2024-02-10 18:33:58,828 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 80]) and y shape : torch.Size([179, 1])\n","2024-02-10 18:33:58,829 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-10 18:33:58,831 [INFO] moving data and model to cpu\n","2024-02-10 18:33:58,853 [INFO] Result on Test Data : {'AUC': 0.8086142322097378, 'ACC': 0.7430167597765364, 'F1 Score': 0.7430087390761548, 'AUPR': 0, 'Loss': 0.8164715568224589}\n","2024-02-10 18:33:58,856 [INFO] Result of fold 2 : {'AUC': 0.8086142322097378, 'ACC': 0.7430167597765364, 'F1 Score': 0.7430087390761548, 'AUPR': 0, 'Loss': 0.8164715568224589}\n","2024-02-10 18:33:58,859 [INFO] ---- Fold 3 ----\n","2024-02-10 18:33:58,863 [INFO] Initializing MDFeatureBasedMDAClassifier with model : simple classifier\n","2024-02-10 18:33:58,865 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-10 18:33:58,868 [INFO] Initial SimpleMLP with 80 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-10 18:33:58,871 [INFO] Initializing MatrixFeatureExtractor\n","2024-02-10 18:33:58,873 [INFO] Initializing MFFeatureExtractor with model : None and decomposer : NMF\n","2024-02-10 18:33:58,874 [INFO] Call Training with adam optimizer\n","2024-02-10 18:33:58,880 [INFO] Calling build with associations :      disease  microbe  increased\n","0      50863    33211          1\n","1      43621    40832          1\n","2      33293    47880          1\n","4      33293    14909          1\n","6      12403    26565          1\n","..       ...      ...        ...\n","893    64642    53920          0\n","894    25026    60601          0\n","895    25026    44316          0\n","896    31069    60226          0\n","897    64642     4251          0\n","\n","[719 rows x 3 columns]\n","2024-02-10 18:33:58,949 [INFO] interaction matrix with shape (5179, 5645) has built\n","2024-02-10 18:33:59,266 [INFO] mask matrix with shape (5179, 5645) has built. This matrix shows not non elements.\n","2024-02-10 18:34:01,811 [INFO] interaction has been imputed to delete nans\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["2024-02-10 18:35:22,675 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 80]) and y shape : torch.Size([719, 1])\n","2024-02-10 18:35:22,678 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-10 18:35:22,680 [INFO] moving data and model to cpu\n","2024-02-10 18:35:22,703 [INFO] loss: 0.0340    [1,    10]\n","2024-02-10 18:35:22,719 [INFO] loss: 0.0203    [1,    20]\n","2024-02-10 18:35:22,740 [INFO] loss: 0.0152    [2,    10]\n","2024-02-10 18:35:22,762 [INFO] loss: 0.0172    [2,    20]\n","2024-02-10 18:35:22,783 [INFO] loss: 0.0152    [3,    10]\n","2024-02-10 18:35:22,802 [INFO] loss: 0.0183    [3,    20]\n","2024-02-10 18:35:22,823 [INFO] loss: 0.0155    [4,    10]\n","2024-02-10 18:35:22,840 [INFO] loss: 0.0150    [4,    20]\n","2024-02-10 18:35:22,861 [INFO] loss: 0.0159    [5,    10]\n","2024-02-10 18:35:22,878 [INFO] loss: 0.0144    [5,    20]\n","2024-02-10 18:35:22,904 [INFO] loss: 0.0141    [6,    10]\n","2024-02-10 18:35:22,920 [INFO] loss: 0.0132    [6,    20]\n","2024-02-10 18:35:22,940 [INFO] loss: 0.0130    [7,    10]\n","2024-02-10 18:35:22,963 [INFO] loss: 0.0138    [7,    20]\n","2024-02-10 18:35:22,988 [INFO] loss: 0.0131    [8,    10]\n","2024-02-10 18:35:23,005 [INFO] loss: 0.0127    [8,    20]\n","2024-02-10 18:35:23,029 [INFO] loss: 0.0134    [9,    10]\n","2024-02-10 18:35:23,046 [INFO] loss: 0.0136    [9,    20]\n","2024-02-10 18:35:23,067 [INFO] loss: 0.0135    [10,    10]\n","2024-02-10 18:35:23,084 [INFO] loss: 0.0120    [10,    20]\n","2024-02-10 18:35:23,107 [INFO] loss: 0.0126    [11,    10]\n","2024-02-10 18:35:23,127 [INFO] loss: 0.0124    [11,    20]\n","2024-02-10 18:35:23,148 [INFO] loss: 0.0121    [12,    10]\n","2024-02-10 18:35:23,167 [INFO] loss: 0.0115    [12,    20]\n","2024-02-10 18:35:23,189 [INFO] loss: 0.0105    [13,    10]\n","2024-02-10 18:35:23,207 [INFO] loss: 0.0122    [13,    20]\n","2024-02-10 18:35:23,228 [INFO] loss: 0.0108    [14,    10]\n","2024-02-10 18:35:23,246 [INFO] loss: 0.0126    [14,    20]\n","2024-02-10 18:35:23,267 [INFO] loss: 0.0105    [15,    10]\n","2024-02-10 18:35:23,285 [INFO] loss: 0.0114    [15,    20]\n","2024-02-10 18:35:23,306 [INFO] loss: 0.0105    [16,    10]\n","2024-02-10 18:35:23,323 [INFO] loss: 0.0113    [16,    20]\n","2024-02-10 18:35:23,347 [INFO] loss: 0.0112    [17,    10]\n","2024-02-10 18:35:23,368 [INFO] loss: 0.0114    [17,    20]\n","2024-02-10 18:35:23,389 [INFO] loss: 0.0101    [18,    10]\n","2024-02-10 18:35:23,407 [INFO] loss: 0.0104    [18,    20]\n","2024-02-10 18:35:23,439 [INFO] loss: 0.0097    [19,    10]\n","2024-02-10 18:35:23,463 [INFO] loss: 0.0107    [19,    20]\n","2024-02-10 18:35:23,496 [INFO] loss: 0.0106    [20,    10]\n","2024-02-10 18:35:23,526 [INFO] loss: 0.0101    [20,    20]\n","2024-02-10 18:35:23,554 [INFO] loss: 0.0100    [21,    10]\n","2024-02-10 18:35:23,584 [INFO] loss: 0.0097    [21,    20]\n","2024-02-10 18:35:23,620 [INFO] loss: 0.0101    [22,    10]\n","2024-02-10 18:35:23,647 [INFO] loss: 0.0100    [22,    20]\n","2024-02-10 18:35:23,675 [INFO] loss: 0.0088    [23,    10]\n","2024-02-10 18:35:23,698 [INFO] loss: 0.0104    [23,    20]\n","2024-02-10 18:35:23,724 [INFO] loss: 0.0085    [24,    10]\n","2024-02-10 18:35:23,749 [INFO] loss: 0.0104    [24,    20]\n","2024-02-10 18:35:23,790 [INFO] loss: 0.0079    [25,    10]\n","2024-02-10 18:35:23,811 [INFO] loss: 0.0092    [25,    20]\n","2024-02-10 18:35:23,838 [INFO] loss: 0.0090    [26,    10]\n","2024-02-10 18:35:23,859 [INFO] loss: 0.0097    [26,    20]\n","2024-02-10 18:35:23,887 [INFO] loss: 0.0077    [27,    10]\n","2024-02-10 18:35:23,908 [INFO] loss: 0.0099    [27,    20]\n","2024-02-10 18:35:23,933 [INFO] loss: 0.0091    [28,    10]\n","2024-02-10 18:35:23,952 [INFO] loss: 0.0086    [28,    20]\n","2024-02-10 18:35:23,991 [INFO] loss: 0.0095    [29,    10]\n","2024-02-10 18:35:24,018 [INFO] loss: 0.0082    [29,    20]\n","2024-02-10 18:35:24,046 [INFO] loss: 0.0092    [30,    10]\n","2024-02-10 18:35:24,070 [INFO] loss: 0.0089    [30,    20]\n","2024-02-10 18:35:24,096 [INFO] loss: 0.0079    [31,    10]\n","2024-02-10 18:35:24,116 [INFO] loss: 0.0085    [31,    20]\n","2024-02-10 18:35:24,142 [INFO] loss: 0.0070    [32,    10]\n","2024-02-10 18:35:24,168 [INFO] loss: 0.0091    [32,    20]\n","2024-02-10 18:35:24,194 [INFO] loss: 0.0073    [33,    10]\n","2024-02-10 18:35:24,214 [INFO] loss: 0.0095    [33,    20]\n","2024-02-10 18:35:24,240 [INFO] loss: 0.0080    [34,    10]\n","2024-02-10 18:35:24,261 [INFO] loss: 0.0092    [34,    20]\n","2024-02-10 18:35:24,286 [INFO] loss: 0.0080    [35,    10]\n","2024-02-10 18:35:24,312 [INFO] loss: 0.0087    [35,    20]\n","2024-02-10 18:35:24,340 [INFO] loss: 0.0078    [36,    10]\n","2024-02-10 18:35:24,362 [INFO] loss: 0.0070    [36,    20]\n","2024-02-10 18:35:24,393 [INFO] loss: 0.0072    [37,    10]\n","2024-02-10 18:35:24,418 [INFO] loss: 0.0095    [37,    20]\n","2024-02-10 18:35:24,448 [INFO] loss: 0.0072    [38,    10]\n","2024-02-10 18:35:24,471 [INFO] loss: 0.0082    [38,    20]\n","2024-02-10 18:35:24,500 [INFO] loss: 0.0078    [39,    10]\n","2024-02-10 18:35:24,524 [INFO] loss: 0.0081    [39,    20]\n","2024-02-10 18:35:24,551 [INFO] loss: 0.0075    [40,    10]\n","2024-02-10 18:35:24,575 [INFO] loss: 0.0085    [40,    20]\n","2024-02-10 18:35:24,602 [INFO] loss: 0.0076    [41,    10]\n","2024-02-10 18:35:24,623 [INFO] loss: 0.0078    [41,    20]\n","2024-02-10 18:35:24,653 [INFO] loss: 0.0071    [42,    10]\n","2024-02-10 18:35:24,674 [INFO] loss: 0.0083    [42,    20]\n","2024-02-10 18:35:24,701 [INFO] loss: 0.0070    [43,    10]\n","2024-02-10 18:35:24,727 [INFO] loss: 0.0076    [43,    20]\n","2024-02-10 18:35:24,755 [INFO] loss: 0.0079    [44,    10]\n","2024-02-10 18:35:24,780 [INFO] loss: 0.0074    [44,    20]\n","2024-02-10 18:35:24,809 [INFO] loss: 0.0068    [45,    10]\n","2024-02-10 18:35:24,835 [INFO] loss: 0.0068    [45,    20]\n","2024-02-10 18:35:24,882 [INFO] loss: 0.0068    [46,    10]\n","2024-02-10 18:35:24,914 [INFO] loss: 0.0081    [46,    20]\n","2024-02-10 18:35:24,949 [INFO] loss: 0.0064    [47,    10]\n","2024-02-10 18:35:24,978 [INFO] loss: 0.0079    [47,    20]\n","2024-02-10 18:35:25,012 [INFO] loss: 0.0085    [48,    10]\n","2024-02-10 18:35:25,034 [INFO] loss: 0.0064    [48,    20]\n","2024-02-10 18:35:25,070 [INFO] loss: 0.0062    [49,    10]\n","2024-02-10 18:35:25,103 [INFO] loss: 0.0081    [49,    20]\n","2024-02-10 18:35:25,140 [INFO] loss: 0.0065    [50,    10]\n","2024-02-10 18:35:25,169 [INFO] loss: 0.0071    [50,    20]\n","2024-02-10 18:35:25,245 [INFO] Result on Train Data : {'AUC': 0.9776365494178846, 'ACC': 0.9276773296244785, 'F1 Score': 0.9275055454728776, 'AUPR': 0, 'Loss': 0.18585614989633145}\n","2024-02-10 18:35:25,252 [INFO] Call Testing with adam optimizer\n","2024-02-10 18:35:25,354 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 80]) and y shape : torch.Size([179, 1])\n","2024-02-10 18:35:25,356 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-10 18:35:25,358 [INFO] moving data and model to cpu\n","2024-02-10 18:35:25,391 [INFO] Result on Test Data : {'AUC': 0.8589388986673372, 'ACC': 0.7988826815642458, 'F1 Score': 0.7926640926640927, 'AUPR': 0, 'Loss': 0.7367178251345953}\n","2024-02-10 18:35:25,394 [INFO] Result of fold 3 : {'AUC': 0.8589388986673372, 'ACC': 0.7988826815642458, 'F1 Score': 0.7926640926640927, 'AUPR': 0, 'Loss': 0.7367178251345953}\n","2024-02-10 18:35:25,399 [INFO] ---- Fold 4 ----\n","2024-02-10 18:35:25,403 [INFO] Initializing MDFeatureBasedMDAClassifier with model : simple classifier\n","2024-02-10 18:35:25,405 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-10 18:35:25,407 [INFO] Initial SimpleMLP with 80 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-10 18:35:25,409 [INFO] Initializing MatrixFeatureExtractor\n","2024-02-10 18:35:25,411 [INFO] Initializing MFFeatureExtractor with model : None and decomposer : NMF\n","2024-02-10 18:35:25,413 [INFO] Call Training with adam optimizer\n","2024-02-10 18:35:25,418 [INFO] Calling build with associations :      disease  microbe  increased\n","0      50863    33211          1\n","1      43621    40832          1\n","3      13213    53186          1\n","5      33293    35937          1\n","6      12403    26565          1\n","..       ...      ...        ...\n","890      654    61681          0\n","891    55164    18341          0\n","892    22068    20153          0\n","894    25026    60601          0\n","895    25026    44316          0\n","\n","[719 rows x 3 columns]\n","2024-02-10 18:35:25,526 [INFO] interaction matrix with shape (5179, 5645) has built\n","2024-02-10 18:35:26,046 [INFO] mask matrix with shape (5179, 5645) has built. This matrix shows not non elements.\n","2024-02-10 18:35:27,987 [INFO] interaction has been imputed to delete nans\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["2024-02-10 18:36:38,035 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 80]) and y shape : torch.Size([719, 1])\n","2024-02-10 18:36:38,037 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-10 18:36:38,041 [INFO] moving data and model to cpu\n","2024-02-10 18:36:38,059 [INFO] loss: 0.0487    [1,    10]\n","2024-02-10 18:36:38,075 [INFO] loss: 0.0282    [1,    20]\n","2024-02-10 18:36:38,096 [INFO] loss: 0.0200    [2,    10]\n","2024-02-10 18:36:38,114 [INFO] loss: 0.0157    [2,    20]\n","2024-02-10 18:36:38,137 [INFO] loss: 0.0183    [3,    10]\n","2024-02-10 18:36:38,155 [INFO] loss: 0.0172    [3,    20]\n","2024-02-10 18:36:38,185 [INFO] loss: 0.0181    [4,    10]\n","2024-02-10 18:36:38,201 [INFO] loss: 0.0151    [4,    20]\n","2024-02-10 18:36:38,221 [INFO] loss: 0.0132    [5,    10]\n","2024-02-10 18:36:38,239 [INFO] loss: 0.0142    [5,    20]\n","2024-02-10 18:36:38,259 [INFO] loss: 0.0141    [6,    10]\n","2024-02-10 18:36:38,275 [INFO] loss: 0.0129    [6,    20]\n","2024-02-10 18:36:38,294 [INFO] loss: 0.0116    [7,    10]\n","2024-02-10 18:36:38,311 [INFO] loss: 0.0128    [7,    20]\n","2024-02-10 18:36:38,330 [INFO] loss: 0.0139    [8,    10]\n","2024-02-10 18:36:38,347 [INFO] loss: 0.0117    [8,    20]\n","2024-02-10 18:36:38,369 [INFO] loss: 0.0132    [9,    10]\n","2024-02-10 18:36:38,385 [INFO] loss: 0.0115    [9,    20]\n","2024-02-10 18:36:38,405 [INFO] loss: 0.0116    [10,    10]\n","2024-02-10 18:36:38,422 [INFO] loss: 0.0123    [10,    20]\n","2024-02-10 18:36:38,445 [INFO] loss: 0.0108    [11,    10]\n","2024-02-10 18:36:38,462 [INFO] loss: 0.0110    [11,    20]\n","2024-02-10 18:36:38,483 [INFO] loss: 0.0104    [12,    10]\n","2024-02-10 18:36:38,500 [INFO] loss: 0.0113    [12,    20]\n","2024-02-10 18:36:38,523 [INFO] loss: 0.0110    [13,    10]\n","2024-02-10 18:36:38,540 [INFO] loss: 0.0104    [13,    20]\n","2024-02-10 18:36:38,560 [INFO] loss: 0.0097    [14,    10]\n","2024-02-10 18:36:38,577 [INFO] loss: 0.0113    [14,    20]\n","2024-02-10 18:36:38,597 [INFO] loss: 0.0097    [15,    10]\n","2024-02-10 18:36:38,614 [INFO] loss: 0.0095    [15,    20]\n","2024-02-10 18:36:38,633 [INFO] loss: 0.0093    [16,    10]\n","2024-02-10 18:36:38,650 [INFO] loss: 0.0119    [16,    20]\n","2024-02-10 18:36:38,670 [INFO] loss: 0.0090    [17,    10]\n","2024-02-10 18:36:38,686 [INFO] loss: 0.0102    [17,    20]\n","2024-02-10 18:36:38,705 [INFO] loss: 0.0079    [18,    10]\n","2024-02-10 18:36:38,722 [INFO] loss: 0.0106    [18,    20]\n","2024-02-10 18:36:38,743 [INFO] loss: 0.0085    [19,    10]\n","2024-02-10 18:36:38,759 [INFO] loss: 0.0106    [19,    20]\n","2024-02-10 18:36:38,779 [INFO] loss: 0.0097    [20,    10]\n","2024-02-10 18:36:38,796 [INFO] loss: 0.0083    [20,    20]\n","2024-02-10 18:36:38,816 [INFO] loss: 0.0075    [21,    10]\n","2024-02-10 18:36:38,833 [INFO] loss: 0.0095    [21,    20]\n","2024-02-10 18:36:38,853 [INFO] loss: 0.0081    [22,    10]\n","2024-02-10 18:36:38,869 [INFO] loss: 0.0097    [22,    20]\n","2024-02-10 18:36:38,890 [INFO] loss: 0.0087    [23,    10]\n","2024-02-10 18:36:38,909 [INFO] loss: 0.0083    [23,    20]\n","2024-02-10 18:36:38,929 [INFO] loss: 0.0089    [24,    10]\n","2024-02-10 18:36:38,950 [INFO] loss: 0.0079    [24,    20]\n","2024-02-10 18:36:38,970 [INFO] loss: 0.0081    [25,    10]\n","2024-02-10 18:36:38,988 [INFO] loss: 0.0092    [25,    20]\n","2024-02-10 18:36:39,009 [INFO] loss: 0.0076    [26,    10]\n","2024-02-10 18:36:39,025 [INFO] loss: 0.0090    [26,    20]\n","2024-02-10 18:36:39,046 [INFO] loss: 0.0067    [27,    10]\n","2024-02-10 18:36:39,063 [INFO] loss: 0.0098    [27,    20]\n","2024-02-10 18:36:39,084 [INFO] loss: 0.0069    [28,    10]\n","2024-02-10 18:36:39,100 [INFO] loss: 0.0081    [28,    20]\n","2024-02-10 18:36:39,121 [INFO] loss: 0.0060    [29,    10]\n","2024-02-10 18:36:39,139 [INFO] loss: 0.0099    [29,    20]\n","2024-02-10 18:36:39,161 [INFO] loss: 0.0077    [30,    10]\n","2024-02-10 18:36:39,178 [INFO] loss: 0.0069    [30,    20]\n","2024-02-10 18:36:39,208 [INFO] loss: 0.0073    [31,    10]\n","2024-02-10 18:36:39,227 [INFO] loss: 0.0061    [31,    20]\n","2024-02-10 18:36:39,247 [INFO] loss: 0.0074    [32,    10]\n","2024-02-10 18:36:39,263 [INFO] loss: 0.0082    [32,    20]\n","2024-02-10 18:36:39,283 [INFO] loss: 0.0064    [33,    10]\n","2024-02-10 18:36:39,300 [INFO] loss: 0.0085    [33,    20]\n","2024-02-10 18:36:39,320 [INFO] loss: 0.0074    [34,    10]\n","2024-02-10 18:36:39,336 [INFO] loss: 0.0070    [34,    20]\n","2024-02-10 18:36:39,356 [INFO] loss: 0.0065    [35,    10]\n","2024-02-10 18:36:39,377 [INFO] loss: 0.0077    [35,    20]\n","2024-02-10 18:36:39,397 [INFO] loss: 0.0061    [36,    10]\n","2024-02-10 18:36:39,413 [INFO] loss: 0.0085    [36,    20]\n","2024-02-10 18:36:39,433 [INFO] loss: 0.0055    [37,    10]\n","2024-02-10 18:36:39,450 [INFO] loss: 0.0082    [37,    20]\n","2024-02-10 18:36:39,470 [INFO] loss: 0.0065    [38,    10]\n","2024-02-10 18:36:39,486 [INFO] loss: 0.0072    [38,    20]\n","2024-02-10 18:36:39,507 [INFO] loss: 0.0054    [39,    10]\n","2024-02-10 18:36:39,524 [INFO] loss: 0.0076    [39,    20]\n","2024-02-10 18:36:39,545 [INFO] loss: 0.0066    [40,    10]\n","2024-02-10 18:36:39,562 [INFO] loss: 0.0059    [40,    20]\n","2024-02-10 18:36:39,583 [INFO] loss: 0.0049    [41,    10]\n","2024-02-10 18:36:39,600 [INFO] loss: 0.0083    [41,    20]\n","2024-02-10 18:36:39,620 [INFO] loss: 0.0069    [42,    10]\n","2024-02-10 18:36:39,636 [INFO] loss: 0.0055    [42,    20]\n","2024-02-10 18:36:39,656 [INFO] loss: 0.0061    [43,    10]\n","2024-02-10 18:36:39,672 [INFO] loss: 0.0063    [43,    20]\n","2024-02-10 18:36:39,692 [INFO] loss: 0.0064    [44,    10]\n","2024-02-10 18:36:39,707 [INFO] loss: 0.0052    [44,    20]\n","2024-02-10 18:36:39,728 [INFO] loss: 0.0057    [45,    10]\n","2024-02-10 18:36:39,744 [INFO] loss: 0.0072    [45,    20]\n","2024-02-10 18:36:39,764 [INFO] loss: 0.0071    [46,    10]\n","2024-02-10 18:36:39,780 [INFO] loss: 0.0057    [46,    20]\n","2024-02-10 18:36:39,800 [INFO] loss: 0.0047    [47,    10]\n","2024-02-10 18:36:39,815 [INFO] loss: 0.0066    [47,    20]\n","2024-02-10 18:36:39,835 [INFO] loss: 0.0061    [48,    10]\n","2024-02-10 18:36:39,855 [INFO] loss: 0.0055    [48,    20]\n","2024-02-10 18:36:39,876 [INFO] loss: 0.0059    [49,    10]\n","2024-02-10 18:36:39,894 [INFO] loss: 0.0062    [49,    20]\n","2024-02-10 18:36:39,915 [INFO] loss: 0.0055    [50,    10]\n","2024-02-10 18:36:39,932 [INFO] loss: 0.0052    [50,    20]\n","2024-02-10 18:36:39,976 [INFO] Result on Train Data : {'AUC': 0.9900108325595791, 'ACC': 0.9457579972183588, 'F1 Score': 0.9457374241676584, 'AUPR': 0, 'Loss': 0.14304386646203374}\n","2024-02-10 18:36:39,979 [INFO] Call Testing with adam optimizer\n","2024-02-10 18:36:40,034 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 80]) and y shape : torch.Size([179, 1])\n","2024-02-10 18:36:40,036 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-10 18:36:40,038 [INFO] moving data and model to cpu\n","2024-02-10 18:36:40,060 [INFO] Result on Test Data : {'AUC': 0.8465043695380775, 'ACC': 0.7430167597765364, 'F1 Score': 0.7400883838383838, 'AUPR': 0, 'Loss': 1.1330179870128632}\n","2024-02-10 18:36:40,061 [INFO] Result of fold 4 : {'AUC': 0.8465043695380775, 'ACC': 0.7430167597765364, 'F1 Score': 0.7400883838383838, 'AUPR': 0, 'Loss': 1.1330179870128632}\n","2024-02-10 18:36:40,065 [INFO] ---- Fold 5 ----\n","2024-02-10 18:36:40,068 [INFO] Initializing MDFeatureBasedMDAClassifier with model : simple classifier\n","2024-02-10 18:36:40,070 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-10 18:36:40,072 [INFO] Initial SimpleMLP with 80 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-10 18:36:40,075 [INFO] Initializing MatrixFeatureExtractor\n","2024-02-10 18:36:40,077 [INFO] Initializing MFFeatureExtractor with model : None and decomposer : NMF\n","2024-02-10 18:36:40,078 [INFO] Call Training with adam optimizer\n","2024-02-10 18:36:40,083 [INFO] Calling build with associations :      disease  microbe  increased\n","1      43621    40832          1\n","2      33293    47880          1\n","3      13213    53186          1\n","4      33293    14909          1\n","5      33293    35937          1\n","..       ...      ...        ...\n","893    64642    53920          0\n","894    25026    60601          0\n","895    25026    44316          0\n","896    31069    60226          0\n","897    64642     4251          0\n","\n","[716 rows x 3 columns]\n","2024-02-10 18:36:40,148 [INFO] interaction matrix with shape (5179, 5645) has built\n","2024-02-10 18:36:40,445 [INFO] mask matrix with shape (5179, 5645) has built. This matrix shows not non elements.\n","2024-02-10 18:36:41,830 [INFO] interaction has been imputed to delete nans\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["2024-02-10 18:37:49,498 [INFO] Initializing SimplePytorchData with X shape : torch.Size([716, 80]) and y shape : torch.Size([716, 1])\n","2024-02-10 18:37:49,499 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-10 18:37:49,502 [INFO] moving data and model to cpu\n","2024-02-10 18:37:49,522 [INFO] loss: 0.0199    [1,    10]\n","2024-02-10 18:37:49,539 [INFO] loss: 0.0183    [1,    20]\n","2024-02-10 18:37:49,560 [INFO] loss: 0.0147    [2,    10]\n","2024-02-10 18:37:49,579 [INFO] loss: 0.0165    [2,    20]\n","2024-02-10 18:37:49,602 [INFO] loss: 0.0125    [3,    10]\n","2024-02-10 18:37:49,618 [INFO] loss: 0.0154    [3,    20]\n","2024-02-10 18:37:49,638 [INFO] loss: 0.0130    [4,    10]\n","2024-02-10 18:37:49,654 [INFO] loss: 0.0143    [4,    20]\n","2024-02-10 18:37:49,674 [INFO] loss: 0.0113    [5,    10]\n","2024-02-10 18:37:49,691 [INFO] loss: 0.0134    [5,    20]\n","2024-02-10 18:37:49,711 [INFO] loss: 0.0122    [6,    10]\n","2024-02-10 18:37:49,727 [INFO] loss: 0.0131    [6,    20]\n","2024-02-10 18:37:49,747 [INFO] loss: 0.0122    [7,    10]\n","2024-02-10 18:37:49,763 [INFO] loss: 0.0118    [7,    20]\n","2024-02-10 18:37:49,784 [INFO] loss: 0.0111    [8,    10]\n","2024-02-10 18:37:49,800 [INFO] loss: 0.0107    [8,    20]\n","2024-02-10 18:37:49,820 [INFO] loss: 0.0109    [9,    10]\n","2024-02-10 18:37:49,836 [INFO] loss: 0.0113    [9,    20]\n","2024-02-10 18:37:49,857 [INFO] loss: 0.0103    [10,    10]\n","2024-02-10 18:37:49,872 [INFO] loss: 0.0115    [10,    20]\n","2024-02-10 18:37:49,893 [INFO] loss: 0.0099    [11,    10]\n","2024-02-10 18:37:49,909 [INFO] loss: 0.0113    [11,    20]\n","2024-02-10 18:37:49,929 [INFO] loss: 0.0103    [12,    10]\n","2024-02-10 18:37:49,946 [INFO] loss: 0.0105    [12,    20]\n","2024-02-10 18:37:49,970 [INFO] loss: 0.0104    [13,    10]\n","2024-02-10 18:37:49,986 [INFO] loss: 0.0107    [13,    20]\n","2024-02-10 18:37:50,009 [INFO] loss: 0.0105    [14,    10]\n","2024-02-10 18:37:50,026 [INFO] loss: 0.0101    [14,    20]\n","2024-02-10 18:37:50,046 [INFO] loss: 0.0103    [15,    10]\n","2024-02-10 18:37:50,062 [INFO] loss: 0.0083    [15,    20]\n","2024-02-10 18:37:50,083 [INFO] loss: 0.0101    [16,    10]\n","2024-02-10 18:37:50,100 [INFO] loss: 0.0093    [16,    20]\n","2024-02-10 18:37:50,125 [INFO] loss: 0.0087    [17,    10]\n","2024-02-10 18:37:50,146 [INFO] loss: 0.0100    [17,    20]\n","2024-02-10 18:37:50,169 [INFO] loss: 0.0082    [18,    10]\n","2024-02-10 18:37:50,187 [INFO] loss: 0.0101    [18,    20]\n","2024-02-10 18:37:50,208 [INFO] loss: 0.0086    [19,    10]\n","2024-02-10 18:37:50,225 [INFO] loss: 0.0102    [19,    20]\n","2024-02-10 18:37:50,245 [INFO] loss: 0.0087    [20,    10]\n","2024-02-10 18:37:50,262 [INFO] loss: 0.0094    [20,    20]\n","2024-02-10 18:37:50,282 [INFO] loss: 0.0082    [21,    10]\n","2024-02-10 18:37:50,299 [INFO] loss: 0.0098    [21,    20]\n","2024-02-10 18:37:50,319 [INFO] loss: 0.0102    [22,    10]\n","2024-02-10 18:37:50,336 [INFO] loss: 0.0084    [22,    20]\n","2024-02-10 18:37:50,357 [INFO] loss: 0.0091    [23,    10]\n","2024-02-10 18:37:50,374 [INFO] loss: 0.0085    [23,    20]\n","2024-02-10 18:37:50,395 [INFO] loss: 0.0090    [24,    10]\n","2024-02-10 18:37:50,412 [INFO] loss: 0.0074    [24,    20]\n","2024-02-10 18:37:50,432 [INFO] loss: 0.0070    [25,    10]\n","2024-02-10 18:37:50,449 [INFO] loss: 0.0104    [25,    20]\n","2024-02-10 18:37:50,470 [INFO] loss: 0.0086    [26,    10]\n","2024-02-10 18:37:50,488 [INFO] loss: 0.0086    [26,    20]\n","2024-02-10 18:37:50,511 [INFO] loss: 0.0080    [27,    10]\n","2024-02-10 18:37:50,528 [INFO] loss: 0.0101    [27,    20]\n","2024-02-10 18:37:50,548 [INFO] loss: 0.0076    [28,    10]\n","2024-02-10 18:37:50,568 [INFO] loss: 0.0078    [28,    20]\n","2024-02-10 18:37:50,591 [INFO] loss: 0.0073    [29,    10]\n","2024-02-10 18:37:50,607 [INFO] loss: 0.0086    [29,    20]\n","2024-02-10 18:37:50,629 [INFO] loss: 0.0077    [30,    10]\n","2024-02-10 18:37:50,647 [INFO] loss: 0.0086    [30,    20]\n","2024-02-10 18:37:50,668 [INFO] loss: 0.0071    [31,    10]\n","2024-02-10 18:37:50,685 [INFO] loss: 0.0072    [31,    20]\n","2024-02-10 18:37:50,706 [INFO] loss: 0.0072    [32,    10]\n","2024-02-10 18:37:50,723 [INFO] loss: 0.0081    [32,    20]\n","2024-02-10 18:37:50,745 [INFO] loss: 0.0072    [33,    10]\n","2024-02-10 18:37:50,762 [INFO] loss: 0.0068    [33,    20]\n","2024-02-10 18:37:50,783 [INFO] loss: 0.0067    [34,    10]\n","2024-02-10 18:37:50,801 [INFO] loss: 0.0071    [34,    20]\n","2024-02-10 18:37:50,821 [INFO] loss: 0.0072    [35,    10]\n","2024-02-10 18:37:50,838 [INFO] loss: 0.0057    [35,    20]\n","2024-02-10 18:37:50,858 [INFO] loss: 0.0067    [36,    10]\n","2024-02-10 18:37:50,879 [INFO] loss: 0.0071    [36,    20]\n","2024-02-10 18:37:50,900 [INFO] loss: 0.0060    [37,    10]\n","2024-02-10 18:37:50,920 [INFO] loss: 0.0073    [37,    20]\n","2024-02-10 18:37:50,941 [INFO] loss: 0.0057    [38,    10]\n","2024-02-10 18:37:50,958 [INFO] loss: 0.0069    [38,    20]\n","2024-02-10 18:37:50,979 [INFO] loss: 0.0061    [39,    10]\n","2024-02-10 18:37:50,996 [INFO] loss: 0.0098    [39,    20]\n","2024-02-10 18:37:51,016 [INFO] loss: 0.0077    [40,    10]\n","2024-02-10 18:37:51,033 [INFO] loss: 0.0054    [40,    20]\n","2024-02-10 18:37:51,053 [INFO] loss: 0.0067    [41,    10]\n","2024-02-10 18:37:51,070 [INFO] loss: 0.0057    [41,    20]\n","2024-02-10 18:37:51,091 [INFO] loss: 0.0053    [42,    10]\n","2024-02-10 18:37:51,109 [INFO] loss: 0.0061    [42,    20]\n","2024-02-10 18:37:51,130 [INFO] loss: 0.0069    [43,    10]\n","2024-02-10 18:37:51,149 [INFO] loss: 0.0072    [43,    20]\n","2024-02-10 18:37:51,178 [INFO] loss: 0.0068    [44,    10]\n","2024-02-10 18:37:51,195 [INFO] loss: 0.0071    [44,    20]\n","2024-02-10 18:37:51,216 [INFO] loss: 0.0070    [45,    10]\n","2024-02-10 18:37:51,232 [INFO] loss: 0.0062    [45,    20]\n","2024-02-10 18:37:51,253 [INFO] loss: 0.0056    [46,    10]\n","2024-02-10 18:37:51,269 [INFO] loss: 0.0066    [46,    20]\n","2024-02-10 18:37:51,290 [INFO] loss: 0.0059    [47,    10]\n","2024-02-10 18:37:51,307 [INFO] loss: 0.0069    [47,    20]\n","2024-02-10 18:37:51,329 [INFO] loss: 0.0069    [48,    10]\n","2024-02-10 18:37:51,347 [INFO] loss: 0.0058    [48,    20]\n","2024-02-10 18:37:51,368 [INFO] loss: 0.0066    [49,    10]\n","2024-02-10 18:37:51,385 [INFO] loss: 0.0059    [49,    20]\n","2024-02-10 18:37:51,405 [INFO] loss: 0.0047    [50,    10]\n","2024-02-10 18:37:51,422 [INFO] loss: 0.0057    [50,    20]\n","2024-02-10 18:37:51,468 [INFO] Result on Train Data : {'AUC': 0.9891576606453123, 'ACC': 0.9329608938547486, 'F1 Score': 0.9329352534831987, 'AUPR': 0, 'Loss': 0.14215290578811066}\n","2024-02-10 18:37:51,469 [INFO] Call Testing with adam optimizer\n","2024-02-10 18:37:51,531 [INFO] Initializing SimplePytorchData with X shape : torch.Size([182, 80]) and y shape : torch.Size([182, 1])\n","2024-02-10 18:37:51,532 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-10 18:37:51,534 [INFO] moving data and model to cpu\n","2024-02-10 18:37:51,557 [INFO] Result on Test Data : {'AUC': 0.8219898452611218, 'ACC': 0.7362637362637363, 'F1 Score': 0.7361362812613266, 'AUPR': 0, 'Loss': 1.1364699602127075}\n","2024-02-10 18:37:51,560 [INFO] Result of fold 5 : {'AUC': 0.8219898452611218, 'ACC': 0.7362637362637363, 'F1 Score': 0.7361362812613266, 'AUPR': 0, 'Loss': 1.1364699602127075}\n","2024-02-10 18:37:51,564 [INFO] 5-fold result: avg_auc: 0.8187488934156054, avg_acc: 0.7349622444594511, avg_f1: 0.7323163680548603, avg_aupr: 0.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<base.evaluation.Result at 0x7f15c51daf50>"]},"metadata":{},"execution_count":18}],"source":["trainer = MatrixFeatureBasedMDAClassifierTrainer()\n","tester = MatrixFeatureBasedMDAClassifierTester()\n","factory = MDFeatureBasedMDAClassifierFactory(simple_classifier_config, md_config)\n","spliter = MicrobeDiseaseAssociationTrainTestSpliter(data.associations)\n","cross_validation(k=5, data_size=data.associations.shape[0], train_test_spliter=spliter, model_factory=factory,\n","                    trainer=trainer, tester=tester, config=classifier_optimizer_config)"]},{"cell_type":"code","source":[],"metadata":{"id":"5cpQ0kPkjuHb","executionInfo":{"status":"ok","timestamp":1707590271989,"user_tz":-210,"elapsed":19,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":18,"outputs":[]}]}