{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbSkLzXRVkG1","executionInfo":{"status":"ok","timestamp":1707730947119,"user_tz":-210,"elapsed":2990,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"02ea6741-5ca3-4066-ecd0-8b3405257513"},"id":"AbSkLzXRVkG1","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":22,"id":"initial_id","metadata":{"collapsed":true,"id":"initial_id","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707730947119,"user_tz":-210,"elapsed":3,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"344dbc9c-6e81-4501-906a-8a6ca9408b8a"},"outputs":[{"output_type":"stream","name":"stdout","text":["base  data_repository  notebooks  requirements.txt  src\n"]}],"source":["!ls"]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Academic/Topics/AI/Machine\\ Learning\\ Dr.\\ Montazeri/Project/ml_mda"],"metadata":{"id":"uDVTuQuDVXDp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707730947119,"user_tz":-210,"elapsed":2,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"323c99dd-c639-40d3-d016-dc77c2037a9b"},"id":"uDVTuQuDVXDp","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Academic/Topics/AI/Machine Learning Dr. Montazeri/Project/ml_mda\n"]}]},{"cell_type":"code","source":["!pip install torch_geometric"],"metadata":{"id":"RDY-Ibk-EuwN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707730953202,"user_tz":-210,"elapsed":6084,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"89e89424-2346-492e-e134-326aa80d17fb"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"]}],"id":"RDY-Ibk-EuwN"},{"cell_type":"code","source":["!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html"],"metadata":{"id":"8Vot3XZDEzNX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707730958420,"user_tz":-210,"elapsed":5223,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"6114e724-b2b5-4b9b-88cb-92f27abe8a1d"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\n","Requirement already satisfied: pyg_lib in /usr/local/lib/python3.10/dist-packages (0.4.0+pt21cu121)\n","Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt21cu121)\n","Requirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt21cu121)\n","Requirement already satisfied: torch_cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt21cu121)\n","Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt21cu121)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n"]}],"id":"8Vot3XZDEzNX"},{"cell_type":"markdown","source":["# Requirements"],"metadata":{"id":"CP5slJxnWMG-"},"id":"CP5slJxnWMG-"},{"cell_type":"code","source":["import torch\n","\n","from torch.optim import Adam\n","from torch_geometric.nn import ComplEx, DistMult, RotatE, TransE\n","from torch_geometric.data import Data\n","\n","from base import OptimizerConfig, cross_validation\n","from base import SimplePytorchData, SimplePytorchDataTrainTestSplit\n","from base import SimpleTrainer, SimpleTester\n","from src.config import SimpleClassifierConfig, GraphAutoEncoderConfig, KGEConfig\n","from src.features import get_relations, get_entities, get_associations, get_homogeneous_graph, get_kge_pair_embedd_for_training_data\n","from src.models import SimpleMDAClassifier, SimpleMDAClassifierFactory\n","from src.utils import train_test_sampler, prj_logger\n","from torch_geometric.nn import GCNConv"],"metadata":{"id":"1Tz_6Gnq191K","executionInfo":{"status":"ok","timestamp":1707730958421,"user_tz":-210,"elapsed":8,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"1Tz_6Gnq191K","execution_count":26,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"5V-nDmj61M_3","executionInfo":{"status":"ok","timestamp":1707730958421,"user_tz":-210,"elapsed":7,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"5V-nDmj61M_3","execution_count":27,"outputs":[]},{"cell_type":"code","source":["import logging\n","import sys\n","\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n","    handlers=[\n","        logging.StreamHandler(stream=sys.stdout)\n","    ],\n","    force=True\n",")"],"metadata":{"id":"v4fhFqHr-UQI","executionInfo":{"status":"ok","timestamp":1707730958421,"user_tz":-210,"elapsed":7,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"v4fhFqHr-UQI","execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["# DistMult"],"metadata":{"id":"jQ9m4sXXMrP_"},"id":"jQ9m4sXXMrP_"},{"cell_type":"markdown","source":["## Config"],"metadata":{"id":"mze45lXFT9mw"},"id":"mze45lXFT9mw"},{"cell_type":"code","source":["kge_optimizer_config = OptimizerConfig()\n","kge_optimizer_config.optimizer = torch.optim.Adam\n","kge_optimizer_config.lr = 0.01\n","kge_optimizer_config.batch_size = 1000\n","kge_optimizer_config.n_epoch = 40\n","kge_optimizer_config.exp_name = \"Optimizer for Graph Auto Encoder\"\n","kge_optimizer_config.device = device\n","kge_optimizer_config.report_size = device"],"metadata":{"id":"r4zjaDCMMsJC","executionInfo":{"status":"ok","timestamp":1707730958421,"user_tz":-210,"elapsed":7,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"r4zjaDCMMsJC","execution_count":29,"outputs":[]},{"cell_type":"code","source":["kge_model_config = KGEConfig()\n","kge_model_config.kge = DistMult\n","kge_model_config.hidden_channels = 32"],"metadata":{"id":"KEPyGw8LNBFv","executionInfo":{"status":"ok","timestamp":1707730958421,"user_tz":-210,"elapsed":7,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"KEPyGw8LNBFv","execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["## Embedding"],"metadata":{"id":"LKtvRPGwT_NG"},"id":"LKtvRPGwT_NG"},{"cell_type":"code","source":["md_embed = get_kge_pair_embedd_for_training_data(kge_model_config, kge_optimizer_config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2Qz4EGMOrrk","executionInfo":{"status":"ok","timestamp":1707731047955,"user_tz":-210,"elapsed":89541,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"373b9ee8-4bf8-4e69-c467-20b48c557668"},"id":"r2Qz4EGMOrrk","execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-12 09:42:38,284 [INFO] Calling get_node2vec_pair_embedd on cuda device ...\n","2024-02-12 09:42:38,288 [INFO] Calling get_homogeneous_graph\n","2024-02-12 09:42:39,588 [INFO] homogeneous data : Data(x=[66911, 1], edge_index=[2, 633662])\n","2024-02-12 09:42:39,593 [INFO] Calling get_kge_embedd on cuda device ...\n","2024-02-12 09:42:39,594 [INFO] Calling get_knowledge_graph\n","2024-02-12 09:42:40,518 [INFO] knowledge graph data : Data(num_nodes=66911, edge_index=[2, 633662], edge_type=[633662])\n","2024-02-12 09:42:40,519 [INFO] Setting num relations and num nodes for kge config to 39 and 66911\n","2024-02-12 09:42:40,522 [INFO] Creating KGE model ...\n","2024-02-12 09:42:40,525 [INFO] Initialing MDATransE with model_config {'model_name': None}\n","2024-02-12 09:42:40,559 [INFO] Training KGE ...\n","2024-02-12 09:42:40,559 [INFO] Running KGETrainer with Optimizer for Graph Auto Encoder\n","2024-02-12 09:42:40,562 [INFO] Creating <class 'torch.optim.adam.Adam'> with lr : 0.01\n","2024-02-12 09:42:40,565 [INFO] moving model to cuda\n","2024-02-12 09:42:42,972 [INFO] Epoch: 001, Loss: 0.2845\n","2024-02-12 09:42:45,982 [INFO] Epoch: 002, Loss: 0.0675\n","2024-02-12 09:42:49,683 [INFO] Epoch: 003, Loss: 0.0590\n","2024-02-12 09:42:51,963 [INFO] Epoch: 004, Loss: 0.0529\n","2024-02-12 09:42:53,937 [INFO] Epoch: 005, Loss: 0.0483\n","2024-02-12 09:42:56,232 [INFO] Epoch: 006, Loss: 0.0461\n","2024-02-12 09:42:58,476 [INFO] Epoch: 007, Loss: 0.0434\n","2024-02-12 09:43:00,460 [INFO] Epoch: 008, Loss: 0.0407\n","2024-02-12 09:43:02,454 [INFO] Epoch: 009, Loss: 0.0399\n","2024-02-12 09:43:04,433 [INFO] Epoch: 010, Loss: 0.0390\n","2024-02-12 09:43:06,422 [INFO] Epoch: 011, Loss: 0.0379\n","2024-02-12 09:43:08,685 [INFO] Epoch: 012, Loss: 0.0367\n","2024-02-12 09:43:10,964 [INFO] Epoch: 013, Loss: 0.0359\n","2024-02-12 09:43:12,957 [INFO] Epoch: 014, Loss: 0.0347\n","2024-02-12 09:43:14,943 [INFO] Epoch: 015, Loss: 0.0346\n","2024-02-12 09:43:16,924 [INFO] Epoch: 016, Loss: 0.0337\n","2024-02-12 09:43:18,923 [INFO] Epoch: 017, Loss: 0.0335\n","2024-02-12 09:43:21,135 [INFO] Epoch: 018, Loss: 0.0326\n","2024-02-12 09:43:23,464 [INFO] Epoch: 019, Loss: 0.0322\n","2024-02-12 09:43:25,445 [INFO] Epoch: 020, Loss: 0.0319\n","2024-02-12 09:43:27,430 [INFO] Epoch: 021, Loss: 0.0315\n","2024-02-12 09:43:29,421 [INFO] Epoch: 022, Loss: 0.0309\n","2024-02-12 09:43:31,414 [INFO] Epoch: 023, Loss: 0.0308\n","2024-02-12 09:43:33,591 [INFO] Epoch: 024, Loss: 0.0312\n","2024-02-12 09:43:35,994 [INFO] Epoch: 025, Loss: 0.0300\n","2024-02-12 09:43:37,977 [INFO] Epoch: 026, Loss: 0.0302\n","2024-02-12 09:43:39,985 [INFO] Epoch: 027, Loss: 0.0292\n","2024-02-12 09:43:42,021 [INFO] Epoch: 028, Loss: 0.0302\n","2024-02-12 09:43:44,045 [INFO] Epoch: 029, Loss: 0.0297\n","2024-02-12 09:43:46,212 [INFO] Epoch: 030, Loss: 0.0295\n","2024-02-12 09:43:49,176 [INFO] Epoch: 031, Loss: 0.0294\n","2024-02-12 09:43:51,159 [INFO] Epoch: 032, Loss: 0.0293\n","2024-02-12 09:43:53,144 [INFO] Epoch: 033, Loss: 0.0285\n","2024-02-12 09:43:55,167 [INFO] Epoch: 034, Loss: 0.0285\n","2024-02-12 09:43:57,155 [INFO] Epoch: 035, Loss: 0.0284\n","2024-02-12 09:43:59,464 [INFO] Epoch: 036, Loss: 0.0285\n","2024-02-12 09:44:01,762 [INFO] Epoch: 037, Loss: 0.0279\n","2024-02-12 09:44:03,741 [INFO] Epoch: 038, Loss: 0.0285\n","2024-02-12 09:44:05,746 [INFO] Epoch: 039, Loss: 0.0272\n","2024-02-12 09:44:07,735 [INFO] Epoch: 040, Loss: 0.0280\n","2024-02-12 09:44:07,737 [INFO] Result on Train Data : {'AUC': 0, 'ACC': 0, 'F1 Score': 0, 'AUPR': 0, 'Loss': 0.028040377674505658}\n","2024-02-12 09:44:07,741 [INFO] loss of KGE model : 0.028040377674505658\n","2024-02-12 09:44:07,754 [INFO] node embedding shape : torch.Size([66911, 32])\n","2024-02-12 09:44:07,757 [INFO] disease embedding shape : torch.Size([898, 32])\n","2024-02-12 09:44:07,758 [INFO] microbe embedding shape : torch.Size([898, 32])\n","2024-02-12 09:44:07,761 [INFO] microbe disease combination embedding shape : torch.Size([898, 64])\n"]}]},{"cell_type":"markdown","source":["# Classification"],"metadata":{"id":"T_hIMihJMts8"},"id":"T_hIMihJMts8"},{"cell_type":"markdown","source":["## Data"],"metadata":{"id":"ocxVXIz1MqLJ"},"id":"ocxVXIz1MqLJ"},{"cell_type":"code","source":["associations = get_associations()\n","y = torch.tensor(associations['increased'].tolist(), dtype=torch.float32).reshape(-1, 1).to(device)"],"metadata":{"id":"jEfB8KA7gPx2","executionInfo":{"status":"ok","timestamp":1707731047955,"user_tz":-210,"elapsed":10,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":32,"outputs":[],"id":"jEfB8KA7gPx2"},{"cell_type":"code","source":["# Train Test Split\n","train_indices, test_indices = train_test_sampler(y.shape[0], 0.7)\n","\n","data = SimplePytorchData(md_embed, y)\n","train_data = SimplePytorchData(md_embed[train_indices], y[train_indices])\n","test_data = SimplePytorchData(md_embed[test_indices], y[test_indices])"],"metadata":{"id":"DNdQlgzMMtHN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707731047955,"user_tz":-210,"elapsed":8,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"8bac3d1c-bad1-4173-bd5d-b2d58ab11f4e"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-12 09:44:07,787 [INFO] Initializing SimplePytorchData with X shape : torch.Size([898, 64]) and y shape : torch.Size([898, 1])\n","2024-02-12 09:44:07,790 [INFO] Initializing SimplePytorchData with X shape : torch.Size([628, 64]) and y shape : torch.Size([628, 1])\n","2024-02-12 09:44:07,793 [INFO] Initializing SimplePytorchData with X shape : torch.Size([270, 64]) and y shape : torch.Size([270, 1])\n"]}],"id":"DNdQlgzMMtHN"},{"cell_type":"markdown","source":["## Classifier"],"metadata":{"id":"ye_6wl6nxmhs"},"id":"ye_6wl6nxmhs"},{"cell_type":"code","source":["simple_classifier_config = SimpleClassifierConfig()\n","simple_classifier_config.model_name = \"simple classifier\"\n","simple_classifier_config.input_dim = md_embed.shape[1]\n","simple_classifier_config.hidden_dim = 32\n","simple_classifier_config.output_dim = 1\n","simple_classifier_config.num_layers = 2\n","simple_classifier_config.dropout = 0.1"],"metadata":{"id":"BFTQsCl8M9bv","executionInfo":{"status":"ok","timestamp":1707731047955,"user_tz":-210,"elapsed":6,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":34,"outputs":[],"id":"BFTQsCl8M9bv"},{"cell_type":"code","source":["mda_classifier = SimpleMDAClassifier(simple_classifier_config)"],"metadata":{"id":"1ciyBQ4QM_0U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707731047955,"user_tz":-210,"elapsed":6,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"67bbc8b6-5d72-417c-f2c5-9e8404880063"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-12 09:44:07,805 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-12 09:44:07,808 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n"]}],"id":"1ciyBQ4QM_0U"},{"cell_type":"markdown","source":["## Optimizer"],"metadata":{"id":"s_5cdKvOx4q5"},"id":"s_5cdKvOx4q5"},{"cell_type":"code","source":["classifier_optimizer_config = OptimizerConfig()\n","classifier_optimizer_config.optimizer = torch.optim.Adam\n","classifier_optimizer_config.criterion = torch.nn.BCEWithLogitsLoss()\n","classifier_optimizer_config.lr = 0.01\n","classifier_optimizer_config.batch_size = 32\n","classifier_optimizer_config.n_epoch = 50\n","classifier_optimizer_config.exp_name = \"adam optimizer\"\n","classifier_optimizer_config.save = False\n","classifier_optimizer_config.save_path = None\n","classifier_optimizer_config.device = device\n","classifier_optimizer_config.report_size = 10  # batch to report ratio\n","classifier_optimizer_config.threshold = 0.5"],"metadata":{"id":"3D6yhiPpNEc8","executionInfo":{"status":"ok","timestamp":1707731047955,"user_tz":-210,"elapsed":5,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":36,"outputs":[],"id":"3D6yhiPpNEc8"},{"cell_type":"markdown","source":["## Train Test Approach"],"metadata":{"id":"4iI5bMmJNQV3"},"id":"4iI5bMmJNQV3"},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"h24KnmDZNAgD"},"id":"h24KnmDZNAgD"},{"cell_type":"code","source":["train_result = SimpleTrainer().train(model=mda_classifier,\n","                                     data=train_data,\n","                                     config=classifier_optimizer_config)"],"metadata":{"id":"OqKrF7HmNFx1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707731050383,"user_tz":-210,"elapsed":2433,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"fe1b56b1-25fd-4d22-92c6-950e56160f85"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-12 09:44:07,822 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-12 09:44:07,824 [INFO] moving data and model to cuda\n","2024-02-12 09:44:07,848 [INFO] loss: 0.0202    [1,    10]\n","2024-02-12 09:44:07,867 [INFO] loss: 0.0184    [1,    20]\n","2024-02-12 09:44:07,885 [INFO] loss: 0.0141    [2,    10]\n","2024-02-12 09:44:07,902 [INFO] loss: 0.0147    [2,    20]\n","2024-02-12 09:44:07,923 [INFO] loss: 0.0121    [3,    10]\n","2024-02-12 09:44:07,942 [INFO] loss: 0.0118    [3,    20]\n","2024-02-12 09:44:07,960 [INFO] loss: 0.0109    [4,    10]\n","2024-02-12 09:44:07,978 [INFO] loss: 0.0116    [4,    20]\n","2024-02-12 09:44:07,996 [INFO] loss: 0.0096    [5,    10]\n","2024-02-12 09:44:08,015 [INFO] loss: 0.0105    [5,    20]\n","2024-02-12 09:44:08,033 [INFO] loss: 0.0095    [6,    10]\n","2024-02-12 09:44:08,051 [INFO] loss: 0.0093    [6,    20]\n","2024-02-12 09:44:08,070 [INFO] loss: 0.0088    [7,    10]\n","2024-02-12 09:44:08,088 [INFO] loss: 0.0085    [7,    20]\n","2024-02-12 09:44:08,106 [INFO] loss: 0.0080    [8,    10]\n","2024-02-12 09:44:08,124 [INFO] loss: 0.0075    [8,    20]\n","2024-02-12 09:44:08,142 [INFO] loss: 0.0071    [9,    10]\n","2024-02-12 09:44:08,160 [INFO] loss: 0.0075    [9,    20]\n","2024-02-12 09:44:08,179 [INFO] loss: 0.0054    [10,    10]\n","2024-02-12 09:44:08,196 [INFO] loss: 0.0079    [10,    20]\n","2024-02-12 09:44:08,215 [INFO] loss: 0.0068    [11,    10]\n","2024-02-12 09:44:08,232 [INFO] loss: 0.0057    [11,    20]\n","2024-02-12 09:44:08,251 [INFO] loss: 0.0059    [12,    10]\n","2024-02-12 09:44:08,269 [INFO] loss: 0.0052    [12,    20]\n","2024-02-12 09:44:08,287 [INFO] loss: 0.0044    [13,    10]\n","2024-02-12 09:44:08,306 [INFO] loss: 0.0057    [13,    20]\n","2024-02-12 09:44:08,330 [INFO] loss: 0.0039    [14,    10]\n","2024-02-12 09:44:08,351 [INFO] loss: 0.0054    [14,    20]\n","2024-02-12 09:44:08,372 [INFO] loss: 0.0039    [15,    10]\n","2024-02-12 09:44:08,391 [INFO] loss: 0.0046    [15,    20]\n","2024-02-12 09:44:08,409 [INFO] loss: 0.0034    [16,    10]\n","2024-02-12 09:44:08,428 [INFO] loss: 0.0041    [16,    20]\n","2024-02-12 09:44:08,446 [INFO] loss: 0.0028    [17,    10]\n","2024-02-12 09:44:08,465 [INFO] loss: 0.0048    [17,    20]\n","2024-02-12 09:44:08,485 [INFO] loss: 0.0042    [18,    10]\n","2024-02-12 09:44:08,503 [INFO] loss: 0.0042    [18,    20]\n","2024-02-12 09:44:08,522 [INFO] loss: 0.0032    [19,    10]\n","2024-02-12 09:44:08,540 [INFO] loss: 0.0038    [19,    20]\n","2024-02-12 09:44:08,561 [INFO] loss: 0.0029    [20,    10]\n","2024-02-12 09:44:08,580 [INFO] loss: 0.0037    [20,    20]\n","2024-02-12 09:44:08,598 [INFO] loss: 0.0031    [21,    10]\n","2024-02-12 09:44:08,617 [INFO] loss: 0.0034    [21,    20]\n","2024-02-12 09:44:08,636 [INFO] loss: 0.0024    [22,    10]\n","2024-02-12 09:44:08,656 [INFO] loss: 0.0033    [22,    20]\n","2024-02-12 09:44:08,675 [INFO] loss: 0.0028    [23,    10]\n","2024-02-12 09:44:08,693 [INFO] loss: 0.0025    [23,    20]\n","2024-02-12 09:44:08,714 [INFO] loss: 0.0025    [24,    10]\n","2024-02-12 09:44:08,732 [INFO] loss: 0.0031    [24,    20]\n","2024-02-12 09:44:08,751 [INFO] loss: 0.0021    [25,    10]\n","2024-02-12 09:44:08,770 [INFO] loss: 0.0022    [25,    20]\n","2024-02-12 09:44:08,789 [INFO] loss: 0.0026    [26,    10]\n","2024-02-12 09:44:08,807 [INFO] loss: 0.0029    [26,    20]\n","2024-02-12 09:44:08,830 [INFO] loss: 0.0023    [27,    10]\n","2024-02-12 09:44:08,869 [INFO] loss: 0.0029    [27,    20]\n","2024-02-12 09:44:08,895 [INFO] loss: 0.0016    [28,    10]\n","2024-02-12 09:44:08,923 [INFO] loss: 0.0025    [28,    20]\n","2024-02-12 09:44:08,950 [INFO] loss: 0.0021    [29,    10]\n","2024-02-12 09:44:08,975 [INFO] loss: 0.0014    [29,    20]\n","2024-02-12 09:44:08,998 [INFO] loss: 0.0017    [30,    10]\n","2024-02-12 09:44:09,022 [INFO] loss: 0.0026    [30,    20]\n","2024-02-12 09:44:09,047 [INFO] loss: 0.0018    [31,    10]\n","2024-02-12 09:44:09,071 [INFO] loss: 0.0015    [31,    20]\n","2024-02-12 09:44:09,094 [INFO] loss: 0.0013    [32,    10]\n","2024-02-12 09:44:09,118 [INFO] loss: 0.0013    [32,    20]\n","2024-02-12 09:44:09,142 [INFO] loss: 0.0014    [33,    10]\n","2024-02-12 09:44:09,166 [INFO] loss: 0.0015    [33,    20]\n","2024-02-12 09:44:09,188 [INFO] loss: 0.0019    [34,    10]\n","2024-02-12 09:44:09,206 [INFO] loss: 0.0011    [34,    20]\n","2024-02-12 09:44:09,224 [INFO] loss: 0.0010    [35,    10]\n","2024-02-12 09:44:09,245 [INFO] loss: 0.0015    [35,    20]\n","2024-02-12 09:44:09,263 [INFO] loss: 0.0012    [36,    10]\n","2024-02-12 09:44:09,281 [INFO] loss: 0.0016    [36,    20]\n","2024-02-12 09:44:09,301 [INFO] loss: 0.0015    [37,    10]\n","2024-02-12 09:44:09,319 [INFO] loss: 0.0015    [37,    20]\n","2024-02-12 09:44:09,341 [INFO] loss: 0.0016    [38,    10]\n","2024-02-12 09:44:09,363 [INFO] loss: 0.0020    [38,    20]\n","2024-02-12 09:44:09,383 [INFO] loss: 0.0012    [39,    10]\n","2024-02-12 09:44:09,401 [INFO] loss: 0.0012    [39,    20]\n","2024-02-12 09:44:09,422 [INFO] loss: 0.0010    [40,    10]\n","2024-02-12 09:44:09,440 [INFO] loss: 0.0015    [40,    20]\n","2024-02-12 09:44:09,461 [INFO] loss: 0.0019    [41,    10]\n","2024-02-12 09:44:09,479 [INFO] loss: 0.0022    [41,    20]\n","2024-02-12 09:44:09,498 [INFO] loss: 0.0014    [42,    10]\n","2024-02-12 09:44:09,516 [INFO] loss: 0.0017    [42,    20]\n","2024-02-12 09:44:09,535 [INFO] loss: 0.0022    [43,    10]\n","2024-02-12 09:44:09,554 [INFO] loss: 0.0018    [43,    20]\n","2024-02-12 09:44:09,573 [INFO] loss: 0.0018    [44,    10]\n","2024-02-12 09:44:09,591 [INFO] loss: 0.0011    [44,    20]\n","2024-02-12 09:44:09,610 [INFO] loss: 0.0014    [45,    10]\n","2024-02-12 09:44:09,628 [INFO] loss: 0.0025    [45,    20]\n","2024-02-12 09:44:09,650 [INFO] loss: 0.0015    [46,    10]\n","2024-02-12 09:44:09,673 [INFO] loss: 0.0017    [46,    20]\n","2024-02-12 09:44:09,692 [INFO] loss: 0.0007    [47,    10]\n","2024-02-12 09:44:09,712 [INFO] loss: 0.0011    [47,    20]\n","2024-02-12 09:44:09,730 [INFO] loss: 0.0007    [48,    10]\n","2024-02-12 09:44:09,749 [INFO] loss: 0.0014    [48,    20]\n","2024-02-12 09:44:09,767 [INFO] loss: 0.0012    [49,    10]\n","2024-02-12 09:44:09,785 [INFO] loss: 0.0012    [49,    20]\n","2024-02-12 09:44:09,804 [INFO] loss: 0.0009    [50,    10]\n","2024-02-12 09:44:09,822 [INFO] loss: 0.0007    [50,    20]\n","2024-02-12 09:44:09,862 [INFO] Result on Train Data : {'AUC': 1.0, 'ACC': 0.9984076433121019, 'F1 Score': 0.9984076069730586, 'AUPR': 0, 'Loss': 0.011866462149191648}\n"]}],"id":"OqKrF7HmNFx1"},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"0eQGNWm_NMVG"},"id":"0eQGNWm_NMVG"},{"cell_type":"code","source":["test_result = SimpleTester().test(model=mda_classifier,\n","                                  data=test_data,\n","                                  config=classifier_optimizer_config)"],"metadata":{"id":"U05mXL_fNHpG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707731050383,"user_tz":-210,"elapsed":13,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"3af784f4-92b3-4ca2-dae4-91d552556671"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-12 09:44:09,869 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-12 09:44:09,872 [INFO] moving data and model to cuda\n","2024-02-12 09:44:09,896 [INFO] Result on Test Data : {'AUC': 0.9607385864793678, 'ACC': 0.9407407407407408, 'F1 Score': 0.9407407407407408, 'AUPR': 0, 'Loss': 0.4104647928227981}\n"]}],"id":"U05mXL_fNHpG"},{"cell_type":"code","source":["test_result.get_result()"],"metadata":{"id":"oqgiZQqRWWGF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707731050383,"user_tz":-210,"elapsed":9,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"bbad40f1-b043-4530-a484-3344b5d49c29"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'AUC': 0.9607385864793678,\n"," 'ACC': 0.9407407407407408,\n"," 'F1 Score': 0.9407407407407408,\n"," 'AUPR': 0,\n"," 'Loss': 0.4104647928227981}"]},"metadata":{},"execution_count":39}],"id":"oqgiZQqRWWGF"},{"cell_type":"markdown","source":["## Cross Validation"],"metadata":{"id":"ti8vEX_cNNwy"},"id":"ti8vEX_cNNwy"},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707731065352,"user_tz":-210,"elapsed":14977,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"f6be2e09-3589-4571-bb5a-af5b4e444cdc","id":"sfI286uv6o-e"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-12 09:44:09,913 [INFO] Initializing SimpleMDAClassifierFactory with model : simple classifier\n","2024-02-12 09:44:09,915 [INFO] Initializing SimplePytorchDataTrainTestSplit\n","2024-02-12 09:44:09,917 [INFO] Start 5-fold Cross Validation with config : adam optimizer\n","2024-02-12 09:44:09,920 [INFO] ---- Fold 1 ----\n","2024-02-12 09:44:09,922 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-12 09:44:09,926 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-12 09:44:09,927 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-12 09:44:09,928 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-12 09:44:09,930 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-12 09:44:09,931 [INFO] moving data and model to cuda\n","2024-02-12 09:44:09,955 [INFO] loss: 0.0191    [1,    10]\n","2024-02-12 09:44:09,973 [INFO] loss: 0.0157    [1,    20]\n","2024-02-12 09:44:10,003 [INFO] loss: 0.0131    [2,    10]\n","2024-02-12 09:44:10,022 [INFO] loss: 0.0131    [2,    20]\n","2024-02-12 09:44:10,045 [INFO] loss: 0.0124    [3,    10]\n","2024-02-12 09:44:10,065 [INFO] loss: 0.0127    [3,    20]\n","2024-02-12 09:44:10,089 [INFO] loss: 0.0105    [4,    10]\n","2024-02-12 09:44:10,107 [INFO] loss: 0.0116    [4,    20]\n","2024-02-12 09:44:10,131 [INFO] loss: 0.0103    [5,    10]\n","2024-02-12 09:44:10,151 [INFO] loss: 0.0102    [5,    20]\n","2024-02-12 09:44:10,174 [INFO] loss: 0.0103    [6,    10]\n","2024-02-12 09:44:10,193 [INFO] loss: 0.0106    [6,    20]\n","2024-02-12 09:44:10,216 [INFO] loss: 0.0085    [7,    10]\n","2024-02-12 09:44:10,236 [INFO] loss: 0.0098    [7,    20]\n","2024-02-12 09:44:10,260 [INFO] loss: 0.0086    [8,    10]\n","2024-02-12 09:44:10,278 [INFO] loss: 0.0077    [8,    20]\n","2024-02-12 09:44:10,300 [INFO] loss: 0.0068    [9,    10]\n","2024-02-12 09:44:10,322 [INFO] loss: 0.0089    [9,    20]\n","2024-02-12 09:44:10,345 [INFO] loss: 0.0076    [10,    10]\n","2024-02-12 09:44:10,363 [INFO] loss: 0.0080    [10,    20]\n","2024-02-12 09:44:10,391 [INFO] loss: 0.0072    [11,    10]\n","2024-02-12 09:44:10,410 [INFO] loss: 0.0073    [11,    20]\n","2024-02-12 09:44:10,433 [INFO] loss: 0.0068    [12,    10]\n","2024-02-12 09:44:10,451 [INFO] loss: 0.0077    [12,    20]\n","2024-02-12 09:44:10,474 [INFO] loss: 0.0055    [13,    10]\n","2024-02-12 09:44:10,492 [INFO] loss: 0.0074    [13,    20]\n","2024-02-12 09:44:10,515 [INFO] loss: 0.0054    [14,    10]\n","2024-02-12 09:44:10,532 [INFO] loss: 0.0053    [14,    20]\n","2024-02-12 09:44:10,555 [INFO] loss: 0.0044    [15,    10]\n","2024-02-12 09:44:10,573 [INFO] loss: 0.0057    [15,    20]\n","2024-02-12 09:44:10,595 [INFO] loss: 0.0052    [16,    10]\n","2024-02-12 09:44:10,612 [INFO] loss: 0.0046    [16,    20]\n","2024-02-12 09:44:10,635 [INFO] loss: 0.0047    [17,    10]\n","2024-02-12 09:44:10,653 [INFO] loss: 0.0050    [17,    20]\n","2024-02-12 09:44:10,675 [INFO] loss: 0.0043    [18,    10]\n","2024-02-12 09:44:10,694 [INFO] loss: 0.0050    [18,    20]\n","2024-02-12 09:44:10,718 [INFO] loss: 0.0044    [19,    10]\n","2024-02-12 09:44:10,736 [INFO] loss: 0.0037    [19,    20]\n","2024-02-12 09:44:10,761 [INFO] loss: 0.0046    [20,    10]\n","2024-02-12 09:44:10,780 [INFO] loss: 0.0039    [20,    20]\n","2024-02-12 09:44:10,803 [INFO] loss: 0.0041    [21,    10]\n","2024-02-12 09:44:10,821 [INFO] loss: 0.0037    [21,    20]\n","2024-02-12 09:44:10,843 [INFO] loss: 0.0038    [22,    10]\n","2024-02-12 09:44:10,861 [INFO] loss: 0.0036    [22,    20]\n","2024-02-12 09:44:10,883 [INFO] loss: 0.0035    [23,    10]\n","2024-02-12 09:44:10,901 [INFO] loss: 0.0027    [23,    20]\n","2024-02-12 09:44:10,923 [INFO] loss: 0.0034    [24,    10]\n","2024-02-12 09:44:10,940 [INFO] loss: 0.0029    [24,    20]\n","2024-02-12 09:44:10,962 [INFO] loss: 0.0035    [25,    10]\n","2024-02-12 09:44:10,980 [INFO] loss: 0.0029    [25,    20]\n","2024-02-12 09:44:11,010 [INFO] loss: 0.0031    [26,    10]\n","2024-02-12 09:44:11,036 [INFO] loss: 0.0034    [26,    20]\n","2024-02-12 09:44:11,080 [INFO] loss: 0.0026    [27,    10]\n","2024-02-12 09:44:11,118 [INFO] loss: 0.0025    [27,    20]\n","2024-02-12 09:44:11,176 [INFO] loss: 0.0025    [28,    10]\n","2024-02-12 09:44:11,219 [INFO] loss: 0.0020    [28,    20]\n","2024-02-12 09:44:11,278 [INFO] loss: 0.0025    [29,    10]\n","2024-02-12 09:44:11,321 [INFO] loss: 0.0024    [29,    20]\n","2024-02-12 09:44:11,359 [INFO] loss: 0.0026    [30,    10]\n","2024-02-12 09:44:11,400 [INFO] loss: 0.0038    [30,    20]\n","2024-02-12 09:44:11,453 [INFO] loss: 0.0027    [31,    10]\n","2024-02-12 09:44:11,496 [INFO] loss: 0.0025    [31,    20]\n","2024-02-12 09:44:11,530 [INFO] loss: 0.0021    [32,    10]\n","2024-02-12 09:44:11,553 [INFO] loss: 0.0024    [32,    20]\n","2024-02-12 09:44:11,581 [INFO] loss: 0.0023    [33,    10]\n","2024-02-12 09:44:11,602 [INFO] loss: 0.0021    [33,    20]\n","2024-02-12 09:44:11,629 [INFO] loss: 0.0029    [34,    10]\n","2024-02-12 09:44:11,650 [INFO] loss: 0.0026    [34,    20]\n","2024-02-12 09:44:11,676 [INFO] loss: 0.0022    [35,    10]\n","2024-02-12 09:44:11,697 [INFO] loss: 0.0018    [35,    20]\n","2024-02-12 09:44:11,726 [INFO] loss: 0.0018    [36,    10]\n","2024-02-12 09:44:11,749 [INFO] loss: 0.0018    [36,    20]\n","2024-02-12 09:44:11,778 [INFO] loss: 0.0021    [37,    10]\n","2024-02-12 09:44:11,801 [INFO] loss: 0.0018    [37,    20]\n","2024-02-12 09:44:11,828 [INFO] loss: 0.0023    [38,    10]\n","2024-02-12 09:44:11,848 [INFO] loss: 0.0016    [38,    20]\n","2024-02-12 09:44:11,874 [INFO] loss: 0.0014    [39,    10]\n","2024-02-12 09:44:11,895 [INFO] loss: 0.0017    [39,    20]\n","2024-02-12 09:44:11,921 [INFO] loss: 0.0018    [40,    10]\n","2024-02-12 09:44:11,943 [INFO] loss: 0.0013    [40,    20]\n","2024-02-12 09:44:11,970 [INFO] loss: 0.0016    [41,    10]\n","2024-02-12 09:44:11,995 [INFO] loss: 0.0020    [41,    20]\n","2024-02-12 09:44:12,026 [INFO] loss: 0.0022    [42,    10]\n","2024-02-12 09:44:12,050 [INFO] loss: 0.0020    [42,    20]\n","2024-02-12 09:44:12,080 [INFO] loss: 0.0015    [43,    10]\n","2024-02-12 09:44:12,106 [INFO] loss: 0.0023    [43,    20]\n","2024-02-12 09:44:12,137 [INFO] loss: 0.0011    [44,    10]\n","2024-02-12 09:44:12,161 [INFO] loss: 0.0017    [44,    20]\n","2024-02-12 09:44:12,191 [INFO] loss: 0.0031    [45,    10]\n","2024-02-12 09:44:12,217 [INFO] loss: 0.0014    [45,    20]\n","2024-02-12 09:44:12,252 [INFO] loss: 0.0016    [46,    10]\n","2024-02-12 09:44:12,276 [INFO] loss: 0.0019    [46,    20]\n","2024-02-12 09:44:12,306 [INFO] loss: 0.0012    [47,    10]\n","2024-02-12 09:44:12,328 [INFO] loss: 0.0013    [47,    20]\n","2024-02-12 09:44:12,357 [INFO] loss: 0.0011    [48,    10]\n","2024-02-12 09:44:12,380 [INFO] loss: 0.0019    [48,    20]\n","2024-02-12 09:44:12,407 [INFO] loss: 0.0019    [49,    10]\n","2024-02-12 09:44:12,429 [INFO] loss: 0.0011    [49,    20]\n","2024-02-12 09:44:12,460 [INFO] loss: 0.0014    [50,    10]\n","2024-02-12 09:44:12,490 [INFO] loss: 0.0016    [50,    20]\n","2024-02-12 09:44:12,561 [INFO] Result on Train Data : {'AUC': 0.9999922617389421, 'ACC': 0.9986091794158554, 'F1 Score': 0.9986090825554964, 'AUPR': 0, 'Loss': 0.016625900398534926}\n","2024-02-12 09:44:12,566 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-12 09:44:12,568 [INFO] moving data and model to cuda\n","2024-02-12 09:44:12,603 [INFO] Result on Test Data : {'AUC': 0.8835958989747437, 'ACC': 0.8324022346368715, 'F1 Score': 0.8315135542168675, 'AUPR': 0, 'Loss': 0.8116775254408518}\n","2024-02-12 09:44:12,604 [INFO] Result of fold 1 : {'AUC': 0.8835958989747437, 'ACC': 0.8324022346368715, 'F1 Score': 0.8315135542168675, 'AUPR': 0, 'Loss': 0.8116775254408518}\n","2024-02-12 09:44:12,605 [INFO] ---- Fold 2 ----\n","2024-02-12 09:44:12,608 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-12 09:44:12,609 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-12 09:44:12,613 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-12 09:44:12,614 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-12 09:44:12,616 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-12 09:44:12,619 [INFO] moving data and model to cuda\n","2024-02-12 09:44:12,653 [INFO] loss: 0.0197    [1,    10]\n","2024-02-12 09:44:12,675 [INFO] loss: 0.0171    [1,    20]\n","2024-02-12 09:44:12,701 [INFO] loss: 0.0136    [2,    10]\n","2024-02-12 09:44:12,724 [INFO] loss: 0.0142    [2,    20]\n","2024-02-12 09:44:12,750 [INFO] loss: 0.0121    [3,    10]\n","2024-02-12 09:44:12,771 [INFO] loss: 0.0114    [3,    20]\n","2024-02-12 09:44:12,797 [INFO] loss: 0.0113    [4,    10]\n","2024-02-12 09:44:12,819 [INFO] loss: 0.0104    [4,    20]\n","2024-02-12 09:44:12,849 [INFO] loss: 0.0097    [5,    10]\n","2024-02-12 09:44:12,874 [INFO] loss: 0.0101    [5,    20]\n","2024-02-12 09:44:12,903 [INFO] loss: 0.0098    [6,    10]\n","2024-02-12 09:44:12,925 [INFO] loss: 0.0095    [6,    20]\n","2024-02-12 09:44:12,953 [INFO] loss: 0.0087    [7,    10]\n","2024-02-12 09:44:12,975 [INFO] loss: 0.0107    [7,    20]\n","2024-02-12 09:44:13,004 [INFO] loss: 0.0069    [8,    10]\n","2024-02-12 09:44:13,025 [INFO] loss: 0.0094    [8,    20]\n","2024-02-12 09:44:13,051 [INFO] loss: 0.0066    [9,    10]\n","2024-02-12 09:44:13,072 [INFO] loss: 0.0085    [9,    20]\n","2024-02-12 09:44:13,098 [INFO] loss: 0.0074    [10,    10]\n","2024-02-12 09:44:13,119 [INFO] loss: 0.0084    [10,    20]\n","2024-02-12 09:44:13,145 [INFO] loss: 0.0071    [11,    10]\n","2024-02-12 09:44:13,165 [INFO] loss: 0.0070    [11,    20]\n","2024-02-12 09:44:13,191 [INFO] loss: 0.0068    [12,    10]\n","2024-02-12 09:44:13,214 [INFO] loss: 0.0058    [12,    20]\n","2024-02-12 09:44:13,242 [INFO] loss: 0.0068    [13,    10]\n","2024-02-12 09:44:13,266 [INFO] loss: 0.0066    [13,    20]\n","2024-02-12 09:44:13,297 [INFO] loss: 0.0054    [14,    10]\n","2024-02-12 09:44:13,321 [INFO] loss: 0.0055    [14,    20]\n","2024-02-12 09:44:13,352 [INFO] loss: 0.0049    [15,    10]\n","2024-02-12 09:44:13,376 [INFO] loss: 0.0054    [15,    20]\n","2024-02-12 09:44:13,404 [INFO] loss: 0.0046    [16,    10]\n","2024-02-12 09:44:13,426 [INFO] loss: 0.0057    [16,    20]\n","2024-02-12 09:44:13,453 [INFO] loss: 0.0036    [17,    10]\n","2024-02-12 09:44:13,478 [INFO] loss: 0.0052    [17,    20]\n","2024-02-12 09:44:13,508 [INFO] loss: 0.0047    [18,    10]\n","2024-02-12 09:44:13,538 [INFO] loss: 0.0041    [18,    20]\n","2024-02-12 09:44:13,571 [INFO] loss: 0.0048    [19,    10]\n","2024-02-12 09:44:13,595 [INFO] loss: 0.0047    [19,    20]\n","2024-02-12 09:44:13,626 [INFO] loss: 0.0038    [20,    10]\n","2024-02-12 09:44:13,649 [INFO] loss: 0.0038    [20,    20]\n","2024-02-12 09:44:13,693 [INFO] loss: 0.0036    [21,    10]\n","2024-02-12 09:44:13,741 [INFO] loss: 0.0045    [21,    20]\n","2024-02-12 09:44:13,811 [INFO] loss: 0.0032    [22,    10]\n","2024-02-12 09:44:13,873 [INFO] loss: 0.0045    [22,    20]\n","2024-02-12 09:44:13,940 [INFO] loss: 0.0022    [23,    10]\n","2024-02-12 09:44:13,999 [INFO] loss: 0.0037    [23,    20]\n","2024-02-12 09:44:14,056 [INFO] loss: 0.0029    [24,    10]\n","2024-02-12 09:44:14,103 [INFO] loss: 0.0023    [24,    20]\n","2024-02-12 09:44:14,151 [INFO] loss: 0.0020    [25,    10]\n","2024-02-12 09:44:14,177 [INFO] loss: 0.0034    [25,    20]\n","2024-02-12 09:44:14,210 [INFO] loss: 0.0033    [26,    10]\n","2024-02-12 09:44:14,237 [INFO] loss: 0.0021    [26,    20]\n","2024-02-12 09:44:14,266 [INFO] loss: 0.0021    [27,    10]\n","2024-02-12 09:44:14,290 [INFO] loss: 0.0029    [27,    20]\n","2024-02-12 09:44:14,320 [INFO] loss: 0.0020    [28,    10]\n","2024-02-12 09:44:14,343 [INFO] loss: 0.0025    [28,    20]\n","2024-02-12 09:44:14,372 [INFO] loss: 0.0018    [29,    10]\n","2024-02-12 09:44:14,399 [INFO] loss: 0.0032    [29,    20]\n","2024-02-12 09:44:14,433 [INFO] loss: 0.0023    [30,    10]\n","2024-02-12 09:44:14,459 [INFO] loss: 0.0024    [30,    20]\n","2024-02-12 09:44:14,494 [INFO] loss: 0.0026    [31,    10]\n","2024-02-12 09:44:14,519 [INFO] loss: 0.0032    [31,    20]\n","2024-02-12 09:44:14,556 [INFO] loss: 0.0028    [32,    10]\n","2024-02-12 09:44:14,586 [INFO] loss: 0.0027    [32,    20]\n","2024-02-12 09:44:14,623 [INFO] loss: 0.0018    [33,    10]\n","2024-02-12 09:44:14,650 [INFO] loss: 0.0019    [33,    20]\n","2024-02-12 09:44:14,688 [INFO] loss: 0.0018    [34,    10]\n","2024-02-12 09:44:14,717 [INFO] loss: 0.0023    [34,    20]\n","2024-02-12 09:44:14,762 [INFO] loss: 0.0014    [35,    10]\n","2024-02-12 09:44:14,798 [INFO] loss: 0.0020    [35,    20]\n","2024-02-12 09:44:14,858 [INFO] loss: 0.0015    [36,    10]\n","2024-02-12 09:44:14,886 [INFO] loss: 0.0020    [36,    20]\n","2024-02-12 09:44:14,920 [INFO] loss: 0.0017    [37,    10]\n","2024-02-12 09:44:14,946 [INFO] loss: 0.0027    [37,    20]\n","2024-02-12 09:44:14,975 [INFO] loss: 0.0018    [38,    10]\n","2024-02-12 09:44:15,013 [INFO] loss: 0.0020    [38,    20]\n","2024-02-12 09:44:15,047 [INFO] loss: 0.0022    [39,    10]\n","2024-02-12 09:44:15,087 [INFO] loss: 0.0024    [39,    20]\n","2024-02-12 09:44:15,116 [INFO] loss: 0.0018    [40,    10]\n","2024-02-12 09:44:15,150 [INFO] loss: 0.0015    [40,    20]\n","2024-02-12 09:44:15,186 [INFO] loss: 0.0016    [41,    10]\n","2024-02-12 09:44:15,210 [INFO] loss: 0.0014    [41,    20]\n","2024-02-12 09:44:15,240 [INFO] loss: 0.0012    [42,    10]\n","2024-02-12 09:44:15,275 [INFO] loss: 0.0022    [42,    20]\n","2024-02-12 09:44:15,316 [INFO] loss: 0.0013    [43,    10]\n","2024-02-12 09:44:15,342 [INFO] loss: 0.0017    [43,    20]\n","2024-02-12 09:44:15,383 [INFO] loss: 0.0015    [44,    10]\n","2024-02-12 09:44:15,409 [INFO] loss: 0.0020    [44,    20]\n","2024-02-12 09:44:15,455 [INFO] loss: 0.0017    [45,    10]\n","2024-02-12 09:44:15,480 [INFO] loss: 0.0012    [45,    20]\n","2024-02-12 09:44:15,513 [INFO] loss: 0.0014    [46,    10]\n","2024-02-12 09:44:15,538 [INFO] loss: 0.0012    [46,    20]\n","2024-02-12 09:44:15,572 [INFO] loss: 0.0011    [47,    10]\n","2024-02-12 09:44:15,614 [INFO] loss: 0.0014    [47,    20]\n","2024-02-12 09:44:15,654 [INFO] loss: 0.0010    [48,    10]\n","2024-02-12 09:44:15,676 [INFO] loss: 0.0011    [48,    20]\n","2024-02-12 09:44:15,715 [INFO] loss: 0.0011    [49,    10]\n","2024-02-12 09:44:15,752 [INFO] loss: 0.0017    [49,    20]\n","2024-02-12 09:44:15,802 [INFO] loss: 0.0010    [50,    10]\n","2024-02-12 09:44:15,825 [INFO] loss: 0.0019    [50,    20]\n","2024-02-12 09:44:15,938 [INFO] Result on Train Data : {'AUC': 0.9999767546374498, 'ACC': 0.9958275382475661, 'F1 Score': 0.9958228840884225, 'AUPR': 0, 'Loss': 0.02653429578260883}\n","2024-02-12 09:44:15,940 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-12 09:44:15,942 [INFO] moving data and model to cuda\n","2024-02-12 09:44:16,001 [INFO] Result on Test Data : {'AUC': 0.863438937148697, 'ACC': 0.776536312849162, 'F1 Score': 0.765399737876802, 'AUPR': 0, 'Loss': 1.070833017428716}\n","2024-02-12 09:44:16,004 [INFO] Result of fold 2 : {'AUC': 0.863438937148697, 'ACC': 0.776536312849162, 'F1 Score': 0.765399737876802, 'AUPR': 0, 'Loss': 1.070833017428716}\n","2024-02-12 09:44:16,006 [INFO] ---- Fold 3 ----\n","2024-02-12 09:44:16,009 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-12 09:44:16,011 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-12 09:44:16,013 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-12 09:44:16,015 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-12 09:44:16,017 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-12 09:44:16,019 [INFO] moving data and model to cuda\n","2024-02-12 09:44:16,055 [INFO] loss: 0.0203    [1,    10]\n","2024-02-12 09:44:16,079 [INFO] loss: 0.0175    [1,    20]\n","2024-02-12 09:44:16,151 [INFO] loss: 0.0143    [2,    10]\n","2024-02-12 09:44:16,176 [INFO] loss: 0.0131    [2,    20]\n","2024-02-12 09:44:16,215 [INFO] loss: 0.0126    [3,    10]\n","2024-02-12 09:44:16,238 [INFO] loss: 0.0117    [3,    20]\n","2024-02-12 09:44:16,267 [INFO] loss: 0.0110    [4,    10]\n","2024-02-12 09:44:16,295 [INFO] loss: 0.0115    [4,    20]\n","2024-02-12 09:44:16,325 [INFO] loss: 0.0095    [5,    10]\n","2024-02-12 09:44:16,347 [INFO] loss: 0.0102    [5,    20]\n","2024-02-12 09:44:16,382 [INFO] loss: 0.0098    [6,    10]\n","2024-02-12 09:44:16,411 [INFO] loss: 0.0078    [6,    20]\n","2024-02-12 09:44:16,441 [INFO] loss: 0.0082    [7,    10]\n","2024-02-12 09:44:16,464 [INFO] loss: 0.0098    [7,    20]\n","2024-02-12 09:44:16,494 [INFO] loss: 0.0082    [8,    10]\n","2024-02-12 09:44:16,517 [INFO] loss: 0.0082    [8,    20]\n","2024-02-12 09:44:16,557 [INFO] loss: 0.0065    [9,    10]\n","2024-02-12 09:44:16,581 [INFO] loss: 0.0082    [9,    20]\n","2024-02-12 09:44:16,611 [INFO] loss: 0.0069    [10,    10]\n","2024-02-12 09:44:16,659 [INFO] loss: 0.0070    [10,    20]\n","2024-02-12 09:44:16,693 [INFO] loss: 0.0063    [11,    10]\n","2024-02-12 09:44:16,725 [INFO] loss: 0.0064    [11,    20]\n","2024-02-12 09:44:16,760 [INFO] loss: 0.0070    [12,    10]\n","2024-02-12 09:44:16,785 [INFO] loss: 0.0056    [12,    20]\n","2024-02-12 09:44:16,817 [INFO] loss: 0.0046    [13,    10]\n","2024-02-12 09:44:16,848 [INFO] loss: 0.0066    [13,    20]\n","2024-02-12 09:44:16,881 [INFO] loss: 0.0051    [14,    10]\n","2024-02-12 09:44:16,907 [INFO] loss: 0.0045    [14,    20]\n","2024-02-12 09:44:16,943 [INFO] loss: 0.0056    [15,    10]\n","2024-02-12 09:44:16,968 [INFO] loss: 0.0057    [15,    20]\n","2024-02-12 09:44:17,000 [INFO] loss: 0.0044    [16,    10]\n","2024-02-12 09:44:17,026 [INFO] loss: 0.0053    [16,    20]\n","2024-02-12 09:44:17,077 [INFO] loss: 0.0039    [17,    10]\n","2024-02-12 09:44:17,124 [INFO] loss: 0.0054    [17,    20]\n","2024-02-12 09:44:17,163 [INFO] loss: 0.0040    [18,    10]\n","2024-02-12 09:44:17,192 [INFO] loss: 0.0053    [18,    20]\n","2024-02-12 09:44:17,235 [INFO] loss: 0.0035    [19,    10]\n","2024-02-12 09:44:17,272 [INFO] loss: 0.0043    [19,    20]\n","2024-02-12 09:44:17,327 [INFO] loss: 0.0038    [20,    10]\n","2024-02-12 09:44:17,353 [INFO] loss: 0.0044    [20,    20]\n","2024-02-12 09:44:17,386 [INFO] loss: 0.0029    [21,    10]\n","2024-02-12 09:44:17,429 [INFO] loss: 0.0043    [21,    20]\n","2024-02-12 09:44:17,463 [INFO] loss: 0.0028    [22,    10]\n","2024-02-12 09:44:17,490 [INFO] loss: 0.0034    [22,    20]\n","2024-02-12 09:44:17,535 [INFO] loss: 0.0035    [23,    10]\n","2024-02-12 09:44:17,559 [INFO] loss: 0.0032    [23,    20]\n","2024-02-12 09:44:17,588 [INFO] loss: 0.0032    [24,    10]\n","2024-02-12 09:44:17,611 [INFO] loss: 0.0030    [24,    20]\n","2024-02-12 09:44:17,648 [INFO] loss: 0.0029    [25,    10]\n","2024-02-12 09:44:17,677 [INFO] loss: 0.0025    [25,    20]\n","2024-02-12 09:44:17,716 [INFO] loss: 0.0026    [26,    10]\n","2024-02-12 09:44:17,740 [INFO] loss: 0.0042    [26,    20]\n","2024-02-12 09:44:17,780 [INFO] loss: 0.0039    [27,    10]\n","2024-02-12 09:44:17,812 [INFO] loss: 0.0023    [27,    20]\n","2024-02-12 09:44:17,843 [INFO] loss: 0.0025    [28,    10]\n","2024-02-12 09:44:17,869 [INFO] loss: 0.0030    [28,    20]\n","2024-02-12 09:44:17,908 [INFO] loss: 0.0026    [29,    10]\n","2024-02-12 09:44:17,955 [INFO] loss: 0.0028    [29,    20]\n","2024-02-12 09:44:18,009 [INFO] loss: 0.0027    [30,    10]\n","2024-02-12 09:44:18,033 [INFO] loss: 0.0023    [30,    20]\n","2024-02-12 09:44:18,086 [INFO] loss: 0.0017    [31,    10]\n","2024-02-12 09:44:18,127 [INFO] loss: 0.0024    [31,    20]\n","2024-02-12 09:44:18,186 [INFO] loss: 0.0023    [32,    10]\n","2024-02-12 09:44:18,211 [INFO] loss: 0.0017    [32,    20]\n","2024-02-12 09:44:18,250 [INFO] loss: 0.0019    [33,    10]\n","2024-02-12 09:44:18,279 [INFO] loss: 0.0019    [33,    20]\n","2024-02-12 09:44:18,353 [INFO] loss: 0.0020    [34,    10]\n","2024-02-12 09:44:18,415 [INFO] loss: 0.0017    [34,    20]\n","2024-02-12 09:44:18,500 [INFO] loss: 0.0026    [35,    10]\n","2024-02-12 09:44:18,549 [INFO] loss: 0.0023    [35,    20]\n","2024-02-12 09:44:18,620 [INFO] loss: 0.0019    [36,    10]\n","2024-02-12 09:44:18,683 [INFO] loss: 0.0024    [36,    20]\n","2024-02-12 09:44:18,797 [INFO] loss: 0.0020    [37,    10]\n","2024-02-12 09:44:18,873 [INFO] loss: 0.0014    [37,    20]\n","2024-02-12 09:44:18,947 [INFO] loss: 0.0019    [38,    10]\n","2024-02-12 09:44:19,003 [INFO] loss: 0.0032    [38,    20]\n","2024-02-12 09:44:19,063 [INFO] loss: 0.0027    [39,    10]\n","2024-02-12 09:44:19,099 [INFO] loss: 0.0043    [39,    20]\n","2024-02-12 09:44:19,179 [INFO] loss: 0.0024    [40,    10]\n","2024-02-12 09:44:19,245 [INFO] loss: 0.0024    [40,    20]\n","2024-02-12 09:44:19,306 [INFO] loss: 0.0026    [41,    10]\n","2024-02-12 09:44:19,337 [INFO] loss: 0.0018    [41,    20]\n","2024-02-12 09:44:19,371 [INFO] loss: 0.0018    [42,    10]\n","2024-02-12 09:44:19,397 [INFO] loss: 0.0013    [42,    20]\n","2024-02-12 09:44:19,435 [INFO] loss: 0.0014    [43,    10]\n","2024-02-12 09:44:19,461 [INFO] loss: 0.0017    [43,    20]\n","2024-02-12 09:44:19,501 [INFO] loss: 0.0019    [44,    10]\n","2024-02-12 09:44:19,527 [INFO] loss: 0.0019    [44,    20]\n","2024-02-12 09:44:19,559 [INFO] loss: 0.0014    [45,    10]\n","2024-02-12 09:44:19,588 [INFO] loss: 0.0019    [45,    20]\n","2024-02-12 09:44:19,619 [INFO] loss: 0.0014    [46,    10]\n","2024-02-12 09:44:19,645 [INFO] loss: 0.0018    [46,    20]\n","2024-02-12 09:44:19,677 [INFO] loss: 0.0016    [47,    10]\n","2024-02-12 09:44:19,710 [INFO] loss: 0.0018    [47,    20]\n","2024-02-12 09:44:19,742 [INFO] loss: 0.0016    [48,    10]\n","2024-02-12 09:44:19,784 [INFO] loss: 0.0014    [48,    20]\n","2024-02-12 09:44:19,825 [INFO] loss: 0.0011    [49,    10]\n","2024-02-12 09:44:19,852 [INFO] loss: 0.0012    [49,    20]\n","2024-02-12 09:44:19,886 [INFO] loss: 0.0014    [50,    10]\n","2024-02-12 09:44:19,916 [INFO] loss: 0.0011    [50,    20]\n","2024-02-12 09:44:19,993 [INFO] Result on Train Data : {'AUC': 0.9998374965177825, 'ACC': 0.9944367176634215, 'F1 Score': 0.9944358458442966, 'AUPR': 0, 'Loss': 0.022635004533778712}\n","2024-02-12 09:44:20,003 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-12 09:44:20,007 [INFO] moving data and model to cuda\n","2024-02-12 09:44:20,038 [INFO] Result on Test Data : {'AUC': 0.8637159289822455, 'ACC': 0.770949720670391, 'F1 Score': 0.7704912906151296, 'AUPR': 0, 'Loss': 0.9615005602439245}\n","2024-02-12 09:44:20,045 [INFO] Result of fold 3 : {'AUC': 0.8637159289822455, 'ACC': 0.770949720670391, 'F1 Score': 0.7704912906151296, 'AUPR': 0, 'Loss': 0.9615005602439245}\n","2024-02-12 09:44:20,049 [INFO] ---- Fold 4 ----\n","2024-02-12 09:44:20,054 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-12 09:44:20,059 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-12 09:44:20,064 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-12 09:44:20,066 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-12 09:44:20,070 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-12 09:44:20,073 [INFO] moving data and model to cuda\n","2024-02-12 09:44:20,118 [INFO] loss: 0.0191    [1,    10]\n","2024-02-12 09:44:20,160 [INFO] loss: 0.0184    [1,    20]\n","2024-02-12 09:44:20,215 [INFO] loss: 0.0146    [2,    10]\n","2024-02-12 09:44:20,245 [INFO] loss: 0.0138    [2,    20]\n","2024-02-12 09:44:20,307 [INFO] loss: 0.0117    [3,    10]\n","2024-02-12 09:44:20,325 [INFO] loss: 0.0130    [3,    20]\n","2024-02-12 09:44:20,348 [INFO] loss: 0.0099    [4,    10]\n","2024-02-12 09:44:20,366 [INFO] loss: 0.0116    [4,    20]\n","2024-02-12 09:44:20,390 [INFO] loss: 0.0097    [5,    10]\n","2024-02-12 09:44:20,412 [INFO] loss: 0.0112    [5,    20]\n","2024-02-12 09:44:20,435 [INFO] loss: 0.0104    [6,    10]\n","2024-02-12 09:44:20,454 [INFO] loss: 0.0099    [6,    20]\n","2024-02-12 09:44:20,477 [INFO] loss: 0.0090    [7,    10]\n","2024-02-12 09:44:20,496 [INFO] loss: 0.0102    [7,    20]\n","2024-02-12 09:44:20,519 [INFO] loss: 0.0092    [8,    10]\n","2024-02-12 09:44:20,538 [INFO] loss: 0.0081    [8,    20]\n","2024-02-12 09:44:20,561 [INFO] loss: 0.0087    [9,    10]\n","2024-02-12 09:44:20,580 [INFO] loss: 0.0080    [9,    20]\n","2024-02-12 09:44:20,603 [INFO] loss: 0.0080    [10,    10]\n","2024-02-12 09:44:20,622 [INFO] loss: 0.0095    [10,    20]\n","2024-02-12 09:44:20,646 [INFO] loss: 0.0076    [11,    10]\n","2024-02-12 09:44:20,664 [INFO] loss: 0.0080    [11,    20]\n","2024-02-12 09:44:20,687 [INFO] loss: 0.0071    [12,    10]\n","2024-02-12 09:44:20,706 [INFO] loss: 0.0073    [12,    20]\n","2024-02-12 09:44:20,730 [INFO] loss: 0.0064    [13,    10]\n","2024-02-12 09:44:20,748 [INFO] loss: 0.0078    [13,    20]\n","2024-02-12 09:44:20,772 [INFO] loss: 0.0074    [14,    10]\n","2024-02-12 09:44:20,791 [INFO] loss: 0.0077    [14,    20]\n","2024-02-12 09:44:20,821 [INFO] loss: 0.0062    [15,    10]\n","2024-02-12 09:44:20,841 [INFO] loss: 0.0056    [15,    20]\n","2024-02-12 09:44:20,864 [INFO] loss: 0.0047    [16,    10]\n","2024-02-12 09:44:20,882 [INFO] loss: 0.0064    [16,    20]\n","2024-02-12 09:44:20,905 [INFO] loss: 0.0050    [17,    10]\n","2024-02-12 09:44:20,922 [INFO] loss: 0.0053    [17,    20]\n","2024-02-12 09:44:20,946 [INFO] loss: 0.0048    [18,    10]\n","2024-02-12 09:44:20,968 [INFO] loss: 0.0050    [18,    20]\n","2024-02-12 09:44:20,991 [INFO] loss: 0.0054    [19,    10]\n","2024-02-12 09:44:21,008 [INFO] loss: 0.0053    [19,    20]\n","2024-02-12 09:44:21,031 [INFO] loss: 0.0039    [20,    10]\n","2024-02-12 09:44:21,050 [INFO] loss: 0.0041    [20,    20]\n","2024-02-12 09:44:21,073 [INFO] loss: 0.0048    [21,    10]\n","2024-02-12 09:44:21,092 [INFO] loss: 0.0034    [21,    20]\n","2024-02-12 09:44:21,115 [INFO] loss: 0.0040    [22,    10]\n","2024-02-12 09:44:21,133 [INFO] loss: 0.0046    [22,    20]\n","2024-02-12 09:44:21,156 [INFO] loss: 0.0034    [23,    10]\n","2024-02-12 09:44:21,174 [INFO] loss: 0.0043    [23,    20]\n","2024-02-12 09:44:21,197 [INFO] loss: 0.0032    [24,    10]\n","2024-02-12 09:44:21,215 [INFO] loss: 0.0032    [24,    20]\n","2024-02-12 09:44:21,238 [INFO] loss: 0.0025    [25,    10]\n","2024-02-12 09:44:21,257 [INFO] loss: 0.0036    [25,    20]\n","2024-02-12 09:44:21,281 [INFO] loss: 0.0028    [26,    10]\n","2024-02-12 09:44:21,299 [INFO] loss: 0.0028    [26,    20]\n","2024-02-12 09:44:21,321 [INFO] loss: 0.0028    [27,    10]\n","2024-02-12 09:44:21,339 [INFO] loss: 0.0037    [27,    20]\n","2024-02-12 09:44:21,363 [INFO] loss: 0.0024    [28,    10]\n","2024-02-12 09:44:21,381 [INFO] loss: 0.0027    [28,    20]\n","2024-02-12 09:44:21,407 [INFO] loss: 0.0029    [29,    10]\n","2024-02-12 09:44:21,424 [INFO] loss: 0.0026    [29,    20]\n","2024-02-12 09:44:21,450 [INFO] loss: 0.0024    [30,    10]\n","2024-02-12 09:44:21,468 [INFO] loss: 0.0026    [30,    20]\n","2024-02-12 09:44:21,491 [INFO] loss: 0.0030    [31,    10]\n","2024-02-12 09:44:21,510 [INFO] loss: 0.0027    [31,    20]\n","2024-02-12 09:44:21,533 [INFO] loss: 0.0024    [32,    10]\n","2024-02-12 09:44:21,551 [INFO] loss: 0.0019    [32,    20]\n","2024-02-12 09:44:21,574 [INFO] loss: 0.0023    [33,    10]\n","2024-02-12 09:44:21,592 [INFO] loss: 0.0032    [33,    20]\n","2024-02-12 09:44:21,614 [INFO] loss: 0.0016    [34,    10]\n","2024-02-12 09:44:21,632 [INFO] loss: 0.0029    [34,    20]\n","2024-02-12 09:44:21,659 [INFO] loss: 0.0025    [35,    10]\n","2024-02-12 09:44:21,678 [INFO] loss: 0.0023    [35,    20]\n","2024-02-12 09:44:21,701 [INFO] loss: 0.0018    [36,    10]\n","2024-02-12 09:44:21,721 [INFO] loss: 0.0018    [36,    20]\n","2024-02-12 09:44:21,745 [INFO] loss: 0.0023    [37,    10]\n","2024-02-12 09:44:21,764 [INFO] loss: 0.0028    [37,    20]\n","2024-02-12 09:44:21,789 [INFO] loss: 0.0026    [38,    10]\n","2024-02-12 09:44:21,808 [INFO] loss: 0.0020    [38,    20]\n","2024-02-12 09:44:21,833 [INFO] loss: 0.0014    [39,    10]\n","2024-02-12 09:44:21,859 [INFO] loss: 0.0018    [39,    20]\n","2024-02-12 09:44:21,885 [INFO] loss: 0.0010    [40,    10]\n","2024-02-12 09:44:21,905 [INFO] loss: 0.0021    [40,    20]\n","2024-02-12 09:44:21,928 [INFO] loss: 0.0016    [41,    10]\n","2024-02-12 09:44:21,947 [INFO] loss: 0.0019    [41,    20]\n","2024-02-12 09:44:21,971 [INFO] loss: 0.0019    [42,    10]\n","2024-02-12 09:44:21,990 [INFO] loss: 0.0017    [42,    20]\n","2024-02-12 09:44:22,013 [INFO] loss: 0.0020    [43,    10]\n","2024-02-12 09:44:22,032 [INFO] loss: 0.0022    [43,    20]\n","2024-02-12 09:44:22,055 [INFO] loss: 0.0017    [44,    10]\n","2024-02-12 09:44:22,078 [INFO] loss: 0.0021    [44,    20]\n","2024-02-12 09:44:22,101 [INFO] loss: 0.0012    [45,    10]\n","2024-02-12 09:44:22,120 [INFO] loss: 0.0017    [45,    20]\n","2024-02-12 09:44:22,143 [INFO] loss: 0.0016    [46,    10]\n","2024-02-12 09:44:22,163 [INFO] loss: 0.0017    [46,    20]\n","2024-02-12 09:44:22,187 [INFO] loss: 0.0012    [47,    10]\n","2024-02-12 09:44:22,205 [INFO] loss: 0.0016    [47,    20]\n","2024-02-12 09:44:22,228 [INFO] loss: 0.0017    [48,    10]\n","2024-02-12 09:44:22,246 [INFO] loss: 0.0016    [48,    20]\n","2024-02-12 09:44:22,269 [INFO] loss: 0.0008    [49,    10]\n","2024-02-12 09:44:22,287 [INFO] loss: 0.0018    [49,    20]\n","2024-02-12 09:44:22,312 [INFO] loss: 0.0016    [50,    10]\n","2024-02-12 09:44:22,331 [INFO] loss: 0.0021    [50,    20]\n","2024-02-12 09:44:22,375 [INFO] Result on Train Data : {'AUC': 0.9999922623377026, 'ACC': 0.9958275382475661, 'F1 Score': 0.9958275382475661, 'AUPR': 0, 'Loss': 0.02873749877123729}\n","2024-02-12 09:44:22,376 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-12 09:44:22,378 [INFO] moving data and model to cuda\n","2024-02-12 09:44:22,397 [INFO] Result on Test Data : {'AUC': 0.9058441558441559, 'ACC': 0.8324022346368715, 'F1 Score': 0.832145536384096, 'AUPR': 0, 'Loss': 0.7059228420257568}\n","2024-02-12 09:44:22,398 [INFO] Result of fold 4 : {'AUC': 0.9058441558441559, 'ACC': 0.8324022346368715, 'F1 Score': 0.832145536384096, 'AUPR': 0, 'Loss': 0.7059228420257568}\n","2024-02-12 09:44:22,400 [INFO] ---- Fold 5 ----\n","2024-02-12 09:44:22,402 [INFO] Initializing SimplePytorchData with X shape : torch.Size([716, 64]) and y shape : torch.Size([716, 1])\n","2024-02-12 09:44:22,404 [INFO] Initializing SimplePytorchData with X shape : torch.Size([182, 64]) and y shape : torch.Size([182, 1])\n","2024-02-12 09:44:22,406 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-12 09:44:22,407 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-12 09:44:22,409 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-12 09:44:22,411 [INFO] moving data and model to cuda\n","2024-02-12 09:44:22,433 [INFO] loss: 0.0210    [1,    10]\n","2024-02-12 09:44:22,450 [INFO] loss: 0.0186    [1,    20]\n","2024-02-12 09:44:22,478 [INFO] loss: 0.0139    [2,    10]\n","2024-02-12 09:44:22,496 [INFO] loss: 0.0148    [2,    20]\n","2024-02-12 09:44:22,521 [INFO] loss: 0.0110    [3,    10]\n","2024-02-12 09:44:22,538 [INFO] loss: 0.0137    [3,    20]\n","2024-02-12 09:44:22,561 [INFO] loss: 0.0104    [4,    10]\n","2024-02-12 09:44:22,579 [INFO] loss: 0.0114    [4,    20]\n","2024-02-12 09:44:22,603 [INFO] loss: 0.0093    [5,    10]\n","2024-02-12 09:44:22,622 [INFO] loss: 0.0109    [5,    20]\n","2024-02-12 09:44:22,646 [INFO] loss: 0.0093    [6,    10]\n","2024-02-12 09:44:22,664 [INFO] loss: 0.0102    [6,    20]\n","2024-02-12 09:44:22,687 [INFO] loss: 0.0083    [7,    10]\n","2024-02-12 09:44:22,705 [INFO] loss: 0.0086    [7,    20]\n","2024-02-12 09:44:22,729 [INFO] loss: 0.0072    [8,    10]\n","2024-02-12 09:44:22,747 [INFO] loss: 0.0079    [8,    20]\n","2024-02-12 09:44:22,771 [INFO] loss: 0.0063    [9,    10]\n","2024-02-12 09:44:22,790 [INFO] loss: 0.0079    [9,    20]\n","2024-02-12 09:44:22,813 [INFO] loss: 0.0065    [10,    10]\n","2024-02-12 09:44:22,832 [INFO] loss: 0.0076    [10,    20]\n","2024-02-12 09:44:22,855 [INFO] loss: 0.0067    [11,    10]\n","2024-02-12 09:44:22,882 [INFO] loss: 0.0059    [11,    20]\n","2024-02-12 09:44:22,907 [INFO] loss: 0.0053    [12,    10]\n","2024-02-12 09:44:22,926 [INFO] loss: 0.0057    [12,    20]\n","2024-02-12 09:44:22,949 [INFO] loss: 0.0059    [13,    10]\n","2024-02-12 09:44:22,967 [INFO] loss: 0.0063    [13,    20]\n","2024-02-12 09:44:22,991 [INFO] loss: 0.0063    [14,    10]\n","2024-02-12 09:44:23,009 [INFO] loss: 0.0056    [14,    20]\n","2024-02-12 09:44:23,033 [INFO] loss: 0.0048    [15,    10]\n","2024-02-12 09:44:23,051 [INFO] loss: 0.0049    [15,    20]\n","2024-02-12 09:44:23,074 [INFO] loss: 0.0040    [16,    10]\n","2024-02-12 09:44:23,093 [INFO] loss: 0.0042    [16,    20]\n","2024-02-12 09:44:23,116 [INFO] loss: 0.0036    [17,    10]\n","2024-02-12 09:44:23,135 [INFO] loss: 0.0037    [17,    20]\n","2024-02-12 09:44:23,158 [INFO] loss: 0.0032    [18,    10]\n","2024-02-12 09:44:23,177 [INFO] loss: 0.0041    [18,    20]\n","2024-02-12 09:44:23,202 [INFO] loss: 0.0038    [19,    10]\n","2024-02-12 09:44:23,221 [INFO] loss: 0.0036    [19,    20]\n","2024-02-12 09:44:23,245 [INFO] loss: 0.0027    [20,    10]\n","2024-02-12 09:44:23,263 [INFO] loss: 0.0034    [20,    20]\n","2024-02-12 09:44:23,286 [INFO] loss: 0.0026    [21,    10]\n","2024-02-12 09:44:23,305 [INFO] loss: 0.0028    [21,    20]\n","2024-02-12 09:44:23,330 [INFO] loss: 0.0032    [22,    10]\n","2024-02-12 09:44:23,349 [INFO] loss: 0.0024    [22,    20]\n","2024-02-12 09:44:23,372 [INFO] loss: 0.0028    [23,    10]\n","2024-02-12 09:44:23,392 [INFO] loss: 0.0039    [23,    20]\n","2024-02-12 09:44:23,415 [INFO] loss: 0.0030    [24,    10]\n","2024-02-12 09:44:23,433 [INFO] loss: 0.0029    [24,    20]\n","2024-02-12 09:44:23,456 [INFO] loss: 0.0025    [25,    10]\n","2024-02-12 09:44:23,475 [INFO] loss: 0.0024    [25,    20]\n","2024-02-12 09:44:23,498 [INFO] loss: 0.0028    [26,    10]\n","2024-02-12 09:44:23,517 [INFO] loss: 0.0021    [26,    20]\n","2024-02-12 09:44:23,540 [INFO] loss: 0.0027    [27,    10]\n","2024-02-12 09:44:23,559 [INFO] loss: 0.0019    [27,    20]\n","2024-02-12 09:44:23,582 [INFO] loss: 0.0015    [28,    10]\n","2024-02-12 09:44:23,600 [INFO] loss: 0.0023    [28,    20]\n","2024-02-12 09:44:23,624 [INFO] loss: 0.0017    [29,    10]\n","2024-02-12 09:44:23,645 [INFO] loss: 0.0030    [29,    20]\n","2024-02-12 09:44:23,668 [INFO] loss: 0.0020    [30,    10]\n","2024-02-12 09:44:23,687 [INFO] loss: 0.0020    [30,    20]\n","2024-02-12 09:44:23,710 [INFO] loss: 0.0023    [31,    10]\n","2024-02-12 09:44:23,728 [INFO] loss: 0.0025    [31,    20]\n","2024-02-12 09:44:23,751 [INFO] loss: 0.0016    [32,    10]\n","2024-02-12 09:44:23,769 [INFO] loss: 0.0029    [32,    20]\n","2024-02-12 09:44:23,793 [INFO] loss: 0.0015    [33,    10]\n","2024-02-12 09:44:23,812 [INFO] loss: 0.0021    [33,    20]\n","2024-02-12 09:44:23,837 [INFO] loss: 0.0018    [34,    10]\n","2024-02-12 09:44:23,855 [INFO] loss: 0.0022    [34,    20]\n","2024-02-12 09:44:23,878 [INFO] loss: 0.0015    [35,    10]\n","2024-02-12 09:44:23,904 [INFO] loss: 0.0027    [35,    20]\n","2024-02-12 09:44:23,926 [INFO] loss: 0.0021    [36,    10]\n","2024-02-12 09:44:23,945 [INFO] loss: 0.0018    [36,    20]\n","2024-02-12 09:44:23,968 [INFO] loss: 0.0020    [37,    10]\n","2024-02-12 09:44:23,986 [INFO] loss: 0.0014    [37,    20]\n","2024-02-12 09:44:24,008 [INFO] loss: 0.0014    [38,    10]\n","2024-02-12 09:44:24,026 [INFO] loss: 0.0016    [38,    20]\n","2024-02-12 09:44:24,049 [INFO] loss: 0.0015    [39,    10]\n","2024-02-12 09:44:24,067 [INFO] loss: 0.0021    [39,    20]\n","2024-02-12 09:44:24,090 [INFO] loss: 0.0020    [40,    10]\n","2024-02-12 09:44:24,108 [INFO] loss: 0.0014    [40,    20]\n","2024-02-12 09:44:24,131 [INFO] loss: 0.0018    [41,    10]\n","2024-02-12 09:44:24,156 [INFO] loss: 0.0010    [41,    20]\n","2024-02-12 09:44:24,187 [INFO] loss: 0.0014    [42,    10]\n","2024-02-12 09:44:24,212 [INFO] loss: 0.0019    [42,    20]\n","2024-02-12 09:44:24,243 [INFO] loss: 0.0017    [43,    10]\n","2024-02-12 09:44:24,270 [INFO] loss: 0.0025    [43,    20]\n","2024-02-12 09:44:24,300 [INFO] loss: 0.0019    [44,    10]\n","2024-02-12 09:44:24,323 [INFO] loss: 0.0016    [44,    20]\n","2024-02-12 09:44:24,351 [INFO] loss: 0.0018    [45,    10]\n","2024-02-12 09:44:24,378 [INFO] loss: 0.0012    [45,    20]\n","2024-02-12 09:44:24,410 [INFO] loss: 0.0016    [46,    10]\n","2024-02-12 09:44:24,432 [INFO] loss: 0.0010    [46,    20]\n","2024-02-12 09:44:24,462 [INFO] loss: 0.0012    [47,    10]\n","2024-02-12 09:44:24,484 [INFO] loss: 0.0023    [47,    20]\n","2024-02-12 09:44:24,511 [INFO] loss: 0.0008    [48,    10]\n","2024-02-12 09:44:24,532 [INFO] loss: 0.0010    [48,    20]\n","2024-02-12 09:44:24,561 [INFO] loss: 0.0010    [49,    10]\n","2024-02-12 09:44:24,582 [INFO] loss: 0.0018    [49,    20]\n","2024-02-12 09:44:24,610 [INFO] loss: 0.0013    [50,    10]\n","2024-02-12 09:44:24,631 [INFO] loss: 0.0015    [50,    20]\n","2024-02-12 09:44:24,698 [INFO] Result on Train Data : {'AUC': 0.9999843919493675, 'ACC': 0.9972067039106145, 'F1 Score': 0.9972061589367796, 'AUPR': 0, 'Loss': 0.014954253828719906}\n","2024-02-12 09:44:24,700 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-12 09:44:24,703 [INFO] moving data and model to cuda\n","2024-02-12 09:44:24,735 [INFO] Result on Test Data : {'AUC': 0.8490188953488373, 'ACC': 0.7637362637362637, 'F1 Score': 0.7631570983264231, 'AUPR': 0, 'Loss': 1.3450003862380981}\n","2024-02-12 09:44:24,736 [INFO] Result of fold 5 : {'AUC': 0.8490188953488373, 'ACC': 0.7637362637362637, 'F1 Score': 0.7631570983264231, 'AUPR': 0, 'Loss': 1.3450003862380981}\n","2024-02-12 09:44:24,738 [INFO] 5-fold result: avg_auc: 0.873122763259736, avg_acc: 0.7952053533059119, avg_f1: 0.7925414434838636, avg_aupr: 0.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<base.evaluation.Result at 0x7bcfadd5a320>"]},"metadata":{},"execution_count":40}],"source":["trainer = SimpleTrainer()\n","tester = SimpleTester()\n","factory = SimpleMDAClassifierFactory(simple_classifier_config)\n","spliter = SimplePytorchDataTrainTestSplit(data)\n","cross_validation(k=5, data_size=data.X.shape[0], train_test_spliter=spliter, model_factory=factory,\n","                    trainer=trainer, tester=tester, config=classifier_optimizer_config)"],"id":"sfI286uv6o-e"},{"cell_type":"code","source":[],"metadata":{"id":"5cpQ0kPkjuHb","executionInfo":{"status":"ok","timestamp":1707731065352,"user_tz":-210,"elapsed":20,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":40,"outputs":[],"id":"5cpQ0kPkjuHb"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}