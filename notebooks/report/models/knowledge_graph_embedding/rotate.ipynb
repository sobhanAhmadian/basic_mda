{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbSkLzXRVkG1","executionInfo":{"status":"ok","timestamp":1707732369456,"user_tz":-210,"elapsed":3225,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"344a781f-ea73-4dd9-b13d-8258f9d7e3e7"},"id":"AbSkLzXRVkG1","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":22,"id":"initial_id","metadata":{"collapsed":true,"id":"initial_id","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707732369456,"user_tz":-210,"elapsed":8,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"9f4b777b-17c9-4b85-e129-1d4131a224c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["base  data_repository  notebooks  requirements.txt  src\n"]}],"source":["!ls"]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Academic/Topics/AI/Machine\\ Learning\\ Dr.\\ Montazeri/Project/ml_mda"],"metadata":{"id":"uDVTuQuDVXDp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707732369457,"user_tz":-210,"elapsed":5,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"d06b2603-e8fa-4424-b426-19bfd459c9a7"},"id":"uDVTuQuDVXDp","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Academic/Topics/AI/Machine Learning Dr. Montazeri/Project/ml_mda\n"]}]},{"cell_type":"code","source":["!pip install torch_geometric"],"metadata":{"id":"RDY-Ibk-EuwN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707732375154,"user_tz":-210,"elapsed":5700,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"311832fb-b643-4c0f-9229-15901a01d137"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"]}],"id":"RDY-Ibk-EuwN"},{"cell_type":"code","source":["!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html"],"metadata":{"id":"8Vot3XZDEzNX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707732385804,"user_tz":-210,"elapsed":9856,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"f75dc22a-8a33-4d09-b6b9-f904e4bd39ed"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\n","Requirement already satisfied: pyg_lib in /usr/local/lib/python3.10/dist-packages (0.4.0+pt21cu121)\n","Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt21cu121)\n","Requirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt21cu121)\n","Requirement already satisfied: torch_cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt21cu121)\n","Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt21cu121)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n"]}],"id":"8Vot3XZDEzNX"},{"cell_type":"markdown","source":["# Requirements"],"metadata":{"id":"CP5slJxnWMG-"},"id":"CP5slJxnWMG-"},{"cell_type":"code","source":["import torch\n","\n","from torch.optim import Adam\n","from torch_geometric.nn import ComplEx, DistMult, RotatE, TransE\n","from torch_geometric.data import Data\n","\n","from base import OptimizerConfig, cross_validation\n","from base import SimplePytorchData, SimplePytorchDataTrainTestSplit\n","from base import SimpleTrainer, SimpleTester\n","from src.config import SimpleClassifierConfig, GraphAutoEncoderConfig, KGEConfig\n","from src.features import get_relations, get_entities, get_associations, get_homogeneous_graph, get_kge_pair_embedd_for_training_data\n","from src.models import SimpleMDAClassifier, SimpleMDAClassifierFactory\n","from src.utils import train_test_sampler, prj_logger\n","from torch_geometric.nn import GCNConv"],"metadata":{"id":"1Tz_6Gnq191K","executionInfo":{"status":"ok","timestamp":1707732385805,"user_tz":-210,"elapsed":23,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"1Tz_6Gnq191K","execution_count":26,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"5V-nDmj61M_3","executionInfo":{"status":"ok","timestamp":1707732385805,"user_tz":-210,"elapsed":22,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"5V-nDmj61M_3","execution_count":27,"outputs":[]},{"cell_type":"code","source":["import logging\n","import sys\n","\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n","    handlers=[\n","        logging.StreamHandler(stream=sys.stdout)\n","    ],\n","    force=True\n",")"],"metadata":{"id":"v4fhFqHr-UQI","executionInfo":{"status":"ok","timestamp":1707732385805,"user_tz":-210,"elapsed":22,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"v4fhFqHr-UQI","execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["# RotatE"],"metadata":{"id":"jQ9m4sXXMrP_"},"id":"jQ9m4sXXMrP_"},{"cell_type":"markdown","source":["## Config"],"metadata":{"id":"mze45lXFT9mw"},"id":"mze45lXFT9mw"},{"cell_type":"code","source":["kge_optimizer_config = OptimizerConfig()\n","kge_optimizer_config.optimizer = torch.optim.Adam\n","kge_optimizer_config.lr = 0.01\n","kge_optimizer_config.batch_size = 1000\n","kge_optimizer_config.n_epoch = 10\n","kge_optimizer_config.exp_name = \"Optimizer for Graph Auto Encoder\"\n","kge_optimizer_config.device = device\n","kge_optimizer_config.report_size = device"],"metadata":{"id":"r4zjaDCMMsJC","executionInfo":{"status":"ok","timestamp":1707732385805,"user_tz":-210,"elapsed":21,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"r4zjaDCMMsJC","execution_count":29,"outputs":[]},{"cell_type":"code","source":["kge_model_config = KGEConfig()\n","kge_model_config.kge = RotatE\n","kge_model_config.hidden_channels = 32"],"metadata":{"id":"KEPyGw8LNBFv","executionInfo":{"status":"ok","timestamp":1707732385805,"user_tz":-210,"elapsed":21,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"id":"KEPyGw8LNBFv","execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["## Embedding"],"metadata":{"id":"LKtvRPGwT_NG"},"id":"LKtvRPGwT_NG"},{"cell_type":"code","source":["md_embed = get_kge_pair_embedd_for_training_data(kge_model_config, kge_optimizer_config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2Qz4EGMOrrk","executionInfo":{"status":"ok","timestamp":1707732772613,"user_tz":-210,"elapsed":386829,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"b7199ab3-d615-4c23-9cea-55282dbe26b2"},"id":"r2Qz4EGMOrrk","execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-12 10:06:25,616 [INFO] Calling get_node2vec_pair_embedd on cpu device ...\n","2024-02-12 10:06:25,621 [INFO] Calling get_homogeneous_graph\n","2024-02-12 10:06:27,402 [INFO] homogeneous data : Data(x=[66911, 1], edge_index=[2, 633662])\n","2024-02-12 10:06:27,410 [INFO] Calling get_kge_embedd on cpu device ...\n","2024-02-12 10:06:27,413 [INFO] Calling get_knowledge_graph\n","2024-02-12 10:06:28,568 [INFO] knowledge graph data : Data(num_nodes=66911, edge_index=[2, 633662], edge_type=[633662])\n","2024-02-12 10:06:28,573 [INFO] Setting num relations and num nodes for kge config to 39 and 66911\n","2024-02-12 10:06:28,577 [INFO] Creating KGE model ...\n","2024-02-12 10:06:28,579 [INFO] Initialing MDATransE with model_config {'model_name': None}\n","2024-02-12 10:06:28,647 [INFO] Training KGE ...\n","2024-02-12 10:06:28,649 [INFO] Running KGETrainer with Optimizer for Graph Auto Encoder\n","2024-02-12 10:06:28,651 [INFO] Creating <class 'torch.optim.adam.Adam'> with lr : 0.01\n","2024-02-12 10:06:28,654 [INFO] moving model to cpu\n","2024-02-12 10:07:12,314 [INFO] Epoch: 001, Loss: 0.5503\n","2024-02-12 10:07:50,079 [INFO] Epoch: 002, Loss: 0.4096\n","2024-02-12 10:08:28,619 [INFO] Epoch: 003, Loss: 0.3456\n","2024-02-12 10:09:07,023 [INFO] Epoch: 004, Loss: 0.3142\n","2024-02-12 10:09:44,042 [INFO] Epoch: 005, Loss: 0.3037\n","2024-02-12 10:10:21,643 [INFO] Epoch: 006, Loss: 0.2996\n","2024-02-12 10:10:59,217 [INFO] Epoch: 007, Loss: 0.2969\n","2024-02-12 10:11:36,535 [INFO] Epoch: 008, Loss: 0.2948\n","2024-02-12 10:12:14,313 [INFO] Epoch: 009, Loss: 0.2938\n","2024-02-12 10:12:52,074 [INFO] Epoch: 010, Loss: 0.2923\n","2024-02-12 10:12:52,076 [INFO] Result on Train Data : {'AUC': 0, 'ACC': 0, 'F1 Score': 0, 'AUPR': 0, 'Loss': 0.29230304201830154}\n","2024-02-12 10:12:52,078 [INFO] loss of KGE model : 0.29230304201830154\n","2024-02-12 10:12:52,100 [INFO] node embedding shape : torch.Size([66911, 32])\n","2024-02-12 10:12:52,104 [INFO] disease embedding shape : torch.Size([898, 32])\n","2024-02-12 10:12:52,107 [INFO] microbe embedding shape : torch.Size([898, 32])\n","2024-02-12 10:12:52,109 [INFO] microbe disease combination embedding shape : torch.Size([898, 64])\n"]}]},{"cell_type":"markdown","source":["# Classification"],"metadata":{"id":"T_hIMihJMts8"},"id":"T_hIMihJMts8"},{"cell_type":"markdown","source":["## Data"],"metadata":{"id":"ocxVXIz1MqLJ"},"id":"ocxVXIz1MqLJ"},{"cell_type":"code","source":["associations = get_associations()\n","y = torch.tensor(associations['increased'].tolist(), dtype=torch.float32).reshape(-1, 1).to(device)"],"metadata":{"id":"jEfB8KA7gPx2","executionInfo":{"status":"ok","timestamp":1707732772613,"user_tz":-210,"elapsed":12,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":32,"outputs":[],"id":"jEfB8KA7gPx2"},{"cell_type":"code","source":["# Train Test Split\n","train_indices, test_indices = train_test_sampler(y.shape[0], 0.7)\n","\n","data = SimplePytorchData(md_embed, y)\n","train_data = SimplePytorchData(md_embed[train_indices], y[train_indices])\n","test_data = SimplePytorchData(md_embed[test_indices], y[test_indices])"],"metadata":{"id":"DNdQlgzMMtHN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707732772613,"user_tz":-210,"elapsed":11,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"166ea7bc-d8f7-4c62-e336-59f0c128c0d0"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-12 10:12:52,144 [INFO] Initializing SimplePytorchData with X shape : torch.Size([898, 64]) and y shape : torch.Size([898, 1])\n","2024-02-12 10:12:52,150 [INFO] Initializing SimplePytorchData with X shape : torch.Size([628, 64]) and y shape : torch.Size([628, 1])\n","2024-02-12 10:12:52,152 [INFO] Initializing SimplePytorchData with X shape : torch.Size([270, 64]) and y shape : torch.Size([270, 1])\n"]}],"id":"DNdQlgzMMtHN"},{"cell_type":"markdown","source":["## Classifier"],"metadata":{"id":"ye_6wl6nxmhs"},"id":"ye_6wl6nxmhs"},{"cell_type":"code","source":["simple_classifier_config = SimpleClassifierConfig()\n","simple_classifier_config.model_name = \"simple classifier\"\n","simple_classifier_config.input_dim = md_embed.shape[1]\n","simple_classifier_config.hidden_dim = 32\n","simple_classifier_config.output_dim = 1\n","simple_classifier_config.num_layers = 2\n","simple_classifier_config.dropout = 0.1"],"metadata":{"id":"BFTQsCl8M9bv","executionInfo":{"status":"ok","timestamp":1707732772613,"user_tz":-210,"elapsed":9,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":34,"outputs":[],"id":"BFTQsCl8M9bv"},{"cell_type":"code","source":["mda_classifier = SimpleMDAClassifier(simple_classifier_config)"],"metadata":{"id":"1ciyBQ4QM_0U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707732772613,"user_tz":-210,"elapsed":9,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"70b85de0-7e27-4260-fd1c-a80b810094d8"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-12 10:12:52,172 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-12 10:12:52,176 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n"]}],"id":"1ciyBQ4QM_0U"},{"cell_type":"markdown","source":["## Optimizer"],"metadata":{"id":"s_5cdKvOx4q5"},"id":"s_5cdKvOx4q5"},{"cell_type":"code","source":["classifier_optimizer_config = OptimizerConfig()\n","classifier_optimizer_config.optimizer = torch.optim.Adam\n","classifier_optimizer_config.criterion = torch.nn.BCEWithLogitsLoss()\n","classifier_optimizer_config.lr = 0.01\n","classifier_optimizer_config.batch_size = 32\n","classifier_optimizer_config.n_epoch = 50\n","classifier_optimizer_config.exp_name = \"adam optimizer\"\n","classifier_optimizer_config.save = False\n","classifier_optimizer_config.save_path = None\n","classifier_optimizer_config.device = device\n","classifier_optimizer_config.report_size = 10  # batch to report ratio\n","classifier_optimizer_config.threshold = 0.5"],"metadata":{"id":"3D6yhiPpNEc8","executionInfo":{"status":"ok","timestamp":1707732772613,"user_tz":-210,"elapsed":8,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":36,"outputs":[],"id":"3D6yhiPpNEc8"},{"cell_type":"markdown","source":["## Train Test Approach"],"metadata":{"id":"4iI5bMmJNQV3"},"id":"4iI5bMmJNQV3"},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"h24KnmDZNAgD"},"id":"h24KnmDZNAgD"},{"cell_type":"code","source":["train_result = SimpleTrainer().train(model=mda_classifier,\n","                                     data=train_data,\n","                                     config=classifier_optimizer_config)"],"metadata":{"id":"OqKrF7HmNFx1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707732774638,"user_tz":-210,"elapsed":2033,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"cc2b7373-eb07-4466-9881-7392d4cfef8b"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-12 10:12:52,196 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-12 10:12:52,198 [INFO] moving data and model to cpu\n","2024-02-12 10:12:52,228 [INFO] loss: 0.0212    [1,    10]\n","2024-02-12 10:12:52,247 [INFO] loss: 0.0198    [1,    20]\n","2024-02-12 10:12:52,267 [INFO] loss: 0.0199    [2,    10]\n","2024-02-12 10:12:52,289 [INFO] loss: 0.0189    [2,    20]\n","2024-02-12 10:12:52,309 [INFO] loss: 0.0199    [3,    10]\n","2024-02-12 10:12:52,328 [INFO] loss: 0.0182    [3,    20]\n","2024-02-12 10:12:52,348 [INFO] loss: 0.0182    [4,    10]\n","2024-02-12 10:12:52,367 [INFO] loss: 0.0200    [4,    20]\n","2024-02-12 10:12:52,387 [INFO] loss: 0.0190    [5,    10]\n","2024-02-12 10:12:52,408 [INFO] loss: 0.0186    [5,    20]\n","2024-02-12 10:12:52,427 [INFO] loss: 0.0187    [6,    10]\n","2024-02-12 10:12:52,446 [INFO] loss: 0.0186    [6,    20]\n","2024-02-12 10:12:52,464 [INFO] loss: 0.0188    [7,    10]\n","2024-02-12 10:12:52,482 [INFO] loss: 0.0182    [7,    20]\n","2024-02-12 10:12:52,500 [INFO] loss: 0.0184    [8,    10]\n","2024-02-12 10:12:52,518 [INFO] loss: 0.0188    [8,    20]\n","2024-02-12 10:12:52,542 [INFO] loss: 0.0179    [9,    10]\n","2024-02-12 10:12:52,566 [INFO] loss: 0.0188    [9,    20]\n","2024-02-12 10:12:52,585 [INFO] loss: 0.0177    [10,    10]\n","2024-02-12 10:12:52,605 [INFO] loss: 0.0185    [10,    20]\n","2024-02-12 10:12:52,624 [INFO] loss: 0.0182    [11,    10]\n","2024-02-12 10:12:52,645 [INFO] loss: 0.0180    [11,    20]\n","2024-02-12 10:12:52,664 [INFO] loss: 0.0176    [12,    10]\n","2024-02-12 10:12:52,685 [INFO] loss: 0.0179    [12,    20]\n","2024-02-12 10:12:52,705 [INFO] loss: 0.0174    [13,    10]\n","2024-02-12 10:12:52,725 [INFO] loss: 0.0189    [13,    20]\n","2024-02-12 10:12:52,746 [INFO] loss: 0.0175    [14,    10]\n","2024-02-12 10:12:52,766 [INFO] loss: 0.0181    [14,    20]\n","2024-02-12 10:12:52,786 [INFO] loss: 0.0174    [15,    10]\n","2024-02-12 10:12:52,805 [INFO] loss: 0.0176    [15,    20]\n","2024-02-12 10:12:52,826 [INFO] loss: 0.0175    [16,    10]\n","2024-02-12 10:12:52,845 [INFO] loss: 0.0175    [16,    20]\n","2024-02-12 10:12:52,868 [INFO] loss: 0.0176    [17,    10]\n","2024-02-12 10:12:52,887 [INFO] loss: 0.0174    [17,    20]\n","2024-02-12 10:12:52,905 [INFO] loss: 0.0176    [18,    10]\n","2024-02-12 10:12:52,925 [INFO] loss: 0.0169    [18,    20]\n","2024-02-12 10:12:52,948 [INFO] loss: 0.0169    [19,    10]\n","2024-02-12 10:12:52,976 [INFO] loss: 0.0170    [19,    20]\n","2024-02-12 10:12:52,994 [INFO] loss: 0.0160    [20,    10]\n","2024-02-12 10:12:53,014 [INFO] loss: 0.0174    [20,    20]\n","2024-02-12 10:12:53,033 [INFO] loss: 0.0158    [21,    10]\n","2024-02-12 10:12:53,052 [INFO] loss: 0.0180    [21,    20]\n","2024-02-12 10:12:53,075 [INFO] loss: 0.0174    [22,    10]\n","2024-02-12 10:12:53,093 [INFO] loss: 0.0171    [22,    20]\n","2024-02-12 10:12:53,115 [INFO] loss: 0.0174    [23,    10]\n","2024-02-12 10:12:53,133 [INFO] loss: 0.0164    [23,    20]\n","2024-02-12 10:12:53,151 [INFO] loss: 0.0171    [24,    10]\n","2024-02-12 10:12:53,179 [INFO] loss: 0.0163    [24,    20]\n","2024-02-12 10:12:53,197 [INFO] loss: 0.0167    [25,    10]\n","2024-02-12 10:12:53,216 [INFO] loss: 0.0178    [25,    20]\n","2024-02-12 10:12:53,238 [INFO] loss: 0.0170    [26,    10]\n","2024-02-12 10:12:53,257 [INFO] loss: 0.0166    [26,    20]\n","2024-02-12 10:12:53,275 [INFO] loss: 0.0168    [27,    10]\n","2024-02-12 10:12:53,296 [INFO] loss: 0.0172    [27,    20]\n","2024-02-12 10:12:53,316 [INFO] loss: 0.0170    [28,    10]\n","2024-02-12 10:12:53,335 [INFO] loss: 0.0165    [28,    20]\n","2024-02-12 10:12:53,354 [INFO] loss: 0.0161    [29,    10]\n","2024-02-12 10:12:53,400 [INFO] loss: 0.0169    [29,    20]\n","2024-02-12 10:12:53,440 [INFO] loss: 0.0164    [30,    10]\n","2024-02-12 10:12:53,468 [INFO] loss: 0.0163    [30,    20]\n","2024-02-12 10:12:53,492 [INFO] loss: 0.0156    [31,    10]\n","2024-02-12 10:12:53,516 [INFO] loss: 0.0174    [31,    20]\n","2024-02-12 10:12:53,542 [INFO] loss: 0.0157    [32,    10]\n","2024-02-12 10:12:53,571 [INFO] loss: 0.0168    [32,    20]\n","2024-02-12 10:12:53,595 [INFO] loss: 0.0162    [33,    10]\n","2024-02-12 10:12:53,622 [INFO] loss: 0.0158    [33,    20]\n","2024-02-12 10:12:53,654 [INFO] loss: 0.0164    [34,    10]\n","2024-02-12 10:12:53,683 [INFO] loss: 0.0160    [34,    20]\n","2024-02-12 10:12:53,710 [INFO] loss: 0.0156    [35,    10]\n","2024-02-12 10:12:53,735 [INFO] loss: 0.0177    [35,    20]\n","2024-02-12 10:12:53,771 [INFO] loss: 0.0156    [36,    10]\n","2024-02-12 10:12:53,806 [INFO] loss: 0.0173    [36,    20]\n","2024-02-12 10:12:53,841 [INFO] loss: 0.0167    [37,    10]\n","2024-02-12 10:12:53,884 [INFO] loss: 0.0159    [37,    20]\n","2024-02-12 10:12:53,912 [INFO] loss: 0.0150    [38,    10]\n","2024-02-12 10:12:53,931 [INFO] loss: 0.0160    [38,    20]\n","2024-02-12 10:12:53,950 [INFO] loss: 0.0153    [39,    10]\n","2024-02-12 10:12:53,970 [INFO] loss: 0.0161    [39,    20]\n","2024-02-12 10:12:53,996 [INFO] loss: 0.0156    [40,    10]\n","2024-02-12 10:12:54,020 [INFO] loss: 0.0157    [40,    20]\n","2024-02-12 10:12:54,042 [INFO] loss: 0.0163    [41,    10]\n","2024-02-12 10:12:54,060 [INFO] loss: 0.0145    [41,    20]\n","2024-02-12 10:12:54,079 [INFO] loss: 0.0154    [42,    10]\n","2024-02-12 10:12:54,098 [INFO] loss: 0.0154    [42,    20]\n","2024-02-12 10:12:54,119 [INFO] loss: 0.0149    [43,    10]\n","2024-02-12 10:12:54,138 [INFO] loss: 0.0159    [43,    20]\n","2024-02-12 10:12:54,167 [INFO] loss: 0.0155    [44,    10]\n","2024-02-12 10:12:54,190 [INFO] loss: 0.0154    [44,    20]\n","2024-02-12 10:12:54,214 [INFO] loss: 0.0157    [45,    10]\n","2024-02-12 10:12:54,237 [INFO] loss: 0.0147    [45,    20]\n","2024-02-12 10:12:54,257 [INFO] loss: 0.0150    [46,    10]\n","2024-02-12 10:12:54,281 [INFO] loss: 0.0156    [46,    20]\n","2024-02-12 10:12:54,307 [INFO] loss: 0.0149    [47,    10]\n","2024-02-12 10:12:54,328 [INFO] loss: 0.0158    [47,    20]\n","2024-02-12 10:12:54,349 [INFO] loss: 0.0162    [48,    10]\n","2024-02-12 10:12:54,383 [INFO] loss: 0.0155    [48,    20]\n","2024-02-12 10:12:54,403 [INFO] loss: 0.0151    [49,    10]\n","2024-02-12 10:12:54,421 [INFO] loss: 0.0150    [49,    20]\n","2024-02-12 10:12:54,441 [INFO] loss: 0.0150    [50,    10]\n","2024-02-12 10:12:54,462 [INFO] loss: 0.0152    [50,    20]\n","2024-02-12 10:12:54,502 [INFO] Result on Train Data : {'AUC': 0.8818618051962546, 'ACC': 0.7468152866242038, 'F1 Score': 0.7356615476660057, 'AUPR': 0, 'Loss': 0.4565255373716354}\n"]}],"id":"OqKrF7HmNFx1"},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"0eQGNWm_NMVG"},"id":"0eQGNWm_NMVG"},{"cell_type":"code","source":["test_result = SimpleTester().test(model=mda_classifier,\n","                                  data=test_data,\n","                                  config=classifier_optimizer_config)"],"metadata":{"id":"U05mXL_fNHpG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707732775073,"user_tz":-210,"elapsed":441,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"bcf947cc-caf5-45d6-e1a8-7c0b50b161a8"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-12 10:12:54,514 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-12 10:12:54,517 [INFO] moving data and model to cpu\n","2024-02-12 10:12:54,548 [INFO] Result on Test Data : {'AUC': 0.8575034293552812, 'ACC': 0.7222222222222222, 'F1 Score': 0.7119446933811291, 'AUPR': 0, 'Loss': 0.5303164654307895}\n"]}],"id":"U05mXL_fNHpG"},{"cell_type":"code","source":["test_result.get_result()"],"metadata":{"id":"oqgiZQqRWWGF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707732775073,"user_tz":-210,"elapsed":9,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"3eecef4f-0a83-4d22-9a90-199ceab5d13a"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'AUC': 0.8575034293552812,\n"," 'ACC': 0.7222222222222222,\n"," 'F1 Score': 0.7119446933811291,\n"," 'AUPR': 0,\n"," 'Loss': 0.5303164654307895}"]},"metadata":{},"execution_count":39}],"id":"oqgiZQqRWWGF"},{"cell_type":"markdown","source":["## Cross Validation"],"metadata":{"id":"ti8vEX_cNNwy"},"id":"ti8vEX_cNNwy"},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707732793308,"user_tz":-210,"elapsed":18242,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}},"outputId":"3689ae51-b9d9-40e2-f014-7c4ff47c1eb4","id":"sfI286uv6o-e"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-12 10:12:54,572 [INFO] Initializing SimpleMDAClassifierFactory with model : simple classifier\n","2024-02-12 10:12:54,574 [INFO] Initializing SimplePytorchDataTrainTestSplit\n","2024-02-12 10:12:54,578 [INFO] Start 5-fold Cross Validation with config : adam optimizer\n","2024-02-12 10:12:54,580 [INFO] ---- Fold 1 ----\n","2024-02-12 10:12:54,583 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-12 10:12:54,586 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-12 10:12:54,587 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-12 10:12:54,589 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-12 10:12:54,591 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-12 10:12:54,593 [INFO] moving data and model to cpu\n","2024-02-12 10:12:54,624 [INFO] loss: 0.0210    [1,    10]\n","2024-02-12 10:12:54,644 [INFO] loss: 0.0193    [1,    20]\n","2024-02-12 10:12:54,674 [INFO] loss: 0.0193    [2,    10]\n","2024-02-12 10:12:54,694 [INFO] loss: 0.0189    [2,    20]\n","2024-02-12 10:12:54,722 [INFO] loss: 0.0196    [3,    10]\n","2024-02-12 10:12:54,740 [INFO] loss: 0.0177    [3,    20]\n","2024-02-12 10:12:54,763 [INFO] loss: 0.0175    [4,    10]\n","2024-02-12 10:12:54,788 [INFO] loss: 0.0198    [4,    20]\n","2024-02-12 10:12:54,810 [INFO] loss: 0.0178    [5,    10]\n","2024-02-12 10:12:54,829 [INFO] loss: 0.0183    [5,    20]\n","2024-02-12 10:12:54,852 [INFO] loss: 0.0179    [6,    10]\n","2024-02-12 10:12:54,871 [INFO] loss: 0.0187    [6,    20]\n","2024-02-12 10:12:54,894 [INFO] loss: 0.0187    [7,    10]\n","2024-02-12 10:12:54,912 [INFO] loss: 0.0172    [7,    20]\n","2024-02-12 10:12:54,935 [INFO] loss: 0.0188    [8,    10]\n","2024-02-12 10:12:54,954 [INFO] loss: 0.0181    [8,    20]\n","2024-02-12 10:12:54,982 [INFO] loss: 0.0178    [9,    10]\n","2024-02-12 10:12:55,001 [INFO] loss: 0.0185    [9,    20]\n","2024-02-12 10:12:55,024 [INFO] loss: 0.0178    [10,    10]\n","2024-02-12 10:12:55,047 [INFO] loss: 0.0180    [10,    20]\n","2024-02-12 10:12:55,079 [INFO] loss: 0.0188    [11,    10]\n","2024-02-12 10:12:55,097 [INFO] loss: 0.0180    [11,    20]\n","2024-02-12 10:12:55,122 [INFO] loss: 0.0189    [12,    10]\n","2024-02-12 10:12:55,141 [INFO] loss: 0.0176    [12,    20]\n","2024-02-12 10:12:55,165 [INFO] loss: 0.0177    [13,    10]\n","2024-02-12 10:12:55,185 [INFO] loss: 0.0179    [13,    20]\n","2024-02-12 10:12:55,214 [INFO] loss: 0.0175    [14,    10]\n","2024-02-12 10:12:55,233 [INFO] loss: 0.0182    [14,    20]\n","2024-02-12 10:12:55,261 [INFO] loss: 0.0175    [15,    10]\n","2024-02-12 10:12:55,281 [INFO] loss: 0.0183    [15,    20]\n","2024-02-12 10:12:55,307 [INFO] loss: 0.0174    [16,    10]\n","2024-02-12 10:12:55,329 [INFO] loss: 0.0178    [16,    20]\n","2024-02-12 10:12:55,351 [INFO] loss: 0.0179    [17,    10]\n","2024-02-12 10:12:55,370 [INFO] loss: 0.0173    [17,    20]\n","2024-02-12 10:12:55,392 [INFO] loss: 0.0173    [18,    10]\n","2024-02-12 10:12:55,411 [INFO] loss: 0.0177    [18,    20]\n","2024-02-12 10:12:55,434 [INFO] loss: 0.0167    [19,    10]\n","2024-02-12 10:12:55,452 [INFO] loss: 0.0184    [19,    20]\n","2024-02-12 10:12:55,480 [INFO] loss: 0.0174    [20,    10]\n","2024-02-12 10:12:55,498 [INFO] loss: 0.0178    [20,    20]\n","2024-02-12 10:12:55,520 [INFO] loss: 0.0175    [21,    10]\n","2024-02-12 10:12:55,540 [INFO] loss: 0.0171    [21,    20]\n","2024-02-12 10:12:55,563 [INFO] loss: 0.0172    [22,    10]\n","2024-02-12 10:12:55,587 [INFO] loss: 0.0170    [22,    20]\n","2024-02-12 10:12:55,610 [INFO] loss: 0.0168    [23,    10]\n","2024-02-12 10:12:55,629 [INFO] loss: 0.0184    [23,    20]\n","2024-02-12 10:12:55,653 [INFO] loss: 0.0163    [24,    10]\n","2024-02-12 10:12:55,673 [INFO] loss: 0.0181    [24,    20]\n","2024-02-12 10:12:55,697 [INFO] loss: 0.0172    [25,    10]\n","2024-02-12 10:12:55,729 [INFO] loss: 0.0173    [25,    20]\n","2024-02-12 10:12:55,772 [INFO] loss: 0.0174    [26,    10]\n","2024-02-12 10:12:55,800 [INFO] loss: 0.0164    [26,    20]\n","2024-02-12 10:12:55,838 [INFO] loss: 0.0166    [27,    10]\n","2024-02-12 10:12:55,863 [INFO] loss: 0.0171    [27,    20]\n","2024-02-12 10:12:55,896 [INFO] loss: 0.0160    [28,    10]\n","2024-02-12 10:12:55,922 [INFO] loss: 0.0173    [28,    20]\n","2024-02-12 10:12:55,954 [INFO] loss: 0.0166    [29,    10]\n","2024-02-12 10:12:55,983 [INFO] loss: 0.0168    [29,    20]\n","2024-02-12 10:12:56,020 [INFO] loss: 0.0162    [30,    10]\n","2024-02-12 10:12:56,053 [INFO] loss: 0.0168    [30,    20]\n","2024-02-12 10:12:56,095 [INFO] loss: 0.0161    [31,    10]\n","2024-02-12 10:12:56,140 [INFO] loss: 0.0170    [31,    20]\n","2024-02-12 10:12:56,181 [INFO] loss: 0.0162    [32,    10]\n","2024-02-12 10:12:56,201 [INFO] loss: 0.0167    [32,    20]\n","2024-02-12 10:12:56,240 [INFO] loss: 0.0156    [33,    10]\n","2024-02-12 10:12:56,274 [INFO] loss: 0.0164    [33,    20]\n","2024-02-12 10:12:56,310 [INFO] loss: 0.0161    [34,    10]\n","2024-02-12 10:12:56,336 [INFO] loss: 0.0155    [34,    20]\n","2024-02-12 10:12:56,372 [INFO] loss: 0.0161    [35,    10]\n","2024-02-12 10:12:56,397 [INFO] loss: 0.0161    [35,    20]\n","2024-02-12 10:12:56,428 [INFO] loss: 0.0160    [36,    10]\n","2024-02-12 10:12:56,453 [INFO] loss: 0.0172    [36,    20]\n","2024-02-12 10:12:56,487 [INFO] loss: 0.0162    [37,    10]\n","2024-02-12 10:12:56,516 [INFO] loss: 0.0160    [37,    20]\n","2024-02-12 10:12:56,547 [INFO] loss: 0.0159    [38,    10]\n","2024-02-12 10:12:56,573 [INFO] loss: 0.0164    [38,    20]\n","2024-02-12 10:12:56,604 [INFO] loss: 0.0155    [39,    10]\n","2024-02-12 10:12:56,633 [INFO] loss: 0.0152    [39,    20]\n","2024-02-12 10:12:56,667 [INFO] loss: 0.0161    [40,    10]\n","2024-02-12 10:12:56,700 [INFO] loss: 0.0150    [40,    20]\n","2024-02-12 10:12:56,740 [INFO] loss: 0.0165    [41,    10]\n","2024-02-12 10:12:56,765 [INFO] loss: 0.0164    [41,    20]\n","2024-02-12 10:12:56,809 [INFO] loss: 0.0153    [42,    10]\n","2024-02-12 10:12:56,842 [INFO] loss: 0.0166    [42,    20]\n","2024-02-12 10:12:56,880 [INFO] loss: 0.0155    [43,    10]\n","2024-02-12 10:12:56,908 [INFO] loss: 0.0165    [43,    20]\n","2024-02-12 10:12:56,945 [INFO] loss: 0.0154    [44,    10]\n","2024-02-12 10:12:56,972 [INFO] loss: 0.0152    [44,    20]\n","2024-02-12 10:12:57,002 [INFO] loss: 0.0155    [45,    10]\n","2024-02-12 10:12:57,027 [INFO] loss: 0.0159    [45,    20]\n","2024-02-12 10:12:57,056 [INFO] loss: 0.0147    [46,    10]\n","2024-02-12 10:12:57,080 [INFO] loss: 0.0158    [46,    20]\n","2024-02-12 10:12:57,109 [INFO] loss: 0.0150    [47,    10]\n","2024-02-12 10:12:57,142 [INFO] loss: 0.0151    [47,    20]\n","2024-02-12 10:12:57,190 [INFO] loss: 0.0140    [48,    10]\n","2024-02-12 10:12:57,221 [INFO] loss: 0.0154    [48,    20]\n","2024-02-12 10:12:57,250 [INFO] loss: 0.0142    [49,    10]\n","2024-02-12 10:12:57,293 [INFO] loss: 0.0158    [49,    20]\n","2024-02-12 10:12:57,335 [INFO] loss: 0.0156    [50,    10]\n","2024-02-12 10:12:57,358 [INFO] loss: 0.0146    [50,    20]\n","2024-02-12 10:12:57,438 [INFO] Result on Train Data : {'AUC': 0.8839146116812954, 'ACC': 0.7746870653685675, 'F1 Score': 0.7728304624602134, 'AUPR': 0, 'Loss': 0.4470475471538046}\n","2024-02-12 10:12:57,441 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-12 10:12:57,443 [INFO] moving data and model to cpu\n","2024-02-12 10:12:57,476 [INFO] Result on Test Data : {'AUC': 0.7871485943775101, 'ACC': 0.7039106145251397, 'F1 Score': 0.6964839875867805, 'AUPR': 0, 'Loss': 0.641465812921524}\n","2024-02-12 10:12:57,479 [INFO] Result of fold 1 : {'AUC': 0.7871485943775101, 'ACC': 0.7039106145251397, 'F1 Score': 0.6964839875867805, 'AUPR': 0, 'Loss': 0.641465812921524}\n","2024-02-12 10:12:57,481 [INFO] ---- Fold 2 ----\n","2024-02-12 10:12:57,484 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-12 10:12:57,487 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-12 10:12:57,489 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-12 10:12:57,491 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-12 10:12:57,494 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-12 10:12:57,494 [INFO] moving data and model to cpu\n","2024-02-12 10:12:57,524 [INFO] loss: 0.0202    [1,    10]\n","2024-02-12 10:12:57,548 [INFO] loss: 0.0207    [1,    20]\n","2024-02-12 10:12:57,579 [INFO] loss: 0.0192    [2,    10]\n","2024-02-12 10:12:57,602 [INFO] loss: 0.0180    [2,    20]\n","2024-02-12 10:12:57,632 [INFO] loss: 0.0186    [3,    10]\n","2024-02-12 10:12:57,656 [INFO] loss: 0.0192    [3,    20]\n","2024-02-12 10:12:57,684 [INFO] loss: 0.0195    [4,    10]\n","2024-02-12 10:12:57,709 [INFO] loss: 0.0180    [4,    20]\n","2024-02-12 10:12:57,739 [INFO] loss: 0.0186    [5,    10]\n","2024-02-12 10:12:57,762 [INFO] loss: 0.0178    [5,    20]\n","2024-02-12 10:12:57,795 [INFO] loss: 0.0190    [6,    10]\n","2024-02-12 10:12:57,818 [INFO] loss: 0.0182    [6,    20]\n","2024-02-12 10:12:57,846 [INFO] loss: 0.0178    [7,    10]\n","2024-02-12 10:12:57,868 [INFO] loss: 0.0186    [7,    20]\n","2024-02-12 10:12:57,896 [INFO] loss: 0.0186    [8,    10]\n","2024-02-12 10:12:57,918 [INFO] loss: 0.0182    [8,    20]\n","2024-02-12 10:12:57,947 [INFO] loss: 0.0180    [9,    10]\n","2024-02-12 10:12:57,969 [INFO] loss: 0.0182    [9,    20]\n","2024-02-12 10:12:58,001 [INFO] loss: 0.0182    [10,    10]\n","2024-02-12 10:12:58,025 [INFO] loss: 0.0192    [10,    20]\n","2024-02-12 10:12:58,056 [INFO] loss: 0.0181    [11,    10]\n","2024-02-12 10:12:58,078 [INFO] loss: 0.0180    [11,    20]\n","2024-02-12 10:12:58,108 [INFO] loss: 0.0157    [12,    10]\n","2024-02-12 10:12:58,133 [INFO] loss: 0.0196    [12,    20]\n","2024-02-12 10:12:58,161 [INFO] loss: 0.0184    [13,    10]\n","2024-02-12 10:12:58,184 [INFO] loss: 0.0168    [13,    20]\n","2024-02-12 10:12:58,215 [INFO] loss: 0.0179    [14,    10]\n","2024-02-12 10:12:58,241 [INFO] loss: 0.0184    [14,    20]\n","2024-02-12 10:12:58,273 [INFO] loss: 0.0180    [15,    10]\n","2024-02-12 10:12:58,299 [INFO] loss: 0.0180    [15,    20]\n","2024-02-12 10:12:58,328 [INFO] loss: 0.0183    [16,    10]\n","2024-02-12 10:12:58,366 [INFO] loss: 0.0173    [16,    20]\n","2024-02-12 10:12:58,412 [INFO] loss: 0.0176    [17,    10]\n","2024-02-12 10:12:58,492 [INFO] loss: 0.0180    [17,    20]\n","2024-02-12 10:12:58,603 [INFO] loss: 0.0169    [18,    10]\n","2024-02-12 10:12:58,687 [INFO] loss: 0.0183    [18,    20]\n","2024-02-12 10:12:58,805 [INFO] loss: 0.0170    [19,    10]\n","2024-02-12 10:12:58,927 [INFO] loss: 0.0177    [19,    20]\n","2024-02-12 10:12:59,027 [INFO] loss: 0.0167    [20,    10]\n","2024-02-12 10:12:59,094 [INFO] loss: 0.0184    [20,    20]\n","2024-02-12 10:12:59,163 [INFO] loss: 0.0178    [21,    10]\n","2024-02-12 10:12:59,225 [INFO] loss: 0.0169    [21,    20]\n","2024-02-12 10:12:59,289 [INFO] loss: 0.0159    [22,    10]\n","2024-02-12 10:12:59,395 [INFO] loss: 0.0181    [22,    20]\n","2024-02-12 10:12:59,479 [INFO] loss: 0.0174    [23,    10]\n","2024-02-12 10:12:59,554 [INFO] loss: 0.0179    [23,    20]\n","2024-02-12 10:12:59,668 [INFO] loss: 0.0167    [24,    10]\n","2024-02-12 10:12:59,738 [INFO] loss: 0.0178    [24,    20]\n","2024-02-12 10:12:59,816 [INFO] loss: 0.0179    [25,    10]\n","2024-02-12 10:12:59,865 [INFO] loss: 0.0180    [25,    20]\n","2024-02-12 10:12:59,975 [INFO] loss: 0.0171    [26,    10]\n","2024-02-12 10:13:00,064 [INFO] loss: 0.0170    [26,    20]\n","2024-02-12 10:13:00,169 [INFO] loss: 0.0160    [27,    10]\n","2024-02-12 10:13:00,239 [INFO] loss: 0.0176    [27,    20]\n","2024-02-12 10:13:00,330 [INFO] loss: 0.0170    [28,    10]\n","2024-02-12 10:13:00,405 [INFO] loss: 0.0167    [28,    20]\n","2024-02-12 10:13:00,522 [INFO] loss: 0.0173    [29,    10]\n","2024-02-12 10:13:00,604 [INFO] loss: 0.0165    [29,    20]\n","2024-02-12 10:13:00,682 [INFO] loss: 0.0163    [30,    10]\n","2024-02-12 10:13:00,768 [INFO] loss: 0.0168    [30,    20]\n","2024-02-12 10:13:00,808 [INFO] loss: 0.0163    [31,    10]\n","2024-02-12 10:13:00,881 [INFO] loss: 0.0166    [31,    20]\n","2024-02-12 10:13:00,956 [INFO] loss: 0.0160    [32,    10]\n","2024-02-12 10:13:01,030 [INFO] loss: 0.0167    [32,    20]\n","2024-02-12 10:13:01,152 [INFO] loss: 0.0168    [33,    10]\n","2024-02-12 10:13:01,282 [INFO] loss: 0.0157    [33,    20]\n","2024-02-12 10:13:01,389 [INFO] loss: 0.0160    [34,    10]\n","2024-02-12 10:13:01,439 [INFO] loss: 0.0165    [34,    20]\n","2024-02-12 10:13:01,477 [INFO] loss: 0.0166    [35,    10]\n","2024-02-12 10:13:01,529 [INFO] loss: 0.0170    [35,    20]\n","2024-02-12 10:13:01,571 [INFO] loss: 0.0157    [36,    10]\n","2024-02-12 10:13:01,626 [INFO] loss: 0.0168    [36,    20]\n","2024-02-12 10:13:01,730 [INFO] loss: 0.0147    [37,    10]\n","2024-02-12 10:13:01,788 [INFO] loss: 0.0177    [37,    20]\n","2024-02-12 10:13:01,848 [INFO] loss: 0.0159    [38,    10]\n","2024-02-12 10:13:01,874 [INFO] loss: 0.0161    [38,    20]\n","2024-02-12 10:13:01,909 [INFO] loss: 0.0170    [39,    10]\n","2024-02-12 10:13:01,936 [INFO] loss: 0.0158    [39,    20]\n","2024-02-12 10:13:01,967 [INFO] loss: 0.0158    [40,    10]\n","2024-02-12 10:13:02,036 [INFO] loss: 0.0152    [40,    20]\n","2024-02-12 10:13:02,082 [INFO] loss: 0.0146    [41,    10]\n","2024-02-12 10:13:02,108 [INFO] loss: 0.0166    [41,    20]\n","2024-02-12 10:13:02,147 [INFO] loss: 0.0150    [42,    10]\n","2024-02-12 10:13:02,182 [INFO] loss: 0.0164    [42,    20]\n","2024-02-12 10:13:02,218 [INFO] loss: 0.0162    [43,    10]\n","2024-02-12 10:13:02,262 [INFO] loss: 0.0161    [43,    20]\n","2024-02-12 10:13:02,296 [INFO] loss: 0.0152    [44,    10]\n","2024-02-12 10:13:02,326 [INFO] loss: 0.0154    [44,    20]\n","2024-02-12 10:13:02,412 [INFO] loss: 0.0155    [45,    10]\n","2024-02-12 10:13:02,440 [INFO] loss: 0.0154    [45,    20]\n","2024-02-12 10:13:02,485 [INFO] loss: 0.0157    [46,    10]\n","2024-02-12 10:13:02,515 [INFO] loss: 0.0149    [46,    20]\n","2024-02-12 10:13:02,590 [INFO] loss: 0.0140    [47,    10]\n","2024-02-12 10:13:02,637 [INFO] loss: 0.0151    [47,    20]\n","2024-02-12 10:13:02,683 [INFO] loss: 0.0151    [48,    10]\n","2024-02-12 10:13:02,717 [INFO] loss: 0.0153    [48,    20]\n","2024-02-12 10:13:02,751 [INFO] loss: 0.0151    [49,    10]\n","2024-02-12 10:13:02,775 [INFO] loss: 0.0151    [49,    20]\n","2024-02-12 10:13:02,805 [INFO] loss: 0.0137    [50,    10]\n","2024-02-12 10:13:02,829 [INFO] loss: 0.0162    [50,    20]\n","2024-02-12 10:13:02,919 [INFO] Result on Train Data : {'AUC': 0.88967641096272, 'ACC': 0.760778859527121, 'F1 Score': 0.7538063385889473, 'AUPR': 0, 'Loss': 0.4832073048405025}\n","2024-02-12 10:13:02,928 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-12 10:13:02,930 [INFO] moving data and model to cpu\n","2024-02-12 10:13:02,968 [INFO] Result on Test Data : {'AUC': 0.7451298701298701, 'ACC': 0.6703910614525139, 'F1 Score': 0.662123684294718, 'AUPR': 0, 'Loss': 0.6441898792982101}\n","2024-02-12 10:13:02,971 [INFO] Result of fold 2 : {'AUC': 0.7451298701298701, 'ACC': 0.6703910614525139, 'F1 Score': 0.662123684294718, 'AUPR': 0, 'Loss': 0.6441898792982101}\n","2024-02-12 10:13:02,973 [INFO] ---- Fold 3 ----\n","2024-02-12 10:13:02,977 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-12 10:13:02,989 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-12 10:13:02,992 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-12 10:13:02,996 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-12 10:13:03,003 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-12 10:13:03,005 [INFO] moving data and model to cpu\n","2024-02-12 10:13:03,042 [INFO] loss: 0.0205    [1,    10]\n","2024-02-12 10:13:03,070 [INFO] loss: 0.0203    [1,    20]\n","2024-02-12 10:13:03,105 [INFO] loss: 0.0182    [2,    10]\n","2024-02-12 10:13:03,133 [INFO] loss: 0.0189    [2,    20]\n","2024-02-12 10:13:03,168 [INFO] loss: 0.0189    [3,    10]\n","2024-02-12 10:13:03,207 [INFO] loss: 0.0175    [3,    20]\n","2024-02-12 10:13:03,250 [INFO] loss: 0.0185    [4,    10]\n","2024-02-12 10:13:03,280 [INFO] loss: 0.0190    [4,    20]\n","2024-02-12 10:13:03,317 [INFO] loss: 0.0181    [5,    10]\n","2024-02-12 10:13:03,350 [INFO] loss: 0.0186    [5,    20]\n","2024-02-12 10:13:03,403 [INFO] loss: 0.0186    [6,    10]\n","2024-02-12 10:13:03,435 [INFO] loss: 0.0182    [6,    20]\n","2024-02-12 10:13:03,473 [INFO] loss: 0.0172    [7,    10]\n","2024-02-12 10:13:03,506 [INFO] loss: 0.0191    [7,    20]\n","2024-02-12 10:13:03,544 [INFO] loss: 0.0188    [8,    10]\n","2024-02-12 10:13:03,578 [INFO] loss: 0.0175    [8,    20]\n","2024-02-12 10:13:03,637 [INFO] loss: 0.0181    [9,    10]\n","2024-02-12 10:13:03,668 [INFO] loss: 0.0177    [9,    20]\n","2024-02-12 10:13:03,704 [INFO] loss: 0.0181    [10,    10]\n","2024-02-12 10:13:03,734 [INFO] loss: 0.0181    [10,    20]\n","2024-02-12 10:13:03,771 [INFO] loss: 0.0178    [11,    10]\n","2024-02-12 10:13:03,809 [INFO] loss: 0.0180    [11,    20]\n","2024-02-12 10:13:03,852 [INFO] loss: 0.0173    [12,    10]\n","2024-02-12 10:13:03,888 [INFO] loss: 0.0182    [12,    20]\n","2024-02-12 10:13:03,926 [INFO] loss: 0.0181    [13,    10]\n","2024-02-12 10:13:03,957 [INFO] loss: 0.0172    [13,    20]\n","2024-02-12 10:13:03,993 [INFO] loss: 0.0178    [14,    10]\n","2024-02-12 10:13:04,025 [INFO] loss: 0.0177    [14,    20]\n","2024-02-12 10:13:04,068 [INFO] loss: 0.0185    [15,    10]\n","2024-02-12 10:13:04,102 [INFO] loss: 0.0170    [15,    20]\n","2024-02-12 10:13:04,143 [INFO] loss: 0.0167    [16,    10]\n","2024-02-12 10:13:04,174 [INFO] loss: 0.0184    [16,    20]\n","2024-02-12 10:13:04,215 [INFO] loss: 0.0171    [17,    10]\n","2024-02-12 10:13:04,246 [INFO] loss: 0.0168    [17,    20]\n","2024-02-12 10:13:04,285 [INFO] loss: 0.0170    [18,    10]\n","2024-02-12 10:13:04,318 [INFO] loss: 0.0177    [18,    20]\n","2024-02-12 10:13:04,359 [INFO] loss: 0.0178    [19,    10]\n","2024-02-12 10:13:04,402 [INFO] loss: 0.0170    [19,    20]\n","2024-02-12 10:13:04,457 [INFO] loss: 0.0166    [20,    10]\n","2024-02-12 10:13:04,489 [INFO] loss: 0.0174    [20,    20]\n","2024-02-12 10:13:04,525 [INFO] loss: 0.0173    [21,    10]\n","2024-02-12 10:13:04,560 [INFO] loss: 0.0173    [21,    20]\n","2024-02-12 10:13:04,600 [INFO] loss: 0.0172    [22,    10]\n","2024-02-12 10:13:04,652 [INFO] loss: 0.0161    [22,    20]\n","2024-02-12 10:13:04,695 [INFO] loss: 0.0164    [23,    10]\n","2024-02-12 10:13:04,724 [INFO] loss: 0.0175    [23,    20]\n","2024-02-12 10:13:04,760 [INFO] loss: 0.0155    [24,    10]\n","2024-02-12 10:13:04,790 [INFO] loss: 0.0178    [24,    20]\n","2024-02-12 10:13:04,831 [INFO] loss: 0.0173    [25,    10]\n","2024-02-12 10:13:04,863 [INFO] loss: 0.0161    [25,    20]\n","2024-02-12 10:13:04,902 [INFO] loss: 0.0170    [26,    10]\n","2024-02-12 10:13:04,934 [INFO] loss: 0.0166    [26,    20]\n","2024-02-12 10:13:04,972 [INFO] loss: 0.0169    [27,    10]\n","2024-02-12 10:13:05,009 [INFO] loss: 0.0164    [27,    20]\n","2024-02-12 10:13:05,050 [INFO] loss: 0.0165    [28,    10]\n","2024-02-12 10:13:05,082 [INFO] loss: 0.0166    [28,    20]\n","2024-02-12 10:13:05,121 [INFO] loss: 0.0164    [29,    10]\n","2024-02-12 10:13:05,152 [INFO] loss: 0.0160    [29,    20]\n","2024-02-12 10:13:05,199 [INFO] loss: 0.0159    [30,    10]\n","2024-02-12 10:13:05,239 [INFO] loss: 0.0163    [30,    20]\n","2024-02-12 10:13:05,300 [INFO] loss: 0.0163    [31,    10]\n","2024-02-12 10:13:05,341 [INFO] loss: 0.0168    [31,    20]\n","2024-02-12 10:13:05,431 [INFO] loss: 0.0170    [32,    10]\n","2024-02-12 10:13:05,484 [INFO] loss: 0.0160    [32,    20]\n","2024-02-12 10:13:05,519 [INFO] loss: 0.0174    [33,    10]\n","2024-02-12 10:13:05,562 [INFO] loss: 0.0155    [33,    20]\n","2024-02-12 10:13:05,596 [INFO] loss: 0.0166    [34,    10]\n","2024-02-12 10:13:05,634 [INFO] loss: 0.0151    [34,    20]\n","2024-02-12 10:13:05,677 [INFO] loss: 0.0165    [35,    10]\n","2024-02-12 10:13:05,729 [INFO] loss: 0.0161    [35,    20]\n","2024-02-12 10:13:05,764 [INFO] loss: 0.0152    [36,    10]\n","2024-02-12 10:13:05,804 [INFO] loss: 0.0171    [36,    20]\n","2024-02-12 10:13:05,864 [INFO] loss: 0.0147    [37,    10]\n","2024-02-12 10:13:05,919 [INFO] loss: 0.0177    [37,    20]\n","2024-02-12 10:13:05,970 [INFO] loss: 0.0160    [38,    10]\n","2024-02-12 10:13:06,000 [INFO] loss: 0.0155    [38,    20]\n","2024-02-12 10:13:06,053 [INFO] loss: 0.0158    [39,    10]\n","2024-02-12 10:13:06,158 [INFO] loss: 0.0158    [39,    20]\n","2024-02-12 10:13:06,313 [INFO] loss: 0.0160    [40,    10]\n","2024-02-12 10:13:06,364 [INFO] loss: 0.0156    [40,    20]\n","2024-02-12 10:13:06,400 [INFO] loss: 0.0153    [41,    10]\n","2024-02-12 10:13:06,429 [INFO] loss: 0.0157    [41,    20]\n","2024-02-12 10:13:06,465 [INFO] loss: 0.0149    [42,    10]\n","2024-02-12 10:13:06,498 [INFO] loss: 0.0163    [42,    20]\n","2024-02-12 10:13:06,542 [INFO] loss: 0.0153    [43,    10]\n","2024-02-12 10:13:06,593 [INFO] loss: 0.0158    [43,    20]\n","2024-02-12 10:13:06,644 [INFO] loss: 0.0143    [44,    10]\n","2024-02-12 10:13:06,678 [INFO] loss: 0.0162    [44,    20]\n","2024-02-12 10:13:06,790 [INFO] loss: 0.0144    [45,    10]\n","2024-02-12 10:13:06,902 [INFO] loss: 0.0160    [45,    20]\n","2024-02-12 10:13:06,985 [INFO] loss: 0.0147    [46,    10]\n","2024-02-12 10:13:07,016 [INFO] loss: 0.0157    [46,    20]\n","2024-02-12 10:13:07,072 [INFO] loss: 0.0145    [47,    10]\n","2024-02-12 10:13:07,100 [INFO] loss: 0.0145    [47,    20]\n","2024-02-12 10:13:07,214 [INFO] loss: 0.0140    [48,    10]\n","2024-02-12 10:13:07,243 [INFO] loss: 0.0140    [48,    20]\n","2024-02-12 10:13:07,277 [INFO] loss: 0.0146    [49,    10]\n","2024-02-12 10:13:07,303 [INFO] loss: 0.0152    [49,    20]\n","2024-02-12 10:13:07,342 [INFO] loss: 0.0154    [50,    10]\n","2024-02-12 10:13:07,375 [INFO] loss: 0.0153    [50,    20]\n","2024-02-12 10:13:07,483 [INFO] Result on Train Data : {'AUC': 0.8906361244389414, 'ACC': 0.7635605006954103, 'F1 Score': 0.7549204388694619, 'AUPR': 0, 'Loss': 0.4468203718247621}\n","2024-02-12 10:13:07,500 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-12 10:13:07,502 [INFO] moving data and model to cpu\n","2024-02-12 10:13:07,537 [INFO] Result on Test Data : {'AUC': 0.8136420525657072, 'ACC': 0.7094972067039106, 'F1 Score': 0.7046204620462047, 'AUPR': 0, 'Loss': 0.6757452537616094}\n","2024-02-12 10:13:07,539 [INFO] Result of fold 3 : {'AUC': 0.8136420525657072, 'ACC': 0.7094972067039106, 'F1 Score': 0.7046204620462047, 'AUPR': 0, 'Loss': 0.6757452537616094}\n","2024-02-12 10:13:07,545 [INFO] ---- Fold 4 ----\n","2024-02-12 10:13:07,552 [INFO] Initializing SimplePytorchData with X shape : torch.Size([719, 64]) and y shape : torch.Size([719, 1])\n","2024-02-12 10:13:07,555 [INFO] Initializing SimplePytorchData with X shape : torch.Size([179, 64]) and y shape : torch.Size([179, 1])\n","2024-02-12 10:13:07,559 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-12 10:13:07,564 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-12 10:13:07,568 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-12 10:13:07,570 [INFO] moving data and model to cpu\n","2024-02-12 10:13:07,673 [INFO] loss: 0.0206    [1,    10]\n","2024-02-12 10:13:07,712 [INFO] loss: 0.0197    [1,    20]\n","2024-02-12 10:13:07,755 [INFO] loss: 0.0186    [2,    10]\n","2024-02-12 10:13:07,781 [INFO] loss: 0.0187    [2,    20]\n","2024-02-12 10:13:07,836 [INFO] loss: 0.0180    [3,    10]\n","2024-02-12 10:13:07,862 [INFO] loss: 0.0194    [3,    20]\n","2024-02-12 10:13:07,896 [INFO] loss: 0.0186    [4,    10]\n","2024-02-12 10:13:07,924 [INFO] loss: 0.0180    [4,    20]\n","2024-02-12 10:13:07,955 [INFO] loss: 0.0184    [5,    10]\n","2024-02-12 10:13:07,981 [INFO] loss: 0.0186    [5,    20]\n","2024-02-12 10:13:08,027 [INFO] loss: 0.0181    [6,    10]\n","2024-02-12 10:13:08,088 [INFO] loss: 0.0182    [6,    20]\n","2024-02-12 10:13:08,166 [INFO] loss: 0.0175    [7,    10]\n","2024-02-12 10:13:08,206 [INFO] loss: 0.0182    [7,    20]\n","2024-02-12 10:13:08,243 [INFO] loss: 0.0176    [8,    10]\n","2024-02-12 10:13:08,277 [INFO] loss: 0.0187    [8,    20]\n","2024-02-12 10:13:08,300 [INFO] loss: 0.0180    [9,    10]\n","2024-02-12 10:13:08,320 [INFO] loss: 0.0183    [9,    20]\n","2024-02-12 10:13:08,343 [INFO] loss: 0.0172    [10,    10]\n","2024-02-12 10:13:08,366 [INFO] loss: 0.0176    [10,    20]\n","2024-02-12 10:13:08,390 [INFO] loss: 0.0180    [11,    10]\n","2024-02-12 10:13:08,412 [INFO] loss: 0.0170    [11,    20]\n","2024-02-12 10:13:08,439 [INFO] loss: 0.0170    [12,    10]\n","2024-02-12 10:13:08,458 [INFO] loss: 0.0187    [12,    20]\n","2024-02-12 10:13:08,480 [INFO] loss: 0.0177    [13,    10]\n","2024-02-12 10:13:08,502 [INFO] loss: 0.0175    [13,    20]\n","2024-02-12 10:13:08,530 [INFO] loss: 0.0184    [14,    10]\n","2024-02-12 10:13:08,555 [INFO] loss: 0.0172    [14,    20]\n","2024-02-12 10:13:08,584 [INFO] loss: 0.0174    [15,    10]\n","2024-02-12 10:13:08,603 [INFO] loss: 0.0176    [15,    20]\n","2024-02-12 10:13:08,626 [INFO] loss: 0.0160    [16,    10]\n","2024-02-12 10:13:08,646 [INFO] loss: 0.0179    [16,    20]\n","2024-02-12 10:13:08,670 [INFO] loss: 0.0166    [17,    10]\n","2024-02-12 10:13:08,688 [INFO] loss: 0.0181    [17,    20]\n","2024-02-12 10:13:08,711 [INFO] loss: 0.0171    [18,    10]\n","2024-02-12 10:13:08,730 [INFO] loss: 0.0175    [18,    20]\n","2024-02-12 10:13:08,755 [INFO] loss: 0.0164    [19,    10]\n","2024-02-12 10:13:08,772 [INFO] loss: 0.0182    [19,    20]\n","2024-02-12 10:13:08,794 [INFO] loss: 0.0172    [20,    10]\n","2024-02-12 10:13:08,816 [INFO] loss: 0.0172    [20,    20]\n","2024-02-12 10:13:08,847 [INFO] loss: 0.0173    [21,    10]\n","2024-02-12 10:13:08,865 [INFO] loss: 0.0165    [21,    20]\n","2024-02-12 10:13:08,887 [INFO] loss: 0.0163    [22,    10]\n","2024-02-12 10:13:08,905 [INFO] loss: 0.0172    [22,    20]\n","2024-02-12 10:13:08,927 [INFO] loss: 0.0171    [23,    10]\n","2024-02-12 10:13:08,949 [INFO] loss: 0.0173    [23,    20]\n","2024-02-12 10:13:08,972 [INFO] loss: 0.0160    [24,    10]\n","2024-02-12 10:13:08,990 [INFO] loss: 0.0174    [24,    20]\n","2024-02-12 10:13:09,013 [INFO] loss: 0.0168    [25,    10]\n","2024-02-12 10:13:09,033 [INFO] loss: 0.0170    [25,    20]\n","2024-02-12 10:13:09,058 [INFO] loss: 0.0170    [26,    10]\n","2024-02-12 10:13:09,079 [INFO] loss: 0.0162    [26,    20]\n","2024-02-12 10:13:09,109 [INFO] loss: 0.0156    [27,    10]\n","2024-02-12 10:13:09,130 [INFO] loss: 0.0168    [27,    20]\n","2024-02-12 10:13:09,154 [INFO] loss: 0.0164    [28,    10]\n","2024-02-12 10:13:09,175 [INFO] loss: 0.0164    [28,    20]\n","2024-02-12 10:13:09,199 [INFO] loss: 0.0167    [29,    10]\n","2024-02-12 10:13:09,219 [INFO] loss: 0.0167    [29,    20]\n","2024-02-12 10:13:09,244 [INFO] loss: 0.0154    [30,    10]\n","2024-02-12 10:13:09,263 [INFO] loss: 0.0178    [30,    20]\n","2024-02-12 10:13:09,286 [INFO] loss: 0.0166    [31,    10]\n","2024-02-12 10:13:09,305 [INFO] loss: 0.0155    [31,    20]\n","2024-02-12 10:13:09,329 [INFO] loss: 0.0152    [32,    10]\n","2024-02-12 10:13:09,351 [INFO] loss: 0.0169    [32,    20]\n","2024-02-12 10:13:09,374 [INFO] loss: 0.0159    [33,    10]\n","2024-02-12 10:13:09,393 [INFO] loss: 0.0161    [33,    20]\n","2024-02-12 10:13:09,416 [INFO] loss: 0.0168    [34,    10]\n","2024-02-12 10:13:09,438 [INFO] loss: 0.0153    [34,    20]\n","2024-02-12 10:13:09,460 [INFO] loss: 0.0149    [35,    10]\n","2024-02-12 10:13:09,479 [INFO] loss: 0.0161    [35,    20]\n","2024-02-12 10:13:09,501 [INFO] loss: 0.0153    [36,    10]\n","2024-02-12 10:13:09,520 [INFO] loss: 0.0158    [36,    20]\n","2024-02-12 10:13:09,543 [INFO] loss: 0.0153    [37,    10]\n","2024-02-12 10:13:09,565 [INFO] loss: 0.0168    [37,    20]\n","2024-02-12 10:13:09,589 [INFO] loss: 0.0158    [38,    10]\n","2024-02-12 10:13:09,610 [INFO] loss: 0.0156    [38,    20]\n","2024-02-12 10:13:09,633 [INFO] loss: 0.0164    [39,    10]\n","2024-02-12 10:13:09,652 [INFO] loss: 0.0152    [39,    20]\n","2024-02-12 10:13:09,677 [INFO] loss: 0.0144    [40,    10]\n","2024-02-12 10:13:09,696 [INFO] loss: 0.0154    [40,    20]\n","2024-02-12 10:13:09,719 [INFO] loss: 0.0151    [41,    10]\n","2024-02-12 10:13:09,741 [INFO] loss: 0.0161    [41,    20]\n","2024-02-12 10:13:09,764 [INFO] loss: 0.0152    [42,    10]\n","2024-02-12 10:13:09,782 [INFO] loss: 0.0151    [42,    20]\n","2024-02-12 10:13:09,805 [INFO] loss: 0.0152    [43,    10]\n","2024-02-12 10:13:09,826 [INFO] loss: 0.0147    [43,    20]\n","2024-02-12 10:13:09,853 [INFO] loss: 0.0141    [44,    10]\n","2024-02-12 10:13:09,878 [INFO] loss: 0.0155    [44,    20]\n","2024-02-12 10:13:09,902 [INFO] loss: 0.0149    [45,    10]\n","2024-02-12 10:13:09,921 [INFO] loss: 0.0151    [45,    20]\n","2024-02-12 10:13:09,944 [INFO] loss: 0.0143    [46,    10]\n","2024-02-12 10:13:09,962 [INFO] loss: 0.0146    [46,    20]\n","2024-02-12 10:13:09,986 [INFO] loss: 0.0137    [47,    10]\n","2024-02-12 10:13:10,005 [INFO] loss: 0.0148    [47,    20]\n","2024-02-12 10:13:10,029 [INFO] loss: 0.0139    [48,    10]\n","2024-02-12 10:13:10,047 [INFO] loss: 0.0143    [48,    20]\n","2024-02-12 10:13:10,073 [INFO] loss: 0.0149    [49,    10]\n","2024-02-12 10:13:10,092 [INFO] loss: 0.0151    [49,    20]\n","2024-02-12 10:13:10,115 [INFO] loss: 0.0138    [50,    10]\n","2024-02-12 10:13:10,139 [INFO] loss: 0.0147    [50,    20]\n","2024-02-12 10:13:10,190 [INFO] Result on Train Data : {'AUC': 0.8872949551222532, 'ACC': 0.7983310152990264, 'F1 Score': 0.7983060454984262, 'AUPR': 0, 'Loss': 0.44676927639090497}\n","2024-02-12 10:13:10,192 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-12 10:13:10,195 [INFO] moving data and model to cpu\n","2024-02-12 10:13:10,219 [INFO] Result on Test Data : {'AUC': 0.7739076154806492, 'ACC': 0.7094972067039106, 'F1 Score': 0.7094155844155845, 'AUPR': 0, 'Loss': 0.6622161815563837}\n","2024-02-12 10:13:10,222 [INFO] Result of fold 4 : {'AUC': 0.7739076154806492, 'ACC': 0.7094972067039106, 'F1 Score': 0.7094155844155845, 'AUPR': 0, 'Loss': 0.6622161815563837}\n","2024-02-12 10:13:10,224 [INFO] ---- Fold 5 ----\n","2024-02-12 10:13:10,227 [INFO] Initializing SimplePytorchData with X shape : torch.Size([716, 64]) and y shape : torch.Size([716, 1])\n","2024-02-12 10:13:10,229 [INFO] Initializing SimplePytorchData with X shape : torch.Size([182, 64]) and y shape : torch.Size([182, 1])\n","2024-02-12 10:13:10,232 [INFO] Initializing SimpleMDAClassifier with model : simple classifier\n","2024-02-12 10:13:10,235 [INFO] Initial SimpleMLP with 64 input dimension, 32 hidden dimension, 1 \n","            output dimension, 2 layers and with 0.1 dropout\n","2024-02-12 10:13:10,238 [INFO] Running Simple Trainer with config : adam optimizer\n","2024-02-12 10:13:10,240 [INFO] moving data and model to cpu\n","2024-02-12 10:13:10,263 [INFO] loss: 0.0210    [1,    10]\n","2024-02-12 10:13:10,280 [INFO] loss: 0.0194    [1,    20]\n","2024-02-12 10:13:10,306 [INFO] loss: 0.0187    [2,    10]\n","2024-02-12 10:13:10,326 [INFO] loss: 0.0189    [2,    20]\n","2024-02-12 10:13:10,349 [INFO] loss: 0.0183    [3,    10]\n","2024-02-12 10:13:10,369 [INFO] loss: 0.0184    [3,    20]\n","2024-02-12 10:13:10,392 [INFO] loss: 0.0188    [4,    10]\n","2024-02-12 10:13:10,412 [INFO] loss: 0.0188    [4,    20]\n","2024-02-12 10:13:10,436 [INFO] loss: 0.0177    [5,    10]\n","2024-02-12 10:13:10,456 [INFO] loss: 0.0194    [5,    20]\n","2024-02-12 10:13:10,482 [INFO] loss: 0.0179    [6,    10]\n","2024-02-12 10:13:10,501 [INFO] loss: 0.0191    [6,    20]\n","2024-02-12 10:13:10,532 [INFO] loss: 0.0178    [7,    10]\n","2024-02-12 10:13:10,556 [INFO] loss: 0.0185    [7,    20]\n","2024-02-12 10:13:10,587 [INFO] loss: 0.0183    [8,    10]\n","2024-02-12 10:13:10,606 [INFO] loss: 0.0181    [8,    20]\n","2024-02-12 10:13:10,629 [INFO] loss: 0.0186    [9,    10]\n","2024-02-12 10:13:10,650 [INFO] loss: 0.0179    [9,    20]\n","2024-02-12 10:13:10,673 [INFO] loss: 0.0179    [10,    10]\n","2024-02-12 10:13:10,693 [INFO] loss: 0.0187    [10,    20]\n","2024-02-12 10:13:10,717 [INFO] loss: 0.0178    [11,    10]\n","2024-02-12 10:13:10,750 [INFO] loss: 0.0188    [11,    20]\n","2024-02-12 10:13:10,779 [INFO] loss: 0.0179    [12,    10]\n","2024-02-12 10:13:10,798 [INFO] loss: 0.0178    [12,    20]\n","2024-02-12 10:13:10,828 [INFO] loss: 0.0178    [13,    10]\n","2024-02-12 10:13:10,848 [INFO] loss: 0.0175    [13,    20]\n","2024-02-12 10:13:10,873 [INFO] loss: 0.0180    [14,    10]\n","2024-02-12 10:13:10,894 [INFO] loss: 0.0171    [14,    20]\n","2024-02-12 10:13:10,927 [INFO] loss: 0.0171    [15,    10]\n","2024-02-12 10:13:10,945 [INFO] loss: 0.0175    [15,    20]\n","2024-02-12 10:13:10,969 [INFO] loss: 0.0178    [16,    10]\n","2024-02-12 10:13:10,990 [INFO] loss: 0.0174    [16,    20]\n","2024-02-12 10:13:11,021 [INFO] loss: 0.0173    [17,    10]\n","2024-02-12 10:13:11,042 [INFO] loss: 0.0184    [17,    20]\n","2024-02-12 10:13:11,066 [INFO] loss: 0.0172    [18,    10]\n","2024-02-12 10:13:11,086 [INFO] loss: 0.0174    [18,    20]\n","2024-02-12 10:13:11,109 [INFO] loss: 0.0169    [19,    10]\n","2024-02-12 10:13:11,132 [INFO] loss: 0.0180    [19,    20]\n","2024-02-12 10:13:11,154 [INFO] loss: 0.0178    [20,    10]\n","2024-02-12 10:13:11,172 [INFO] loss: 0.0176    [20,    20]\n","2024-02-12 10:13:11,194 [INFO] loss: 0.0167    [21,    10]\n","2024-02-12 10:13:11,212 [INFO] loss: 0.0175    [21,    20]\n","2024-02-12 10:13:11,238 [INFO] loss: 0.0168    [22,    10]\n","2024-02-12 10:13:11,256 [INFO] loss: 0.0174    [22,    20]\n","2024-02-12 10:13:11,279 [INFO] loss: 0.0163    [23,    10]\n","2024-02-12 10:13:11,297 [INFO] loss: 0.0183    [23,    20]\n","2024-02-12 10:13:11,321 [INFO] loss: 0.0172    [24,    10]\n","2024-02-12 10:13:11,339 [INFO] loss: 0.0173    [24,    20]\n","2024-02-12 10:13:11,362 [INFO] loss: 0.0164    [25,    10]\n","2024-02-12 10:13:11,386 [INFO] loss: 0.0171    [25,    20]\n","2024-02-12 10:13:11,408 [INFO] loss: 0.0166    [26,    10]\n","2024-02-12 10:13:11,429 [INFO] loss: 0.0169    [26,    20]\n","2024-02-12 10:13:11,454 [INFO] loss: 0.0173    [27,    10]\n","2024-02-12 10:13:11,473 [INFO] loss: 0.0162    [27,    20]\n","2024-02-12 10:13:11,496 [INFO] loss: 0.0165    [28,    10]\n","2024-02-12 10:13:11,514 [INFO] loss: 0.0176    [28,    20]\n","2024-02-12 10:13:11,538 [INFO] loss: 0.0166    [29,    10]\n","2024-02-12 10:13:11,557 [INFO] loss: 0.0170    [29,    20]\n","2024-02-12 10:13:11,580 [INFO] loss: 0.0163    [30,    10]\n","2024-02-12 10:13:11,598 [INFO] loss: 0.0168    [30,    20]\n","2024-02-12 10:13:11,621 [INFO] loss: 0.0174    [31,    10]\n","2024-02-12 10:13:11,640 [INFO] loss: 0.0165    [31,    20]\n","2024-02-12 10:13:11,663 [INFO] loss: 0.0159    [32,    10]\n","2024-02-12 10:13:11,683 [INFO] loss: 0.0185    [32,    20]\n","2024-02-12 10:13:11,711 [INFO] loss: 0.0161    [33,    10]\n","2024-02-12 10:13:11,729 [INFO] loss: 0.0170    [33,    20]\n","2024-02-12 10:13:11,752 [INFO] loss: 0.0161    [34,    10]\n","2024-02-12 10:13:11,771 [INFO] loss: 0.0163    [34,    20]\n","2024-02-12 10:13:11,794 [INFO] loss: 0.0158    [35,    10]\n","2024-02-12 10:13:11,812 [INFO] loss: 0.0162    [35,    20]\n","2024-02-12 10:13:11,841 [INFO] loss: 0.0169    [36,    10]\n","2024-02-12 10:13:11,868 [INFO] loss: 0.0157    [36,    20]\n","2024-02-12 10:13:11,899 [INFO] loss: 0.0160    [37,    10]\n","2024-02-12 10:13:11,924 [INFO] loss: 0.0165    [37,    20]\n","2024-02-12 10:13:11,963 [INFO] loss: 0.0156    [38,    10]\n","2024-02-12 10:13:11,993 [INFO] loss: 0.0173    [38,    20]\n","2024-02-12 10:13:12,025 [INFO] loss: 0.0163    [39,    10]\n","2024-02-12 10:13:12,051 [INFO] loss: 0.0159    [39,    20]\n","2024-02-12 10:13:12,088 [INFO] loss: 0.0148    [40,    10]\n","2024-02-12 10:13:12,113 [INFO] loss: 0.0166    [40,    20]\n","2024-02-12 10:13:12,144 [INFO] loss: 0.0159    [41,    10]\n","2024-02-12 10:13:12,169 [INFO] loss: 0.0152    [41,    20]\n","2024-02-12 10:13:12,202 [INFO] loss: 0.0151    [42,    10]\n","2024-02-12 10:13:12,226 [INFO] loss: 0.0164    [42,    20]\n","2024-02-12 10:13:12,264 [INFO] loss: 0.0143    [43,    10]\n","2024-02-12 10:13:12,289 [INFO] loss: 0.0163    [43,    20]\n","2024-02-12 10:13:12,322 [INFO] loss: 0.0156    [44,    10]\n","2024-02-12 10:13:12,346 [INFO] loss: 0.0158    [44,    20]\n","2024-02-12 10:13:12,376 [INFO] loss: 0.0146    [45,    10]\n","2024-02-12 10:13:12,400 [INFO] loss: 0.0159    [45,    20]\n","2024-02-12 10:13:12,429 [INFO] loss: 0.0157    [46,    10]\n","2024-02-12 10:13:12,463 [INFO] loss: 0.0167    [46,    20]\n","2024-02-12 10:13:12,494 [INFO] loss: 0.0150    [47,    10]\n","2024-02-12 10:13:12,517 [INFO] loss: 0.0155    [47,    20]\n","2024-02-12 10:13:12,545 [INFO] loss: 0.0146    [48,    10]\n","2024-02-12 10:13:12,569 [INFO] loss: 0.0151    [48,    20]\n","2024-02-12 10:13:12,608 [INFO] loss: 0.0140    [49,    10]\n","2024-02-12 10:13:12,636 [INFO] loss: 0.0167    [49,    20]\n","2024-02-12 10:13:12,664 [INFO] loss: 0.0144    [50,    10]\n","2024-02-12 10:13:12,688 [INFO] loss: 0.0155    [50,    20]\n","2024-02-12 10:13:12,769 [INFO] Result on Train Data : {'AUC': 0.8847327231728346, 'ACC': 0.8156424581005587, 'F1 Score': 0.8154985007496252, 'AUPR': 0, 'Loss': 0.4595922711102859}\n","2024-02-12 10:13:12,772 [INFO] Running Simple Tester with config : adam optimizer\n","2024-02-12 10:13:12,774 [INFO] moving data and model to cpu\n","2024-02-12 10:13:12,805 [INFO] Result on Test Data : {'AUC': 0.7623188405797101, 'ACC': 0.6978021978021978, 'F1 Score': 0.6977930742988256, 'AUPR': 0, 'Loss': 0.7885752220948538}\n","2024-02-12 10:13:12,807 [INFO] Result of fold 5 : {'AUC': 0.7623188405797101, 'ACC': 0.6978021978021978, 'F1 Score': 0.6977930742988256, 'AUPR': 0, 'Loss': 0.7885752220948538}\n","2024-02-12 10:13:12,810 [INFO] 5-fold result: avg_auc: 0.7764293946266895, avg_acc: 0.6982196574375346, avg_f1: 0.6940873585284226, avg_aupr: 0.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<base.evaluation.Result at 0x7afad00fb100>"]},"metadata":{},"execution_count":40}],"source":["trainer = SimpleTrainer()\n","tester = SimpleTester()\n","factory = SimpleMDAClassifierFactory(simple_classifier_config)\n","spliter = SimplePytorchDataTrainTestSplit(data)\n","cross_validation(k=5, data_size=data.X.shape[0], train_test_spliter=spliter, model_factory=factory,\n","                    trainer=trainer, tester=tester, config=classifier_optimizer_config)"],"id":"sfI286uv6o-e"},{"cell_type":"code","source":[],"metadata":{"id":"5cpQ0kPkjuHb","executionInfo":{"status":"ok","timestamp":1707732793308,"user_tz":-210,"elapsed":19,"user":{"displayName":"Sobhan Ahmadian Moghadam","userId":"12456655244096551013"}}},"execution_count":40,"outputs":[],"id":"5cpQ0kPkjuHb"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}